<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>2 R for Statistical Inference | Financial and Actuarial Modelling in R (MATH377)</title>
  <meta name="description" content="2 R for Statistical Inference | Financial and Actuarial Modelling in R (MATH377)" />
  <meta name="generator" content="bookdown 0.32 and GitBook 2.6.7" />

  <meta property="og:title" content="2 R for Statistical Inference | Financial and Actuarial Modelling in R (MATH377)" />
  <meta property="og:type" content="book" />
  
  
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 R for Statistical Inference | Financial and Actuarial Modelling in R (MATH377)" />
  
  
  

<meta name="author" content="Jorge Yslas" />



  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="introduction-to-r.html"/>
<link rel="next" href="r-for-finance.html"/>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.1.0/anchor-sections.css" rel="stylesheet" />
<link href="libs/anchor-sections-1.1.0/anchor-sections-hash.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.1.0/anchor-sections.js"></script>


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { color: #008000; } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { color: #008000; font-weight: bold; } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="introduction-to-r.html"><a href="introduction-to-r.html"><i class="fa fa-check"></i><b>1</b> Introduction to R</a>
<ul>
<li class="chapter" data-level="1.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#installation"><i class="fa fa-check"></i><b>1.1</b> Installation</a>
<ul>
<li class="chapter" data-level="1.1.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#installation-of-r"><i class="fa fa-check"></i><b>1.1.1</b> Installation of R</a></li>
<li class="chapter" data-level="1.1.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#installation-of-rstudio"><i class="fa fa-check"></i><b>1.1.2</b> Installation of Rstudio</a></li>
</ul></li>
<li class="chapter" data-level="1.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-as-a-simple-calculator"><i class="fa fa-check"></i><b>1.2</b> R as a simple calculator</a>
<ul>
<li class="chapter" data-level="1.2.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#logical-operators"><i class="fa fa-check"></i><b>1.2.1</b> Logical operators</a></li>
</ul></li>
<li class="chapter" data-level="1.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#r-objects"><i class="fa fa-check"></i><b>1.3</b> R objects</a>
<ul>
<li class="chapter" data-level="1.3.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#assignment"><i class="fa fa-check"></i><b>1.3.1</b> Assignment</a></li>
<li class="chapter" data-level="1.3.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-types"><i class="fa fa-check"></i><b>1.3.2</b> Data types</a></li>
</ul></li>
<li class="chapter" data-level="1.4" data-path="introduction-to-r.html"><a href="introduction-to-r.html#vectors"><i class="fa fa-check"></i><b>1.4</b> Vectors</a>
<ul>
<li class="chapter" data-level="1.4.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#accessing-vector-elements"><i class="fa fa-check"></i><b>1.4.1</b> Accessing vector elements</a></li>
<li class="chapter" data-level="1.4.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#operations-with-vectors"><i class="fa fa-check"></i><b>1.4.2</b> Operations with vectors</a></li>
</ul></li>
<li class="chapter" data-level="1.5" data-path="introduction-to-r.html"><a href="introduction-to-r.html#matrices-data-frames-and-lists"><i class="fa fa-check"></i><b>1.5</b> Matrices, data frames, and lists</a>
<ul>
<li class="chapter" data-level="1.5.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#matrices"><i class="fa fa-check"></i><b>1.5.1</b> Matrices</a></li>
<li class="chapter" data-level="1.5.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#data-frames"><i class="fa fa-check"></i><b>1.5.2</b> Data frames</a></li>
<li class="chapter" data-level="1.5.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#lists"><i class="fa fa-check"></i><b>1.5.3</b> Lists</a></li>
</ul></li>
<li class="chapter" data-level="1.6" data-path="introduction-to-r.html"><a href="introduction-to-r.html#functions"><i class="fa fa-check"></i><b>1.6</b> Functions</a></li>
<li class="chapter" data-level="1.7" data-path="introduction-to-r.html"><a href="introduction-to-r.html#packages"><i class="fa fa-check"></i><b>1.7</b> Packages</a></li>
<li class="chapter" data-level="1.8" data-path="introduction-to-r.html"><a href="introduction-to-r.html#control-statements"><i class="fa fa-check"></i><b>1.8</b> Control Statements</a>
<ul>
<li class="chapter" data-level="1.8.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#conditional-statements"><i class="fa fa-check"></i><b>1.8.1</b> Conditional statements</a></li>
<li class="chapter" data-level="1.8.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#loop-statements"><i class="fa fa-check"></i><b>1.8.2</b> Loop statements</a></li>
</ul></li>
<li class="chapter" data-level="1.9" data-path="introduction-to-r.html"><a href="introduction-to-r.html#vectorized-operations"><i class="fa fa-check"></i><b>1.9</b> Vectorized operations</a></li>
<li class="chapter" data-level="1.10" data-path="introduction-to-r.html"><a href="introduction-to-r.html#reading-and-writing-data"><i class="fa fa-check"></i><b>1.10</b> Reading and writing data</a>
<ul>
<li class="chapter" data-level="1.10.1" data-path="introduction-to-r.html"><a href="introduction-to-r.html#working-directory"><i class="fa fa-check"></i><b>1.10.1</b> Working directory</a></li>
<li class="chapter" data-level="1.10.2" data-path="introduction-to-r.html"><a href="introduction-to-r.html#writing-data"><i class="fa fa-check"></i><b>1.10.2</b> Writing data</a></li>
<li class="chapter" data-level="1.10.3" data-path="introduction-to-r.html"><a href="introduction-to-r.html#reading-data"><i class="fa fa-check"></i><b>1.10.3</b> Reading data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="2" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html"><i class="fa fa-check"></i><b>2</b> R for Statistical Inference</a>
<ul>
<li class="chapter" data-level="2.1" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#descriptive-statistics"><i class="fa fa-check"></i><b>2.1</b> Descriptive statistics</a>
<ul>
<li class="chapter" data-level="2.1.1" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#visual-tools"><i class="fa fa-check"></i><b>2.1.1</b> Visual tools</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#probability-distributions"><i class="fa fa-check"></i><b>2.2</b> Probability distributions</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#tranformations"><i class="fa fa-check"></i><b>2.2.1</b> Tranformations</a></li>
<li class="chapter" data-level="2.2.2" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#law-of-large-numbers-and-central-limit-theorem"><i class="fa fa-check"></i><b>2.2.2</b> Law of large numbers and central limit theorem</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#parinf"><i class="fa fa-check"></i><b>2.3</b> Parametric inference</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#maximum-likelihood-estimation"><i class="fa fa-check"></i><b>2.3.1</b> Maximum likelihood estimation</a></li>
<li class="chapter" data-level="2.3.2" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#adequacy-of-the-fit"><i class="fa fa-check"></i><b>2.3.2</b> Adequacy of the fit</a></li>
<li class="chapter" data-level="2.3.3" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#other-estimation-methods"><i class="fa fa-check"></i><b>2.3.3</b> Other estimation methods</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#multivariate-distributions"><i class="fa fa-check"></i><b>2.4</b> Multivariate distributions</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#multivariate-normal-distribution"><i class="fa fa-check"></i><b>2.4.1</b> Multivariate normal distribution</a></li>
<li class="chapter" data-level="2.4.2" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#copulas"><i class="fa fa-check"></i><b>2.4.2</b> Copulas</a></li>
<li class="chapter" data-level="2.4.3" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#constructing-multivariate-distributions-from-copulas"><i class="fa fa-check"></i><b>2.4.3</b> Constructing multivariate distributions from copulas</a></li>
<li class="chapter" data-level="2.4.4" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#dependence-measures"><i class="fa fa-check"></i><b>2.4.4</b> Dependence measures</a></li>
<li class="chapter" data-level="2.4.5" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#fitting"><i class="fa fa-check"></i><b>2.4.5</b> Fitting</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="r-for-statistical-inference.html"><a href="r-for-statistical-inference.html#linear-regression"><i class="fa fa-check"></i><b>2.5</b> Linear regression</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="r-for-finance.html"><a href="r-for-finance.html"><i class="fa fa-check"></i><b>3</b> R for Finance</a>
<ul>
<li class="chapter" data-level="3.1" data-path="r-for-finance.html"><a href="r-for-finance.html#market-portfolio-and-capm"><i class="fa fa-check"></i><b>3.1</b> Market portfolio and CAPM</a>
<ul>
<li class="chapter" data-level="3.1.1" data-path="r-for-finance.html"><a href="r-for-finance.html#mean-variance-portfolio"><i class="fa fa-check"></i><b>3.1.1</b> Mean-variance portfolio</a></li>
<li class="chapter" data-level="3.1.2" data-path="r-for-finance.html"><a href="r-for-finance.html#capital-asset-pricing-model-capm"><i class="fa fa-check"></i><b>3.1.2</b> Capital Asset Pricing Model (CAPM)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="r-for-finance.html"><a href="r-for-finance.html#the-binomial-model"><i class="fa fa-check"></i><b>3.2</b> The binomial model</a>
<ul>
<li class="chapter" data-level="3.2.1" data-path="r-for-finance.html"><a href="r-for-finance.html#one-period-binomial-model"><i class="fa fa-check"></i><b>3.2.1</b> One-period binomial model</a></li>
<li class="chapter" data-level="3.2.2" data-path="r-for-finance.html"><a href="r-for-finance.html#multiperiod-binomial-model"><i class="fa fa-check"></i><b>3.2.2</b> Multiperiod binomial model</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="r-for-finance.html"><a href="r-for-finance.html#the-black-and-scholes-model"><i class="fa fa-check"></i><b>3.3</b> The Black and Scholes model</a>
<ul>
<li class="chapter" data-level="3.3.1" data-path="r-for-finance.html"><a href="r-for-finance.html#preliminars-brownian-motion"><i class="fa fa-check"></i><b>3.3.1</b> Preliminars: Brownian motion</a></li>
<li class="chapter" data-level="3.3.2" data-path="r-for-finance.html"><a href="r-for-finance.html#the-black-and-scholes-formula"><i class="fa fa-check"></i><b>3.3.2</b> The Black and Scholes formula</a></li>
<li class="chapter" data-level="3.3.3" data-path="r-for-finance.html"><a href="r-for-finance.html#greeks"><i class="fa fa-check"></i><b>3.3.3</b> Greeks</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="4" data-path="r-for-insurance.html"><a href="r-for-insurance.html"><i class="fa fa-check"></i><b>4</b> R for Insurance</a>
<ul>
<li class="chapter" data-level="4.1" data-path="r-for-insurance.html"><a href="r-for-insurance.html#the-collective-risk-model"><i class="fa fa-check"></i><b>4.1</b> The collective risk model</a>
<ul>
<li class="chapter" data-level="4.1.1" data-path="r-for-insurance.html"><a href="r-for-insurance.html#discretization-of-claim-amount-distributions"><i class="fa fa-check"></i><b>4.1.1</b> Discretization of claim amount distributions</a></li>
<li class="chapter" data-level="4.1.2" data-path="r-for-insurance.html"><a href="r-for-insurance.html#calculation-of-the-aggregate-claim-amount-distribution"><i class="fa fa-check"></i><b>4.1.2</b> Calculation of the aggregate claim amount distribution</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="r-for-insurance.html"><a href="r-for-insurance.html#ruin-theory"><i class="fa fa-check"></i><b>4.2</b> Ruin theory</a>
<ul>
<li class="chapter" data-level="4.2.1" data-path="r-for-insurance.html"><a href="r-for-insurance.html#the-surplus-process"><i class="fa fa-check"></i><b>4.2.1</b> The surplus process</a></li>
<li class="chapter" data-level="4.2.2" data-path="r-for-insurance.html"><a href="r-for-insurance.html#the-adjustment-coefficient"><i class="fa fa-check"></i><b>4.2.2</b> The adjustment coefficient</a></li>
<li class="chapter" data-level="4.2.3" data-path="r-for-insurance.html"><a href="r-for-insurance.html#probability-of-ruin"><i class="fa fa-check"></i><b>4.2.3</b> Probability of ruin</a></li>
<li class="chapter" data-level="4.2.4" data-path="r-for-insurance.html"><a href="r-for-insurance.html#reinsurance"><i class="fa fa-check"></i><b>4.2.4</b> Reinsurance</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Financial and Actuarial Modelling in R (MATH377)</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="r-for-statistical-inference" class="section level1 hasAnchor" number="2">
<h1><span class="header-section-number">2</span> R for Statistical Inference<a href="r-for-statistical-inference.html#r-for-statistical-inference" class="anchor-section" aria-label="Anchor link to header"></a></h1>
<div id="descriptive-statistics" class="section level2 hasAnchor" number="2.1">
<h2><span class="header-section-number">2.1</span> Descriptive statistics<a href="r-for-statistical-inference.html#descriptive-statistics" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>When working with real-life data, one of the first things we may want to do is get a general understanding of the data. For this purpose, we can use some descriptive statics and plots available in R.</p>
<p>R comes with some databases that can be accessed using the <code>data()</code> function. Moreover, we can see the list of data sets available by typing <code>data()</code>. For example, we can find the <code>iris</code> data set (use <code>?iris</code> for a complete description of the data). Although not an insurance or financial data set, we will use <code>iris</code> in this section since it is readily available, and the tools presented here do not depend on the source of the data.</p>
<p>First, we need to load the data into our working space using <code>data()</code>:</p>
<div class="sourceCode" id="cb540"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb540-1"><a href="r-for-statistical-inference.html#cb540-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(iris)</span></code></pre></div>
<p>Now, the <code>iris</code> should appear in the <strong>Environment</strong> tab. Note that <code>iris</code> is a data frame, which is one of the most common ways of presenting data in R.</p>
<div class="sourceCode" id="cb541"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb541-1"><a href="r-for-statistical-inference.html#cb541-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(iris)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    150 obs. of  5 variables:
##  $ Sepal.Length: num  5.1 4.9 4.7 4.6 5 5.4 4.6 5 4.4 4.9 ...
##  $ Sepal.Width : num  3.5 3 3.2 3.1 3.6 3.9 3.4 3.4 2.9 3.1 ...
##  $ Petal.Length: num  1.4 1.4 1.3 1.5 1.4 1.7 1.4 1.5 1.4 1.5 ...
##  $ Petal.Width : num  0.2 0.2 0.2 0.2 0.2 0.4 0.3 0.2 0.2 0.1 ...
##  $ Species     : Factor w/ 3 levels &quot;setosa&quot;,&quot;versicolor&quot;,..: 1 1 1 1 1 1 1 1 1 1 ...</code></pre>
<div class="remark">
<p><span id="unlabeled-div-23" class="remark"><em>Remark</em>. </span>Some R packages include data sets. For instance, install and load the package <code>insuranceData</code>. Here you will find the <code>dataCar</code> data set.</p>
</div>
<p>The first thing that we may want to do is to compute some measures of central tendency and variability. Let us focus for now on the column <code>Sepal.Lenght</code>. Regarding measures of central tendency, these refer to measures such as the mean and the median. We already know that the function <code>mean()</code> can be used to compute the sample mean.</p>
<div class="sourceCode" id="cb543"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb543-1"><a href="r-for-statistical-inference.html#cb543-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>## [1] 5.843333</code></pre>
<p>We can also compute the sample median using the <code>median()</code> function. Recall that the sample median refers to the value in the middle of the observations.</p>
<div class="sourceCode" id="cb545"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb545-1"><a href="r-for-statistical-inference.html#cb545-1" aria-hidden="true" tabindex="-1"></a><span class="fu">median</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>## [1] 5.8</code></pre>
<p>Let us now move to some measures of variability, which help us understand how spread the data is. First, we can look at the minimum and maximum values, which can be obtained using the functions <code>min()</code> and <code>max()</code> receptively.</p>
<div class="sourceCode" id="cb547"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb547-1"><a href="r-for-statistical-inference.html#cb547-1" aria-hidden="true" tabindex="-1"></a><span class="fu">min</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>## [1] 4.3</code></pre>
<div class="sourceCode" id="cb549"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb549-1"><a href="r-for-statistical-inference.html#cb549-1" aria-hidden="true" tabindex="-1"></a><span class="fu">max</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>## [1] 7.9</code></pre>
<p>Alternatively, we can use the <code>range()</code> function to compute both minimum and maximum simultaneously.</p>
<div class="sourceCode" id="cb551"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb551-1"><a href="r-for-statistical-inference.html#cb551-1" aria-hidden="true" tabindex="-1"></a><span class="fu">range</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>## [1] 4.3 7.9</code></pre>
<p>Next, we can look at the variance, which measures how the data values are dispersed around the mean. This can be computed with the <code>var()</code> function:</p>
<div class="sourceCode" id="cb553"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb553-1"><a href="r-for-statistical-inference.html#cb553-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>## [1] 0.6856935</code></pre>
<p>A related measure is the standard deviation, which is simply the square root of the variance. To compute it, we can use <code>sd()</code>:</p>
<div class="sourceCode" id="cb555"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb555-1"><a href="r-for-statistical-inference.html#cb555-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sd</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>## [1] 0.8280661</code></pre>
<p>Finally, we may be interested in computing the sample quantiles of our data. The R command to do so is <code>quantile()</code>:</p>
<div class="sourceCode" id="cb557"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb557-1"><a href="r-for-statistical-inference.html#cb557-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>##   0%  25%  50%  75% 100% 
##  4.3  5.1  5.8  6.4  7.9</code></pre>
<p>Note that by default, R computes the quantiles of 0% (min), 25%, 50% (median), 75%, and 100% (max). However, we can change this with the argument <code>probs</code>:</p>
<div class="sourceCode" id="cb559"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb559-1"><a href="r-for-statistical-inference.html#cb559-1" aria-hidden="true" tabindex="-1"></a><span class="fu">quantile</span>(iris<span class="sc">$</span>Sepal.Length, <span class="at">probs =</span> <span class="fu">seq</span>(<span class="fl">0.1</span>, <span class="fl">0.9</span>, <span class="at">by =</span> <span class="fl">0.1</span>))</span></code></pre></div>
<pre><code>##  10%  20%  30%  40%  50%  60%  70%  80%  90% 
## 4.80 5.00 5.27 5.60 5.80 6.10 6.30 6.52 6.90</code></pre>
<p>Although all the above measures can be computed separately, the <code>summary()</code> function provides an easier way to compute several of them at once:</p>
<div class="sourceCode" id="cb561"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb561-1"><a href="r-for-statistical-inference.html#cb561-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<pre><code>##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   4.300   5.100   5.800   5.843   6.400   7.900</code></pre>
<p>Moreover, if our data set has several columns, <code>summary()</code> can compute all these measures for all columns at the same time:</p>
<div class="sourceCode" id="cb563"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb563-1"><a href="r-for-statistical-inference.html#cb563-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(iris)</span></code></pre></div>
<pre><code>##   Sepal.Length    Sepal.Width     Petal.Length    Petal.Width   
##  Min.   :4.300   Min.   :2.000   Min.   :1.000   Min.   :0.100  
##  1st Qu.:5.100   1st Qu.:2.800   1st Qu.:1.600   1st Qu.:0.300  
##  Median :5.800   Median :3.000   Median :4.350   Median :1.300  
##  Mean   :5.843   Mean   :3.057   Mean   :3.758   Mean   :1.199  
##  3rd Qu.:6.400   3rd Qu.:3.300   3rd Qu.:5.100   3rd Qu.:1.800  
##  Max.   :7.900   Max.   :4.400   Max.   :6.900   Max.   :2.500  
##        Species  
##  setosa    :50  
##  versicolor:50  
##  virginica :50  
##                 
##                 
## </code></pre>
<p>Note that our data set has a column called <code>Species</code>, indicating the flower species. Although the summary function above already provides us with the list of species (three species), we can also use the <code>unique()</code> function to check how many species we have:</p>
<div class="sourceCode" id="cb565"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb565-1"><a href="r-for-statistical-inference.html#cb565-1" aria-hidden="true" tabindex="-1"></a><span class="fu">unique</span>(iris<span class="sc">$</span>Species)</span></code></pre></div>
<pre><code>## [1] setosa     versicolor virginica 
## Levels: setosa versicolor virginica</code></pre>
<p>Now, we can use <code>Species</code> to give more insides into our data set. For example, we may be interested in computing the mean of <code>Sepal.Lenght</code> by species. For that, we can use the function <code>tapply()</code> as follows:</p>
<div class="sourceCode" id="cb567"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb567-1"><a href="r-for-statistical-inference.html#cb567-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tapply</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Species, mean)</span></code></pre></div>
<pre><code>##     setosa versicolor  virginica 
##      5.006      5.936      6.588</code></pre>
<p>Or we can use <code>tapply()</code> in conjunction with <code>summary()</code>.</p>
<div class="sourceCode" id="cb569"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb569-1"><a href="r-for-statistical-inference.html#cb569-1" aria-hidden="true" tabindex="-1"></a><span class="fu">tapply</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Species, summary)</span></code></pre></div>
<pre><code>## $setosa
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   4.300   4.800   5.000   5.006   5.200   5.800 
## 
## $versicolor
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   4.900   5.600   5.900   5.936   6.300   7.000 
## 
## $virginica
##    Min. 1st Qu.  Median    Mean 3rd Qu.    Max. 
##   4.900   6.225   6.500   6.588   6.900   7.900</code></pre>
<p>We may also be interested in seeing if there is a relationship among the different columns of our data set. For that purpose, we can start, for instance, by computing their correlation, a measure of how a pair of variables are linearly related. Recall that for two vectors <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_n)\)</span> and <span class="math inline">\(\mathbf{y} = (y_1, \dots, y_n)\)</span> the sample covariance is given by
<span class="math display">\[
\mbox{Cov}(\mathbf{x}, \mathbf{y}) = \frac{1}{n-1} \sum_{i = 1}^{n} \frac{(x_i - \bar{x})(y_i - \bar{y})}{s_{x}s_{y}} \,,
\]</span>
where <span class="math inline">\(s_{\mathbf{x}}\)</span> and <span class="math inline">\(s_{\mathbf{y}}\)</span> are the sample standard deviations of <span class="math inline">\(\mathbf{x}\)</span> and <span class="math inline">\(\mathbf{y}\)</span>, respectively. In R, the sample correlation is computed using the <code>cor()</code> function. For example,</p>
<div class="sourceCode" id="cb571"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb571-1"><a href="r-for-statistical-inference.html#cb571-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Sepal.Width)</span></code></pre></div>
<pre><code>## [1] -0.1175698</code></pre>
<p>If we have several (numeric) columns, we can compute all correlations at once:</p>
<div class="sourceCode" id="cb573"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb573-1"><a href="r-for-statistical-inference.html#cb573-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(iris[, <span class="sc">-</span><span class="dv">5</span>])</span></code></pre></div>
<pre><code>##              Sepal.Length Sepal.Width Petal.Length Petal.Width
## Sepal.Length    1.0000000  -0.1175698    0.8717538   0.8179411
## Sepal.Width    -0.1175698   1.0000000   -0.4284401  -0.3661259
## Petal.Length    0.8717538  -0.4284401    1.0000000   0.9628654
## Petal.Width     0.8179411  -0.3661259    0.9628654   1.0000000</code></pre>
<div class="remark">
<p><span id="unlabeled-div-24" class="remark"><em>Remark</em>. </span>The <code>cor()</code> computes, by default, the Person’s correlation coefficient described above. However, we can use the <code>method</code> argument to calculate Kendall’s tau and Spearman’s rho, two measures that assess how well the relationship between two variables can be described using a monotonic function. We will review these two other measures later on.</p>
</div>
<div id="visual-tools" class="section level3 hasAnchor" number="2.1.1">
<h3><span class="header-section-number">2.1.1</span> Visual tools<a href="r-for-statistical-inference.html#visual-tools" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now present some R tools that can be employed to visualize data. More specifically, we will see how to create histograms, box plots, and scatter plots.</p>
<div id="histograms" class="section level4 unnumbered hasAnchor">
<h4>Histograms<a href="r-for-statistical-inference.html#histograms" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To create a histogram, we can use the <code>hist()</code> function. For instance, to draw a histogram for <code>Sepal.Length</code>, we type:</p>
<div class="sourceCode" id="cb575"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb575-1"><a href="r-for-statistical-inference.html#cb575-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-224-1.png" width="672" /></p>
<p>We can customize our plot further using the different arguments of <code>hist()</code> (see <code>?hist</code>):</p>
<div class="sourceCode" id="cb576"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb576-1"><a href="r-for-statistical-inference.html#cb576-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(iris<span class="sc">$</span>Sepal.Length,</span>
<span id="cb576-2"><a href="r-for-statistical-inference.html#cb576-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">breaks =</span> <span class="dv">15</span>, <span class="co"># Number of cells in the histogram</span></span>
<span id="cb576-3"><a href="r-for-statistical-inference.html#cb576-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Histogram of Sepal Lenght&quot;</span>, <span class="co"># Main tittle</span></span>
<span id="cb576-4"><a href="r-for-statistical-inference.html#cb576-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Sepal Lenght&quot;</span>, <span class="co"># Text on the x-axis</span></span>
<span id="cb576-5"><a href="r-for-statistical-inference.html#cb576-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="co"># Probability density</span></span>
<span id="cb576-6"><a href="r-for-statistical-inference.html#cb576-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">8</span>), <span class="co"># Range for the x-axis</span></span>
<span id="cb576-7"><a href="r-for-statistical-inference.html#cb576-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;blue&quot;</span> <span class="co"># Color to fill the bars</span></span>
<span id="cb576-8"><a href="r-for-statistical-inference.html#cb576-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-225-1.png" width="672" /></p>
<p>R also allows to compute kernel density estimates via the <code>density()</code> function.</p>
<div class="sourceCode" id="cb577"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb577-1"><a href="r-for-statistical-inference.html#cb577-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">density</span>(iris<span class="sc">$</span>Sepal.Length))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-226-1.png" width="672" /></p>
<p>We can combine our two previous plots using <code>lines()</code> as follows:</p>
<div class="sourceCode" id="cb578"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb578-1"><a href="r-for-statistical-inference.html#cb578-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(iris<span class="sc">$</span>Sepal.Length,</span>
<span id="cb578-2"><a href="r-for-statistical-inference.html#cb578-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">breaks =</span> <span class="dv">15</span>, <span class="co"># Number of cells in the histogram</span></span>
<span id="cb578-3"><a href="r-for-statistical-inference.html#cb578-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Histogram of Sepal Lenght&quot;</span>, <span class="co"># Main tittle</span></span>
<span id="cb578-4"><a href="r-for-statistical-inference.html#cb578-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Sepal Lenght&quot;</span>, <span class="co"># Text on the x-axis</span></span>
<span id="cb578-5"><a href="r-for-statistical-inference.html#cb578-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">freq =</span> <span class="cn">FALSE</span>, <span class="co"># Probability density</span></span>
<span id="cb578-6"><a href="r-for-statistical-inference.html#cb578-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">8</span>), <span class="co"># Range for the x-axis</span></span>
<span id="cb578-7"><a href="r-for-statistical-inference.html#cb578-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;blue&quot;</span> <span class="co"># Color to fill the bars</span></span>
<span id="cb578-8"><a href="r-for-statistical-inference.html#cb578-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb578-9"><a href="r-for-statistical-inference.html#cb578-9" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(<span class="fu">density</span>(iris<span class="sc">$</span>Sepal.Length),</span>
<span id="cb578-10"><a href="r-for-statistical-inference.html#cb578-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">lwd =</span> <span class="dv">3</span>, <span class="co"># Line width</span></span>
<span id="cb578-11"><a href="r-for-statistical-inference.html#cb578-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;red&quot;</span> <span class="co"># Color of the line</span></span>
<span id="cb578-12"><a href="r-for-statistical-inference.html#cb578-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-227-1.png" width="672" /></p>
</div>
<div id="box-plots" class="section level4 unnumbered hasAnchor">
<h4>Box plots<a href="r-for-statistical-inference.html#box-plots" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>To produce box plots, R uses the <code>boxplot()</code> function. Let us try an example with the <code>iris</code> data set:</p>
<div class="sourceCode" id="cb579"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb579-1"><a href="r-for-statistical-inference.html#cb579-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(iris<span class="sc">$</span>Sepal.Length)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-228-1.png" width="672" /></p>
<p>We can create box plots for the different (numeric) columns of <code>iris</code> at the same time:</p>
<div class="sourceCode" id="cb580"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb580-1"><a href="r-for-statistical-inference.html#cb580-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(iris[, <span class="sc">-</span><span class="dv">5</span>])</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-229-1.png" width="672" /></p>
<p>Let us now customize the above plot:</p>
<div class="sourceCode" id="cb581"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb581-1"><a href="r-for-statistical-inference.html#cb581-1" aria-hidden="true" tabindex="-1"></a><span class="fu">boxplot</span>(iris[, <span class="sc">-</span><span class="dv">5</span>],</span>
<span id="cb581-2"><a href="r-for-statistical-inference.html#cb581-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Box plot - Iris data set&quot;</span>,</span>
<span id="cb581-3"><a href="r-for-statistical-inference.html#cb581-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">names =</span> <span class="fu">c</span>(</span>
<span id="cb581-4"><a href="r-for-statistical-inference.html#cb581-4" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Sepal length&quot;</span>, <span class="st">&quot;Sepal width&quot;</span>,</span>
<span id="cb581-5"><a href="r-for-statistical-inference.html#cb581-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">&quot;Petal length&quot;</span>, <span class="st">&quot;Petal width&quot;</span></span>
<span id="cb581-6"><a href="r-for-statistical-inference.html#cb581-6" aria-hidden="true" tabindex="-1"></a>  ), <span class="co"># Change names of x axis</span></span>
<span id="cb581-7"><a href="r-for-statistical-inference.html#cb581-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;green&quot;</span></span>
<span id="cb581-8"><a href="r-for-statistical-inference.html#cb581-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-230-1.png" width="672" /></p>
</div>
<div id="scatter-plots" class="section level4 unnumbered hasAnchor">
<h4>Scatter plots<a href="r-for-statistical-inference.html#scatter-plots" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Scatter plots can help us to visualize the relationship between the different data columns. We can use the <code>plot()</code> function to create a scatter plot. For instance, below, we plot Sepal Length against Petal Length:</p>
<div class="sourceCode" id="cb582"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb582-1"><a href="r-for-statistical-inference.html#cb582-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris<span class="sc">$</span>Sepal.Length, iris<span class="sc">$</span>Petal.Length,</span>
<span id="cb582-2"><a href="r-for-statistical-inference.html#cb582-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">panel.first =</span> <span class="fu">grid</span>(<span class="dv">8</span>, <span class="dv">8</span>), <span class="co"># Adds a 8x8 grid</span></span>
<span id="cb582-3"><a href="r-for-statistical-inference.html#cb582-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">cex =</span> <span class="fl">1.2</span>, <span class="co"># Size of the dots</span></span>
<span id="cb582-4"><a href="r-for-statistical-inference.html#cb582-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb582-5"><a href="r-for-statistical-inference.html#cb582-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Sepal length&quot;</span>,</span>
<span id="cb582-6"><a href="r-for-statistical-inference.html#cb582-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Petal length&quot;</span>,</span>
<span id="cb582-7"><a href="r-for-statistical-inference.html#cb582-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Iris - Sepal length and petal length&quot;</span></span>
<span id="cb582-8"><a href="r-for-statistical-inference.html#cb582-8" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-231-1.png" width="672" /></p>
<p>Finally, for data with several columns, we can plot them all at once:</p>
<div class="sourceCode" id="cb583"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb583-1"><a href="r-for-statistical-inference.html#cb583-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(iris[, <span class="sc">-</span><span class="dv">5</span>],</span>
<span id="cb583-2"><a href="r-for-statistical-inference.html#cb583-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>,</span>
<span id="cb583-3"><a href="r-for-statistical-inference.html#cb583-3" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-232-1.png" width="672" /></p>
</div>
</div>
</div>
<div id="probability-distributions" class="section level2 hasAnchor" number="2.2">
<h2><span class="header-section-number">2.2</span> Probability distributions<a href="r-for-statistical-inference.html#probability-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>R comes with several parametric probability distributions that can help us to describe our data. Every distribution in R has four functions, which can be called by using the <em>root</em> name of the distribution (e.g., <code>exp</code>) preceded by one of the following letters:</p>
<ul>
<li><p><code>d</code>: The probability density function (pdf).</p></li>
<li><p><code>p</code>: The cumulative distribution function (cdf).</p></li>
<li><p><code>q</code>: Quantile.</p></li>
<li><p><code>r</code>: Random generator for the specified distribution.</p></li>
</ul>
<p>For instance, the exponential distribution has the four functions: <code>dexp()</code>, <code>pexp()</code>, <code>qexp()</code> and <code>rexp()</code>.</p>
<p>Table <a href="r-for-statistical-inference.html#tab:contdist">2.1</a> shows the continuous distributions, and Table <a href="r-for-statistical-inference.html#tab:disdist">2.2</a> the discrete distributions available by default in R. Note, however, that these two lists are far from comprehensive since there are several other distributions not contained there. Fortunately, other distributions may be available in different packages. For example, an implementation for the Pareto distribution can be found in the <code>actuar</code> R package.</p>
<table>
<caption><span id="tab:contdist">Table 2.1: </span>Continuous distributions.</caption>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="left">Root name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Beta</td>
<td align="left">beta</td>
</tr>
<tr class="even">
<td align="left">Cauchy</td>
<td align="left">cauchy</td>
</tr>
<tr class="odd">
<td align="left">Chi-2</td>
<td align="left">chisq</td>
</tr>
<tr class="even">
<td align="left">Exponential</td>
<td align="left">exp</td>
</tr>
<tr class="odd">
<td align="left">Fisher F</td>
<td align="left">f</td>
</tr>
<tr class="even">
<td align="left">Gamma</td>
<td align="left">gamma</td>
</tr>
<tr class="odd">
<td align="left">Logistic</td>
<td align="left">logis</td>
</tr>
<tr class="even">
<td align="left">Lognormal</td>
<td align="left">lnorm</td>
</tr>
<tr class="odd">
<td align="left">Normal</td>
<td align="left">norm</td>
</tr>
<tr class="even">
<td align="left">Student t</td>
<td align="left">t</td>
</tr>
<tr class="odd">
<td align="left">Uniform</td>
<td align="left">unif</td>
</tr>
<tr class="even">
<td align="left">Weibull</td>
<td align="left">weibull</td>
</tr>
</tbody>
</table>
<table>
<caption><span id="tab:disdist">Table 2.2: </span>Discrete distributions.</caption>
<thead>
<tr class="header">
<th align="left">Distribution</th>
<th align="left">Root name</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Binomial</td>
<td align="left">binom</td>
</tr>
<tr class="even">
<td align="left">Geometric</td>
<td align="left">geom</td>
</tr>
<tr class="odd">
<td align="left">Hypergeometric</td>
<td align="left">hyper</td>
</tr>
<tr class="even">
<td align="left">Negative Binomial</td>
<td align="left">nbinom</td>
</tr>
<tr class="odd">
<td align="left">Poisson</td>
<td align="left">pois</td>
</tr>
</tbody>
</table>
<div class="remark">
<p><span id="unlabeled-div-25" class="remark"><em>Remark</em>. </span>When using these R built-in functions, we must be careful and check the parametric form implemented for these distributions since they may differ from the ones we are familiar with. For instance, in R, the pdf of the Gamma distribution has two parametrizations (see help - <code>?pgamma</code>). The first one is</p>
<p><span class="math display">\[
f(x) = \frac{1}{\sigma^\alpha \Gamma(\alpha)} x^{\alpha-1} e^{-x/\sigma} \,, \quad x\ge 0\,,
\]</span>
where <span class="math inline">\(\alpha&gt;0\)</span> and <span class="math inline">\(\sigma&gt;0\)</span> and is accessible by using the arguments <code>shape</code> (<span class="math inline">\(\alpha\)</span>) and <code>scale</code> (<span class="math inline">\(\sigma\)</span>). The second parametrization is</p>
<p><span class="math display">\[
f(x) = \frac{\lambda^\alpha}{ \Gamma(\alpha)} x^{\alpha-1} e^{-\lambda x} \,, \quad x\ge 0\,,
\]</span>
where <span class="math inline">\(\alpha&gt;0\)</span> and <span class="math inline">\(\lambda&gt;0\)</span>, which correspond to the use of the arguments <code>shape</code> (<span class="math inline">\(\alpha\)</span>) and <code>rate</code> (<span class="math inline">\(\lambda\)</span>). However, note that both representations are equivalent. Indeed, take <span class="math inline">\(s = 1/\lambda\)</span> and <span class="math inline">\(a = \alpha\)</span>.</p>
</div>
<p>We now look at some examples of how to use these functions, and we will use the normal distribution to do so. Recall that a random variable <span class="math inline">\(X\)</span> is said to be normal distributed with mean <span class="math inline">\(\mu \in \mathbb{R}\)</span> and standard deviation <span class="math inline">\(\sigma&gt;0\)</span>, if its density function is given by
<span class="math display">\[
f(x) = \frac{1}{\sigma \sqrt{2 \pi }} \exp\left({- \frac{(x - \mu)^2}{2 \sigma^2}}\right) \,, \quad x\in \mathbb{R}\,.
\]</span>
We write <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>.</p>
<p>In R, this density can be evaluated using the <code>dnorm()</code> function. For instance,</p>
<div class="sourceCode" id="cb584"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb584-1"><a href="r-for-statistical-inference.html#cb584-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="dv">1</span>) <span class="co"># mu = 0, sigma = 1</span></span></code></pre></div>
<pre><code>## [1] 0.2419707</code></pre>
<div class="sourceCode" id="cb586"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb586-1"><a href="r-for-statistical-inference.html#cb586-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dnorm</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>) <span class="co"># mu = 1, sigma = 2</span></span></code></pre></div>
<pre><code>## [1] 0.1994711</code></pre>
<p>We will now plot this density function for different combinations of parameters.
The usual way to plot a function in R is first generate a sequence of numbers, then evaluate the desired function at the generated sequence, and finally use <code>plot()</code>.</p>
<div class="sourceCode" id="cb588"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb588-1"><a href="r-for-statistical-inference.html#cb588-1" aria-hidden="true" tabindex="-1"></a>sq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb588-2"><a href="r-for-statistical-inference.html#cb588-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(sq, <span class="fu">dnorm</span>(sq), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="fl">0.85</span>), <span class="at">ylab =</span> <span class="st">&quot;f(x)&quot;</span>, <span class="at">xlab =</span> <span class="st">&quot;x&quot;</span>)</span>
<span id="cb588-3"><a href="r-for-statistical-inference.html#cb588-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq, <span class="fu">dnorm</span>(sq, <span class="dv">0</span>, <span class="fl">0.5</span>), <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span>
<span id="cb588-4"><a href="r-for-statistical-inference.html#cb588-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq, <span class="fu">dnorm</span>(sq, <span class="dv">0</span>, <span class="dv">2</span>), <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb588-5"><a href="r-for-statistical-inference.html#cb588-5" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq, <span class="fu">dnorm</span>(sq, <span class="dv">1</span>, <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&quot;green&quot;</span>)</span>
<span id="cb588-6"><a href="r-for-statistical-inference.html#cb588-6" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq, <span class="fu">dnorm</span>(sq, <span class="sc">-</span><span class="dv">1</span>, <span class="dv">1</span>), <span class="at">col =</span> <span class="st">&quot;orange&quot;</span>)</span>
<span id="cb588-7"><a href="r-for-statistical-inference.html#cb588-7" aria-hidden="true" tabindex="-1"></a><span class="fu">legend</span>(<span class="st">&quot;topright&quot;</span>,</span>
<span id="cb588-8"><a href="r-for-statistical-inference.html#cb588-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">leg =</span> <span class="fu">paste0</span>(<span class="st">&quot;mu = &quot;</span>, <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>, <span class="sc">-</span><span class="dv">1</span>), <span class="st">&quot;, sigma = &quot;</span>, <span class="fu">c</span>(<span class="dv">1</span>, <span class="fl">0.5</span>, <span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">1</span>)),</span>
<span id="cb588-9"><a href="r-for-statistical-inference.html#cb588-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">lty =</span> <span class="dv">1</span>,</span>
<span id="cb588-10"><a href="r-for-statistical-inference.html#cb588-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="fu">c</span>(<span class="st">&quot;black&quot;</span>, <span class="st">&quot;red&quot;</span>, <span class="st">&quot;blue&quot;</span>, <span class="st">&quot;green&quot;</span>, <span class="st">&quot;orange&quot;</span>)</span>
<span id="cb588-11"><a href="r-for-statistical-inference.html#cb588-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-234-1.png" width="672" /></p>
<p>Next, we consider the distribution function of <span class="math inline">\(X \sim N(\mu, \sigma^2)\)</span>. Recall that this is given by</p>
<p><span class="math display">\[
F(x) = \mathbb{P} (X \leq x) = \int_{-\infty}^x \frac{1}{\sigma \sqrt{2 \pi }} \exp\left({- \frac{(y - \mu)^2}{2 \sigma^2}}\right) dy \,.
\]</span>
To evaluate this function in R, we can use <code>pnorm()</code>. For example, if we want to find <span class="math inline">\(\mathbb{P} (X \leq 1.8)\)</span> for <span class="math inline">\(X \sim N(0, 1)\)</span>, we simply type:</p>
<div class="sourceCode" id="cb589"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb589-1"><a href="r-for-statistical-inference.html#cb589-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">1.8</span>)</span></code></pre></div>
<pre><code>## [1] 0.9640697</code></pre>
<p>Note that <code>pnorm()</code> has an optional argument <code>lower.tail</code>. By default <code>lower.tail</code> takes the value <code>TRUE</code>, indicating that <code>pnorm()</code> will compute <span class="math inline">\(\mathbb{P} (X \leq x)\)</span>. However, we can compute <span class="math inline">\(\mathbb{P} (X &gt; x) = 1 - \mathbb{P} (X \leq x)\)</span> by using <code>lower.tail = FALSE</code>. For instance,</p>
<div class="sourceCode" id="cb591"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb591-1"><a href="r-for-statistical-inference.html#cb591-1" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span> <span class="sc">-</span> <span class="fu">pnorm</span>(<span class="fl">1.8</span>)</span></code></pre></div>
<pre><code>## [1] 0.03593032</code></pre>
<div class="sourceCode" id="cb593"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb593-1"><a href="r-for-statistical-inference.html#cb593-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(<span class="fl">1.8</span>, <span class="at">lower.tail =</span> <span class="cn">FALSE</span>)</span></code></pre></div>
<pre><code>## [1] 0.03593032</code></pre>
<p>We can simulate random values following a <span class="math inline">\(N(\mu, \sigma^2)\)</span> distribution via the <code>rnorm()</code> function. For example,</p>
<div class="sourceCode" id="cb595"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb595-1"><a href="r-for-statistical-inference.html#cb595-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rnorm</span>(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>##  [1]  0.01874617 -0.18425254 -1.37133055 -0.59916772  0.29454513  0.38979430
##  [7] -1.20807618 -0.36367602 -1.62667268 -0.25647839</code></pre>
<p>Note that every time you run <code>rnorm()</code>, it will generate a different set of values:</p>
<div class="sourceCode" id="cb597"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb597-1"><a href="r-for-statistical-inference.html#cb597-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rnorm</span>(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>##  [1]  1.10177950  0.75578151 -0.23823356  0.98744470  0.74139013  0.08934727
##  [7] -0.95494386 -0.19515038  0.92552126  0.48297852</code></pre>
<p>However, sometimes it is convenient to generate the same random sequence at will. This can allow us, for example, to replicate a study. To do this, we need to give R an initial <em>seed</em> to generate the random numbers, which is done via the <code>set.seed()</code> function. For example, consider the following code</p>
<div class="sourceCode" id="cb599"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb599-1"><a href="r-for-statistical-inference.html#cb599-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb599-2"><a href="r-for-statistical-inference.html#cb599-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rnorm</span>(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>##  [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -0.8204684
##  [7]  0.4874291  0.7383247  0.5757814 -0.3053884</code></pre>
<p>Then, if we run the code above again, we will get exactly the same sequence of values:</p>
<div class="sourceCode" id="cb601"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb601-1"><a href="r-for-statistical-inference.html#cb601-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb601-2"><a href="r-for-statistical-inference.html#cb601-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rnorm</span>(<span class="dv">10</span>)</span></code></pre></div>
<pre><code>##  [1] -0.6264538  0.1836433 -0.8356286  1.5952808  0.3295078 -0.8204684
##  [7]  0.4874291  0.7383247  0.5757814 -0.3053884</code></pre>
<p>A visual way to evaluate if certain data follows a specific distribution is to compare the histogram generated by the data and the density function of the distribution. Let us look at a simple example: First, we generate a random sample following a <span class="math inline">\(N(0, 1)\)</span> distribution.</p>
<div class="sourceCode" id="cb603"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb603-1"><a href="r-for-statistical-inference.html#cb603-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb603-2"><a href="r-for-statistical-inference.html#cb603-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>)</span></code></pre></div>
<p>Now, if the data would really follow a <span class="math inline">\(N(0, 1)\)</span> distribution (which, in this case, it does by construction), the histogram of the data should be similar to the density of a <span class="math inline">\(N(0, 1)\)</span> distribution. The following plot shows precisely this:</p>
<div class="sourceCode" id="cb604"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb604-1"><a href="r-for-statistical-inference.html#cb604-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(x, <span class="at">freq =</span> F, <span class="at">main =</span> <span class="st">&quot;Histogram vs density&quot;</span>)</span>
<span id="cb604-2"><a href="r-for-statistical-inference.html#cb604-2" aria-hidden="true" tabindex="-1"></a>sq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">5</span>, <span class="dv">5</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb604-3"><a href="r-for-statistical-inference.html#cb604-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq, <span class="fu">dnorm</span>(sq), <span class="at">type =</span> <span class="st">&quot;l&quot;</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-243-1.png" width="672" /></p>
<p>Finally, we will look at the function to compute the quantiles of a distribution. Recall that for a random variable <span class="math inline">\(X\)</span> with distribution function <span class="math inline">\(F\)</span>, its quantile function <span class="math inline">\(F^{\leftarrow}\)</span> is given by
<span class="math display">\[
F^{\leftarrow}(p) = \inf \{x : p \leq F(x)  \} \,, \quad p \in [0,1] \,.
\]</span>
If the distribution function is continuous and strictly monotonic, then <span class="math inline">\(F^{\leftarrow}(p)\)</span> satisfies that
<span class="math display">\[
F(F^{\leftarrow}(p)) = p \,.
\]</span>
In other words, it corresponds to the inverse of <span class="math inline">\(F\)</span>.</p>
<p>Now, consider <span class="math inline">\(X \sim N(1, 2^2)\)</span> and suppose that we want to find <span class="math inline">\(x\)</span> such that <span class="math inline">\(P(X \leq x) = 0.95\)</span>. This can be done with the <code>qnorm()</code> function:</p>
<div class="sourceCode" id="cb605"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb605-1"><a href="r-for-statistical-inference.html#cb605-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(<span class="fl">0.95</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb605-2"><a href="r-for-statistical-inference.html#cb605-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>## [1] 4.289707</code></pre>
<div class="sourceCode" id="cb607"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb607-1"><a href="r-for-statistical-inference.html#cb607-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pnorm</span>(x, <span class="dv">1</span>, <span class="dv">2</span>) <span class="co"># Check</span></span></code></pre></div>
<pre><code>## [1] 0.95</code></pre>
<p>An alternative visual way of evaluating if our data comes from a certain distribution is to plot the sample quantiles against the theoretical quantiles of the distribution to check. This is called a QQ-plot. If the data comes from that specific distribution, then we should observe that the points form (approximately) an identity line. Let us look at an example:</p>
<div class="sourceCode" id="cb609"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb609-1"><a href="r-for-statistical-inference.html#cb609-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb609-2"><a href="r-for-statistical-inference.html#cb609-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb609-3"><a href="r-for-statistical-inference.html#cb609-3" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.01</span>, <span class="fl">0.99</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb609-4"><a href="r-for-statistical-inference.html#cb609-4" aria-hidden="true" tabindex="-1"></a>the_quantile <span class="ot">&lt;-</span> <span class="fu">qnorm</span>(p, <span class="dv">1</span>, <span class="dv">2</span>)</span>
<span id="cb609-5"><a href="r-for-statistical-inference.html#cb609-5" aria-hidden="true" tabindex="-1"></a>sam_quantile <span class="ot">&lt;-</span> <span class="fu">quantile</span>(x, p)</span>
<span id="cb609-6"><a href="r-for-statistical-inference.html#cb609-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(the_quantile, sam_quantile,</span>
<span id="cb609-7"><a href="r-for-statistical-inference.html#cb609-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;QQ plot&quot;</span>,</span>
<span id="cb609-8"><a href="r-for-statistical-inference.html#cb609-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Theoretical quantiles&quot;</span>,</span>
<span id="cb609-9"><a href="r-for-statistical-inference.html#cb609-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Sample quantiles&quot;</span></span>
<span id="cb609-10"><a href="r-for-statistical-inference.html#cb609-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb609-11"><a href="r-for-statistical-inference.html#cb609-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>) <span class="co"># Identity</span></span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-245-1.png" width="672" /></p>
<div id="tranformations" class="section level3 hasAnchor" number="2.2.1">
<h3><span class="header-section-number">2.2.1</span> Tranformations<a href="r-for-statistical-inference.html#tranformations" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Several distributions are obtained via transformations. For instance, a lognormal distributed random variable can be obtained by exponentiation of a normal distributed random variable. Here, we will illustrate how to use the previous implementations to work with transformations of random variables.</p>
<p>First, let us recall some results. Let <span class="math inline">\(Y\)</span> be a continuous random variable with density and distribution functions <span class="math inline">\(f_{Y}\)</span> and <span class="math inline">\(F_{Y}\)</span>, respectively. Now, consider a strictly increasing transformation <span class="math inline">\(g(\cdot)\)</span>, and define <span class="math inline">\(X = g(Y)\)</span>. Then, the distribution function <span class="math inline">\(F_X\)</span> of X is given by
<span class="math display">\[
F_X(x) = \mathbb{P}(X \leq x) = \mathbb{P}(g(Y) \leq x) = \mathbb{P}(Y \leq g^{-1}(x)) = F_Y(g^{-1}(x)) \,.
\]</span>
From the expression above, it follows that the density function <span class="math inline">\(f_X\)</span> of <span class="math inline">\(X\)</span> is given by
<span class="math display">\[
f_X(x) =   f_Y(g^{-1}(x)) \frac{d}{dx} (g^{-1}(x)) \,.
\]</span></p>
<p>Now, let us consider an explicit example: the lognormal distribution. Recall that a lognormal distributed random variable with parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma^2\)</span> is obtained via the transformation</p>
<p><span class="math display">\[
X = \exp(Y) \,,
\]</span>
where <span class="math inline">\(Y \sim N(\mu, \sigma^2)\)</span>. We write <span class="math inline">\(X \sim LN(\mu, \sigma^2)\)</span>. Although already implemented in R under the root name <code>lnorm</code>, we can use this distribution to illustrate how to work with transformations and, at the same time, verify our computations. Note that in this case <span class="math inline">\(g(y) = \exp(y)\)</span>, <span class="math inline">\(y \in \mathbb{R}\)</span>, and <span class="math inline">\(g^{-1}(x) = \log(x)\)</span>, <span class="math inline">\(x&gt;0\)</span>.</p>
<p>We can now compute the distribution function <span class="math inline">\(F_X(x)\)</span> of <span class="math inline">\(X \sim LN(\mu, \sigma^2)\)</span> at <span class="math inline">\(x\)</span>, by using <code>pnorm()</code> evaluated at <span class="math inline">\(g^{-1}(x) = \log(x)\)</span>. For example, for <span class="math inline">\(X \sim LN(1, 2^2)\)</span>, <span class="math inline">\(\mathbb{P}(X \leq 3)\)</span> can be computed as follows:</p>
<div class="sourceCode" id="cb610"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb610-1"><a href="r-for-statistical-inference.html#cb610-1" aria-hidden="true" tabindex="-1"></a>user_plnorm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, mu, sigma) {</span>
<span id="cb610-2"><a href="r-for-statistical-inference.html#cb610-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">pnorm</span>(<span class="fu">log</span>(x), mu, sigma)</span>
<span id="cb610-3"><a href="r-for-statistical-inference.html#cb610-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb610-4"><a href="r-for-statistical-inference.html#cb610-4" aria-hidden="true" tabindex="-1"></a><span class="fu">user_plnorm</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.5196623</code></pre>
<div class="sourceCode" id="cb612"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb612-1"><a href="r-for-statistical-inference.html#cb612-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plnorm</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>) <span class="co"># Check</span></span></code></pre></div>
<pre><code>## [1] 0.5196623</code></pre>
<p>Now for the density evaluation, we need <span class="math inline">\(\frac{d}{dx}(g^{-1}(x)) = 1/x\)</span>. Thus, the density evaluation at <span class="math inline">\(x = 3\)</span> for <span class="math inline">\(X \sim LN(1, 2^2)\)</span> can be computed as:</p>
<div class="sourceCode" id="cb614"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb614-1"><a href="r-for-statistical-inference.html#cb614-1" aria-hidden="true" tabindex="-1"></a>user_dlnorm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, mu, sigma) {</span>
<span id="cb614-2"><a href="r-for-statistical-inference.html#cb614-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dnorm</span>(<span class="fu">log</span>(x), mu, sigma) <span class="sc">/</span> x</span>
<span id="cb614-3"><a href="r-for-statistical-inference.html#cb614-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb614-4"><a href="r-for-statistical-inference.html#cb614-4" aria-hidden="true" tabindex="-1"></a><span class="fu">user_dlnorm</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.06640961</code></pre>
<div class="sourceCode" id="cb616"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb616-1"><a href="r-for-statistical-inference.html#cb616-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dlnorm</span>(<span class="dv">3</span>, <span class="dv">1</span>, <span class="dv">2</span>) <span class="co"># Check</span></span></code></pre></div>
<pre><code>## [1] 0.06640961</code></pre>
<p>In this case, since our transformation is strictly monotonic, we can compute the quantiles easily.</p>
<div class="sourceCode" id="cb618"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb618-1"><a href="r-for-statistical-inference.html#cb618-1" aria-hidden="true" tabindex="-1"></a>user_qlnorm <span class="ot">&lt;-</span> <span class="cf">function</span>(p, mu, sigma) {</span>
<span id="cb618-2"><a href="r-for-statistical-inference.html#cb618-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(<span class="fu">qnorm</span>(p, mu, sigma))</span>
<span id="cb618-3"><a href="r-for-statistical-inference.html#cb618-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb618-4"><a href="r-for-statistical-inference.html#cb618-4" aria-hidden="true" tabindex="-1"></a><span class="fu">user_qlnorm</span>(<span class="fl">0.95</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 72.94511</code></pre>
<div class="sourceCode" id="cb620"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb620-1"><a href="r-for-statistical-inference.html#cb620-1" aria-hidden="true" tabindex="-1"></a><span class="fu">qlnorm</span>(<span class="fl">0.95</span>, <span class="dv">1</span>, <span class="dv">2</span>) <span class="co"># Check</span></span></code></pre></div>
<pre><code>## [1] 72.94511</code></pre>
<p>Simulation can also be performed using the relationship <span class="math inline">\(X = \exp(Y)\)</span>:</p>
<div class="sourceCode" id="cb622"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb622-1"><a href="r-for-statistical-inference.html#cb622-1" aria-hidden="true" tabindex="-1"></a>user_rlnorm <span class="ot">&lt;-</span> <span class="cf">function</span>(n, mu, sigma) {</span>
<span id="cb622-2"><a href="r-for-statistical-inference.html#cb622-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(<span class="fu">rnorm</span>(n, mu, sigma))</span>
<span id="cb622-3"><a href="r-for-statistical-inference.html#cb622-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb622-4"><a href="r-for-statistical-inference.html#cb622-4" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb622-5"><a href="r-for-statistical-inference.html#cb622-5" aria-hidden="true" tabindex="-1"></a><span class="fu">user_rlnorm</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##  [1]  0.7765396  3.9246872  0.5110656 66.0598801  5.2541358  0.5267987
##  [7]  7.2055971 11.9013211  8.5982845  1.4758340</code></pre>
<p>In this very particular case, we can check that our simulation is correct by using <code>rlnorm()</code>:</p>
<div class="sourceCode" id="cb624"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb624-1"><a href="r-for-statistical-inference.html#cb624-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb624-2"><a href="r-for-statistical-inference.html#cb624-2" aria-hidden="true" tabindex="-1"></a><span class="fu">rlnorm</span>(<span class="dv">10</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>##  [1]  0.7765396  3.9246872  0.5110656 66.0598801  5.2541358  0.5267987
##  [7]  7.2055971 11.9013211  8.5982845  1.4758340</code></pre>
</div>
<div id="law-of-large-numbers-and-central-limit-theorem" class="section level3 hasAnchor" number="2.2.2">
<h3><span class="header-section-number">2.2.2</span> Law of large numbers and central limit theorem<a href="r-for-statistical-inference.html#law-of-large-numbers-and-central-limit-theorem" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now recall two important results in probability theory and illustrate them using R, namely the <em>Law of Large Numbers</em> and the <em>Central Limit Theorem</em>. We start with the Law of Large Numbers:</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-26" class="theorem"><strong>Theorem 2.1  </strong></span>Let <span class="math inline">\(X_1,X_2,\dots\)</span> be a sequence of i.i.d. random variables such that <span class="math inline">\(\mathbb{E}[X_1]=\mu&lt;\infty\)</span>. Then, for any <span class="math inline">\(\epsilon &gt;0\)</span>
<span class="math display">\[
\underset{n\rightarrow \infty}{\lim}\mathbb{P}(|\bar{X}_n-\mu|\geq \epsilon)=0 \,,
\]</span>
where <span class="math inline">\(\bar{X}_n = n^{-1}\sum_{i = 1}^n X_i\)</span> denotes the sample mean.
In other words, as the sample size <span class="math inline">\(n\)</span> increases, the probability that the sample mean <span class="math inline">\(\bar{X}_n\)</span> is different from the population mean <span class="math inline">\(\mu\)</span> converges to zero.</p>
</div>
<p>We now illustrate this result via a simulation:</p>
<div class="sourceCode" id="cb626"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb626-1"><a href="r-for-statistical-inference.html#cb626-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">1000</span></span>
<span id="cb626-2"><a href="r-for-statistical-inference.html#cb626-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">cumsum</span>(<span class="fu">rnorm</span>(n)) <span class="sc">/</span> <span class="dv">1</span><span class="sc">:</span>n,</span>
<span id="cb626-3"><a href="r-for-statistical-inference.html#cb626-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Sample size&quot;</span>,</span>
<span id="cb626-4"><a href="r-for-statistical-inference.html#cb626-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Sample mean&quot;</span>,</span>
<span id="cb626-5"><a href="r-for-statistical-inference.html#cb626-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;darkgray&quot;</span></span>
<span id="cb626-6"><a href="r-for-statistical-inference.html#cb626-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb626-7"><a href="r-for-statistical-inference.html#cb626-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-251-1.png" width="672" /></p>
<p>In the figure above, we can observe that as the sample size increases, the sample mean gets closer to the population mean (zero).
Next, we recall the Central Limit Theorem:</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-27" class="theorem"><strong>Theorem 2.2  </strong></span>Let <span class="math inline">\(X_1,X_2,\ldots\)</span> be a sequence of i.i.d. random variables with a finite expected value <span class="math inline">\(\mathbb{E}[X_1]=\mu&lt;\infty\)</span> and variance <span class="math inline">\(\mbox{Var}(X_1)= \sigma^2 &lt;\infty\)</span>. Now, let <span class="math inline">\(Z_n\)</span> be the standardized mean given by
<span class="math display">\[
Z_n:=\frac{\bar{X}_n-\mu}{\sigma/\sqrt{n}}.
\]</span>
Then, for <span class="math inline">\(n\)</span> sufficiently large,
<span class="math display">\[
Z_n\simeq N(0,1).
\]</span>
Or equivalently,
<span class="math display">\[
\bar{X}_n\simeq N(\mu,\sigma^2/n)\,,\quad
\]</span>
In other words, for sufficiently large <span class="math inline">\(n\)</span>, the sample mean <span class="math inline">\(\bar{X}_n\)</span> is close to being normal distributed with mean <span class="math inline">\(\mu\)</span> and variance <span class="math inline">\(\sigma^2/n\)</span>.</p>
</div>
<p>Let us exemplify this result via a simulation study. The idea is as follows: consider a sample of size <span class="math inline">\(n\)</span> from an exponential distributed random variable with mean <span class="math inline">\(1/\lambda\)</span>. If we were to observe several samples of size <span class="math inline">\(n\)</span> from this distribution, let’s say <span class="math inline">\(p\)</span> samples, and compute <span class="math inline">\(Z_n^{(j)}\)</span> for each sample <span class="math inline">\(j = 1,\dots, p\)</span>, then for <span class="math inline">\(n\)</span> large enough <span class="math inline">\(Z_n^{(j)}\)</span>, <span class="math inline">\(j = 1,\dots, p\)</span>, should be approximately a sample from a standard normal distributed random variable. We could then check if <span class="math inline">\(Z_n^{(j)}\)</span>, <span class="math inline">\(j = 1,\dots, p\)</span> is truly normal distributed via, e.g., a QQ-plot. Let us try this, with <span class="math inline">\(n = 10\)</span>, <span class="math inline">\(p = 500\)</span> and <span class="math inline">\(\lambda = 0.5\)</span>:</p>
<div class="sourceCode" id="cb627"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb627-1"><a href="r-for-statistical-inference.html#cb627-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">10</span> <span class="co"># Sample size</span></span>
<span id="cb627-2"><a href="r-for-statistical-inference.html#cb627-2" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="dv">500</span> <span class="co"># Replications of the experiment</span></span>
<span id="cb627-3"><a href="r-for-statistical-inference.html#cb627-3" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">0.5</span></span>
<span id="cb627-4"><a href="r-for-statistical-inference.html#cb627-4" aria-hidden="true" tabindex="-1"></a>sim_exp <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">rexp</span>(n <span class="sc">*</span> p, lambda), p, n) <span class="co"># Simulations in matrix form</span></span>
<span id="cb627-5"><a href="r-for-statistical-inference.html#cb627-5" aria-hidden="true" tabindex="-1"></a>samp_mean <span class="ot">&lt;-</span> <span class="fu">apply</span>(sim_exp, <span class="dv">1</span>, mean) <span class="co"># Sample mean for each replication</span></span>
<span id="cb627-6"><a href="r-for-statistical-inference.html#cb627-6" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> lambda <span class="co"># Population mean</span></span>
<span id="cb627-7"><a href="r-for-statistical-inference.html#cb627-7" aria-hidden="true" tabindex="-1"></a>sigma2 <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> lambda<span class="sc">^</span><span class="dv">2</span> <span class="co"># Population variance</span></span>
<span id="cb627-8"><a href="r-for-statistical-inference.html#cb627-8" aria-hidden="true" tabindex="-1"></a>std_mean <span class="ot">&lt;-</span> (samp_mean <span class="sc">-</span> mu) <span class="sc">/</span> (<span class="fu">sqrt</span>(sigma2 <span class="sc">/</span> n)) <span class="co"># Standardized mean (Z_n)</span></span>
<span id="cb627-9"><a href="r-for-statistical-inference.html#cb627-9" aria-hidden="true" tabindex="-1"></a><span class="fu">qqnorm</span>(std_mean, <span class="at">main =</span> <span class="st">&quot;Normal QQ plot - n = 10&quot;</span>) <span class="co"># QQ-plot with standard normal</span></span>
<span id="cb627-10"><a href="r-for-statistical-inference.html#cb627-10" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-252-1.png" width="672" /></p>
<p>In the figure above, we observe that <span class="math inline">\(Z_n\)</span> is not standard normal distributed (yet). However, if we now consider <span class="math inline">\(n = 1000\)</span>, the conclusion changes (see figure below).</p>
<p><img src="_main_files/figure-html/unnamed-chunk-253-1.png" width="672" /></p>
</div>
</div>
<div id="parinf" class="section level2 hasAnchor" number="2.3">
<h2><span class="header-section-number">2.3</span> Parametric inference<a href="r-for-statistical-inference.html#parinf" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In the last section, we presented some distributions in R that can be used to model our data. However, so far, we have not covered how to fit these models to given data, which is essential for their application in insurance and finance. Therefore, this section aims to present some estimation methods available.</p>
<div id="maximum-likelihood-estimation" class="section level3 hasAnchor" number="2.3.1">
<h3><span class="header-section-number">2.3.1</span> Maximum likelihood estimation<a href="r-for-statistical-inference.html#maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Let <span class="math inline">\(\boldsymbol{X} = (X_1, \dots, X_n)\)</span> be a random sample such that <span class="math inline">\(X_i\)</span> are i.i.d. random variables with common distribution function <span class="math inline">\(F(\cdot; \boldsymbol{\theta})\)</span>, where <span class="math inline">\(\boldsymbol{\theta} = (\theta_1,\dots,\theta_d) \in \boldsymbol{\Theta} \subset \mathbb{R}^d\)</span>. Here, <span class="math inline">\(\boldsymbol{\Theta}\)</span> is known as the parameter space. Given an observed data sample <span class="math inline">\(\mathbf{x} = (x_1, \dots, x_n)\)</span> from <span class="math inline">\(\boldsymbol{X}\)</span>, the <em>likelihood function</em> <span class="math inline">\(L\)</span> is defined as the joint density (as a function of <span class="math inline">\(\boldsymbol{\theta}\)</span>) evaluated at <span class="math inline">\(\mathbf{x}\)</span>, that is,</p>
<p><span class="math display">\[
L(\boldsymbol{\theta}; \mathbf{x})= f_{\boldsymbol{X}} (\mathbf{x}; \boldsymbol{\theta})  = \prod_{i = 1}^{n} f(x_i; \boldsymbol{\theta}) \,.
\]</span>
The <em>maximum likelihood estimator</em> (MLE) is defined as the value of <span class="math inline">\(\boldsymbol{\theta}\)</span> that maximizes the likelihood function, that is,</p>
<p><span class="math display">\[
\hat{\boldsymbol{\theta}} = \mathrm{arg\,max}_{\boldsymbol{\theta} \in \boldsymbol{\Theta}} L(\boldsymbol{\theta}; \mathbf{x}) = \mathrm{arg\,max}_{\boldsymbol{\theta} \in \boldsymbol{\Theta}} \prod_{i = 1}^{n} f(x_i; \boldsymbol{\theta}) \,.
\]</span></p>
<p>In practice, it is often more convenient to work with the <em>loglikelihood function</em> <span class="math inline">\(l\)</span>, which is obtained by taking <span class="math inline">\(\log\)</span> of the likelihood function, i.e.,
<span class="math display">\[
l(\mathbf{x}, \boldsymbol{\theta}) = \log(L(\boldsymbol{\theta}; \mathbf{x})) = \sum_{i = 1}^{n} \log\left(f(x_i; \boldsymbol{\theta}) \right) \,.
\]</span>
Since <span class="math inline">\(\log\)</span> is an increasing continuous function, maximizing the loglikelihood is equivalent to maximizing the likelihood. In other words,
<span class="math display">\[
\hat{\boldsymbol{\theta}} = \mathrm{arg\,max}_{\boldsymbol{\theta} \in \boldsymbol{\Theta}} l(\boldsymbol{\theta}; \mathbf{x}) = \mathrm{arg\,max}_{\boldsymbol{\theta} \in \boldsymbol{\Theta}} \sum_{i = 1}^{n} \log(f(x_i; \boldsymbol{\theta})) \,.
\]</span>
Lets us now give some examples of how to implement loglikelihood functions in R. We start by considering the exponential distribution. First, we simulate a sample following this distribution:</p>
<div class="sourceCode" id="cb628"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb628-1"><a href="r-for-statistical-inference.html#cb628-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb628-2"><a href="r-for-statistical-inference.html#cb628-2" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb628-3"><a href="r-for-statistical-inference.html#cb628-3" aria-hidden="true" tabindex="-1"></a>x_exp <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">1000</span>, lambda)</span></code></pre></div>
<p>The following implementation computes the loglikelihood, assuming exponential distributed observations, for different parameters:</p>
<div class="sourceCode" id="cb629"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb629-1"><a href="r-for-statistical-inference.html#cb629-1" aria-hidden="true" tabindex="-1"></a>loglik_exp <span class="ot">&lt;-</span> <span class="cf">function</span>(x, lambda) {</span>
<span id="cb629-2"><a href="r-for-statistical-inference.html#cb629-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dexp</span>(x, lambda)))</span>
<span id="cb629-3"><a href="r-for-statistical-inference.html#cb629-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Given that our data originally comes from an exponential distribution with <span class="math inline">\(\lambda = 1.5\)</span>, we expect that values close to <span class="math inline">\(1.5\)</span> return larger values.</p>
<div class="sourceCode" id="cb630"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb630-1"><a href="r-for-statistical-inference.html#cb630-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_exp</span>(x_exp, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] -1036.915</code></pre>
<div class="sourceCode" id="cb632"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb632-1"><a href="r-for-statistical-inference.html#cb632-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_exp</span>(x_exp, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] -687.5351</code></pre>
<p>Moreover, we can plot the loglikelihood as a function of <span class="math inline">\(\lambda\)</span>. To do so, we need to modify our loglikelihood implementation above to work with vector inputs for the parameter. Otherwise, we will obtain only one incorrect evaluation:</p>
<div class="sourceCode" id="cb634"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb634-1"><a href="r-for-statistical-inference.html#cb634-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_exp</span>(x_exp, <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] -865.5976</code></pre>
<p>Note that the above is in fact is computing</p>
<div class="sourceCode" id="cb636"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb636-1"><a href="r-for-statistical-inference.html#cb636-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_exp</span>(x_exp[<span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>) <span class="sc">-</span> <span class="dv">1</span>], <span class="fl">0.5</span>) <span class="sc">+</span> <span class="fu">loglik_exp</span>(x_exp[<span class="dv">2</span> <span class="sc">*</span> (<span class="dv">1</span><span class="sc">:</span><span class="dv">500</span>)], <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] -865.5976</code></pre>
<p>due to the recycling of information that R performs. One possible way to modify the function to work with vectors is the following:</p>
<div class="sourceCode" id="cb638"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb638-1"><a href="r-for-statistical-inference.html#cb638-1" aria-hidden="true" tabindex="-1"></a>loglik_exp <span class="ot">&lt;-</span> <span class="cf">function</span>(x, lambda) {</span>
<span id="cb638-2"><a href="r-for-statistical-inference.html#cb638-2" aria-hidden="true" tabindex="-1"></a>  ll <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">length</span>(lambda))</span>
<span id="cb638-3"><a href="r-for-statistical-inference.html#cb638-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(lambda)) {</span>
<span id="cb638-4"><a href="r-for-statistical-inference.html#cb638-4" aria-hidden="true" tabindex="-1"></a>    ll[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dexp</span>(x, lambda[i])))</span>
<span id="cb638-5"><a href="r-for-statistical-inference.html#cb638-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb638-6"><a href="r-for-statistical-inference.html#cb638-6" aria-hidden="true" tabindex="-1"></a>  ll</span>
<span id="cb638-7"><a href="r-for-statistical-inference.html#cb638-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>With this new implementation, we obtain:</p>
<div class="sourceCode" id="cb639"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb639-1"><a href="r-for-statistical-inference.html#cb639-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_exp</span>(x_exp, <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] -1036.9147  -687.5351</code></pre>
<p>Now, we can generate our plot.</p>
<div class="sourceCode" id="cb641"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb641-1"><a href="r-for-statistical-inference.html#cb641-1" aria-hidden="true" tabindex="-1"></a>lambda_sq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.01</span>, <span class="dv">4</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb641-2"><a href="r-for-statistical-inference.html#cb641-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(lambda_sq, <span class="fu">loglik_exp</span>(x_exp, lambda_sq),</span>
<span id="cb641-3"><a href="r-for-statistical-inference.html#cb641-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Loglikelihood&quot;</span>,</span>
<span id="cb641-4"><a href="r-for-statistical-inference.html#cb641-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;l(lambda; x)&quot;</span>,</span>
<span id="cb641-5"><a href="r-for-statistical-inference.html#cb641-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Lambda&quot;</span>,</span>
<span id="cb641-6"><a href="r-for-statistical-inference.html#cb641-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">type =</span> <span class="st">&quot;l&quot;</span></span>
<span id="cb641-7"><a href="r-for-statistical-inference.html#cb641-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb641-8"><a href="r-for-statistical-inference.html#cb641-8" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="at">v =</span> <span class="fl">1.5</span>, <span class="at">col =</span> <span class="st">&quot;red&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-261-1.png" width="672" /></p>
<p>The figure above shows that the loglikelihood is maximized around the original value <span class="math inline">\(\lambda = 1.5\)</span> (as expected).</p>
<div class="remark">
<p><span id="unlabeled-div-28" class="remark"><em>Remark</em>. </span>The process of making a scalar function work with vectors is sometimes called: vectorization of a scalar function. There are other ways to solve the same problem, and here we present two more. The first one is to use the <code>sapply()</code> function. For instance, let us consider our initial implementation of the loglikelihood:</p>
<div class="sourceCode" id="cb642"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb642-1"><a href="r-for-statistical-inference.html#cb642-1" aria-hidden="true" tabindex="-1"></a>loglik_exp <span class="ot">&lt;-</span> <span class="cf">function</span>(x, lambda) {</span>
<span id="cb642-2"><a href="r-for-statistical-inference.html#cb642-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dexp</span>(x, lambda)))</span>
<span id="cb642-3"><a href="r-for-statistical-inference.html#cb642-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can now evaluate this function in a vector using `<code>sapply()</code> as follows:</p>
<div class="sourceCode" id="cb643"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb643-1"><a href="r-for-statistical-inference.html#cb643-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sapply</span>(<span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>), loglik_exp, <span class="at">x =</span> x_exp)</span></code></pre></div>
<pre><code>## [1] -1036.9147  -687.5351</code></pre>
<p>A second way to vectorize arguments of a function is to use the <code>Vectorize()</code> function, which creates a new function with vectorized arguments. The main arguments of this function are <code>FUN</code>, which is the function we need to vectorize, and <code>vectorize.args</code>, which is a vector with the arguments’ names that we need to vectorize. Now, let us apply this function to our initial loglikelihood implementation:</p>
<div class="sourceCode" id="cb645"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb645-1"><a href="r-for-statistical-inference.html#cb645-1" aria-hidden="true" tabindex="-1"></a>loglik_exp_v <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(loglik_exp, <span class="st">&quot;lambda&quot;</span>)</span>
<span id="cb645-2"><a href="r-for-statistical-inference.html#cb645-2" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_exp_v</span>(x_exp, <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] -1036.9147  -687.5351</code></pre>
</div>
<p>Let us now consider a second example, where we have two parameters, namely a normal distribution. First, we simulate a sample:</p>
<div class="sourceCode" id="cb647"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb647-1"><a href="r-for-statistical-inference.html#cb647-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb647-2"><a href="r-for-statistical-inference.html#cb647-2" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="dv">1</span></span>
<span id="cb647-3"><a href="r-for-statistical-inference.html#cb647-3" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="dv">2</span></span>
<span id="cb647-4"><a href="r-for-statistical-inference.html#cb647-4" aria-hidden="true" tabindex="-1"></a>x_norm <span class="ot">&lt;-</span> <span class="fu">rnorm</span>(<span class="dv">1000</span>, mu, sigma)</span></code></pre></div>
<p>Next, we implement the loglikelihood:</p>
<div class="sourceCode" id="cb648"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb648-1"><a href="r-for-statistical-inference.html#cb648-1" aria-hidden="true" tabindex="-1"></a>loglik_norm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, mu, sigma) {</span>
<span id="cb648-2"><a href="r-for-statistical-inference.html#cb648-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dnorm</span>(x, mu, sigma)))</span>
<span id="cb648-3"><a href="r-for-statistical-inference.html#cb648-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Let us test our function:</p>
<div class="sourceCode" id="cb649"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb649-1"><a href="r-for-statistical-inference.html#cb649-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_norm</span>(x_norm, <span class="fl">0.5</span>, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] -3172.521</code></pre>
<div class="sourceCode" id="cb651"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb651-1"><a href="r-for-statistical-inference.html#cb651-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_norm</span>(x_norm, <span class="fl">0.5</span>, <span class="fl">1.5</span>)</span></code></pre></div>
<pre><code>## [1] -2325.996</code></pre>
<div class="sourceCode" id="cb653"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb653-1"><a href="r-for-statistical-inference.html#cb653-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_norm</span>(x_norm, <span class="fl">0.8</span>, <span class="dv">1</span>)</span></code></pre></div>
<pre><code>## [1] -3074.51</code></pre>
<div class="sourceCode" id="cb655"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb655-1"><a href="r-for-statistical-inference.html#cb655-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_norm</span>(x_norm, <span class="fl">0.8</span>, <span class="fl">1.5</span>)</span></code></pre></div>
<pre><code>## [1] -2282.435</code></pre>
<div class="sourceCode" id="cb657"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb657-1"><a href="r-for-statistical-inference.html#cb657-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_norm</span>(x_norm, <span class="fl">2.5</span>, <span class="fl">2.5</span>)</span></code></pre></div>
<pre><code>## [1] -2363.257</code></pre>
<p>Again, we can see that we obtain larger values when evaluating the function close to the real parameters <span class="math inline">\(\mu = 1\)</span> and <span class="math inline">\(\sigma = 2\)</span>.
As in the example of the exponential distribution, we need to modify the function above to work with vectors for plotting purposes.</p>
<div class="sourceCode" id="cb659"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb659-1"><a href="r-for-statistical-inference.html#cb659-1" aria-hidden="true" tabindex="-1"></a>loglik_norm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, mu, sigma) {</span>
<span id="cb659-2"><a href="r-for-statistical-inference.html#cb659-2" aria-hidden="true" tabindex="-1"></a>  ll <span class="ot">&lt;-</span> <span class="fu">rep</span>(<span class="dv">0</span>, <span class="fu">length</span>(mu))</span>
<span id="cb659-3"><a href="r-for-statistical-inference.html#cb659-3" aria-hidden="true" tabindex="-1"></a>  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="sc">:</span><span class="fu">length</span>(mu)) {</span>
<span id="cb659-4"><a href="r-for-statistical-inference.html#cb659-4" aria-hidden="true" tabindex="-1"></a>    ll[i] <span class="ot">&lt;-</span> <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dnorm</span>(x, mu[i], sigma[i])))</span>
<span id="cb659-5"><a href="r-for-statistical-inference.html#cb659-5" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb659-6"><a href="r-for-statistical-inference.html#cb659-6" aria-hidden="true" tabindex="-1"></a>  ll</span>
<span id="cb659-7"><a href="r-for-statistical-inference.html#cb659-7" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>We can now perform computations for vector arguments:</p>
<div class="sourceCode" id="cb660"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb660-1"><a href="r-for-statistical-inference.html#cb660-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_norm</span>(x_norm, <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] -2147.143 -2277.967</code></pre>
<p>With this implementation at hand, we can now create a surface plot for the loglikelihood. To that end, we need to create a grid of evaluation points and evaluate our loglikelihood at the generated points. This can be done as follows using the <code>outer()</code> function:</p>
<div class="sourceCode" id="cb662"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb662-1"><a href="r-for-statistical-inference.html#cb662-1" aria-hidden="true" tabindex="-1"></a>mu_sq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.75</span>, <span class="fl">1.5</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb662-2"><a href="r-for-statistical-inference.html#cb662-2" aria-hidden="true" tabindex="-1"></a>sigma_sq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.75</span>, <span class="fl">2.5</span>, <span class="at">by =</span> <span class="fl">0.05</span>)</span>
<span id="cb662-3"><a href="r-for-statistical-inference.html#cb662-3" aria-hidden="true" tabindex="-1"></a>ll_eval <span class="ot">&lt;-</span> <span class="fu">outer</span>(mu_sq, sigma_sq, loglik_norm, <span class="at">x =</span> x_norm) <span class="co"># Evaluates the LogLik at all points</span></span>
<span id="cb662-4"><a href="r-for-statistical-inference.html#cb662-4" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(mu_sq, sigma_sq, ll_eval,</span>
<span id="cb662-5"><a href="r-for-statistical-inference.html#cb662-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">phi =</span> <span class="dv">20</span>,</span>
<span id="cb662-6"><a href="r-for-statistical-inference.html#cb662-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">theta =</span> <span class="dv">45</span>,</span>
<span id="cb662-7"><a href="r-for-statistical-inference.html#cb662-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">ticktype =</span> <span class="st">&quot;detailed&quot;</span>,</span>
<span id="cb662-8"><a href="r-for-statistical-inference.html#cb662-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;mu&quot;</span>,</span>
<span id="cb662-9"><a href="r-for-statistical-inference.html#cb662-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;sigma&quot;</span>,</span>
<span id="cb662-10"><a href="r-for-statistical-inference.html#cb662-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">zlab =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb662-11"><a href="r-for-statistical-inference.html#cb662-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Loglikelihood&quot;</span></span>
<span id="cb662-12"><a href="r-for-statistical-inference.html#cb662-12" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-270-1.png" width="672" style="display: block; margin: auto;" /></p>
<div class="remark">
<p><span id="unlabeled-div-29" class="remark"><em>Remark</em>. </span>As in the exponential case, we have two alternative methods of evaluating the loglikelihood when passing vector inputs. The first one is to use the `<code>mapply()</code> function, which is a multivariate version of <code>sapply()</code>. Let us consider our initial implementation of the loglikelihood:</p>
<div class="sourceCode" id="cb663"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb663-1"><a href="r-for-statistical-inference.html#cb663-1" aria-hidden="true" tabindex="-1"></a>loglik_norm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, mu, sigma) {</span>
<span id="cb663-2"><a href="r-for-statistical-inference.html#cb663-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dnorm</span>(x, mu, sigma)))</span>
<span id="cb663-3"><a href="r-for-statistical-inference.html#cb663-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Then, we can evaluate this function in vector parameters using <code>mapply()</code> as follows:</p>
<div class="sourceCode" id="cb664"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb664-1"><a href="r-for-statistical-inference.html#cb664-1" aria-hidden="true" tabindex="-1"></a><span class="fu">mapply</span>(loglik_norm, <span class="at">mu =</span> <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="at">sigma =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>), <span class="at">MoreArgs =</span> <span class="fu">list</span>(<span class="at">x =</span> x_norm))</span></code></pre></div>
<pre><code>## [1] -2147.143 -2277.967</code></pre>
<p>The second way to vectorize the arguments of our loglikelihood function is to use <code>Vectorize()</code> as follows:</p>
<div class="sourceCode" id="cb666"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb666-1"><a href="r-for-statistical-inference.html#cb666-1" aria-hidden="true" tabindex="-1"></a>loglik_norm_v <span class="ot">&lt;-</span> <span class="fu">Vectorize</span>(loglik_norm, <span class="fu">c</span>(<span class="st">&quot;mu&quot;</span>, <span class="st">&quot;sigma&quot;</span>))</span>
<span id="cb666-2"><a href="r-for-statistical-inference.html#cb666-2" aria-hidden="true" tabindex="-1"></a><span class="fu">loglik_norm_v</span>(x_norm, <span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span></code></pre></div>
<pre><code>## [1] -2147.143 -2277.967</code></pre>
</div>
<div id="maximization" class="section level4 unnumbered hasAnchor">
<h4>Maximization<a href="r-for-statistical-inference.html#maximization" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Our next step to finding the MLE is to maximize the loglikelihood with respect to the parameters. In R, this can be done by using <code>optim()</code>, which is a function that performs minimization. Nevertheless, remember that maximizing a function is equivalent to minimizing the negative of that function. Thus, we need to work with the negative loglikelihood in order to use <code>optim()</code>. Let us exemplify the above with the exponential distribution.</p>
<p>We will consider the previous exponentially distributed sample (<code>x_exp</code>). We start by implementing the negative loglikelihood:</p>
<div class="sourceCode" id="cb668"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb668-1"><a href="r-for-statistical-inference.html#cb668-1" aria-hidden="true" tabindex="-1"></a>nloglik_exp <span class="ot">&lt;-</span> <span class="cf">function</span>(x, lambda) {</span>
<span id="cb668-2"><a href="r-for-statistical-inference.html#cb668-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dexp</span>(x, lambda)))</span>
<span id="cb668-3"><a href="r-for-statistical-inference.html#cb668-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>With this implementation at hand, we can find the MLE of <span class="math inline">\(\lambda\)</span> using <code>optim()</code>.</p>
<div class="sourceCode" id="cb669"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb669-1"><a href="r-for-statistical-inference.html#cb669-1" aria-hidden="true" tabindex="-1"></a>mle_exp <span class="ot">&lt;-</span> <span class="fu">optim</span>(</span>
<span id="cb669-2"><a href="r-for-statistical-inference.html#cb669-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">par =</span> <span class="dv">1</span>, <span class="co"># Initial value for the parameter to be optimized over</span></span>
<span id="cb669-3"><a href="r-for-statistical-inference.html#cb669-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">fn =</span> nloglik_exp, <span class="co"># Function to be minimized</span></span>
<span id="cb669-4"><a href="r-for-statistical-inference.html#cb669-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_exp <span class="co"># Further parameters</span></span>
<span id="cb669-5"><a href="r-for-statistical-inference.html#cb669-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Warning in optim(par = 1, fn = nloglik_exp, x = x_exp): one-dimensional optimization by Nelder-Mead is unreliable:
## use &quot;Brent&quot; or optimize() directly</code></pre>
<div class="sourceCode" id="cb671"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb671-1"><a href="r-for-statistical-inference.html#cb671-1" aria-hidden="true" tabindex="-1"></a>mle_exp<span class="sc">$</span>par <span class="co"># MLE - note that it is close to the original parameter</span></span></code></pre></div>
<pre><code>## [1] 1.454297</code></pre>
<div class="sourceCode" id="cb673"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb673-1"><a href="r-for-statistical-inference.html#cb673-1" aria-hidden="true" tabindex="-1"></a>mle_exp<span class="sc">$</span>value <span class="co"># Negative loglikelihood</span></span></code></pre></div>
<pre><code>## [1] 625.3576</code></pre>
<p>In this particular case, we can verify our result using the fact that the MLE for the exponential distribution has an explicit solution given by
<span class="math display">\[
\hat{\lambda} = 1 / \bar{x}_n \,.
\]</span>
With our simulated sample, we then obtain</p>
<div class="sourceCode" id="cb675"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb675-1"><a href="r-for-statistical-inference.html#cb675-1" aria-hidden="true" tabindex="-1"></a>lambda_hat <span class="ot">&lt;-</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">mean</span>(x_exp)</span>
<span id="cb675-2"><a href="r-for-statistical-inference.html#cb675-2" aria-hidden="true" tabindex="-1"></a>lambda_hat</span></code></pre></div>
<pre><code>## [1] 1.454471</code></pre>
<p>which is very close to our solution with <code>optim()</code>. The difference is because the first solution is solved using numerical methods, while the second one is a closed-form expression.</p>
<p>Let us now try the same procedure with our normal distributed sample. In this case, we require to estimate two parameters. The first step is to implement the negative loglikelihood.</p>
<div class="sourceCode" id="cb677"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb677-1"><a href="r-for-statistical-inference.html#cb677-1" aria-hidden="true" tabindex="-1"></a>nloglik_norm <span class="ot">&lt;-</span> <span class="cf">function</span>(x, par) {</span>
<span id="cb677-2"><a href="r-for-statistical-inference.html#cb677-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">-</span><span class="fu">sum</span>(<span class="fu">log</span>(<span class="fu">dnorm</span>(x, par[<span class="dv">1</span>], par[<span class="dv">2</span>])))</span>
<span id="cb677-3"><a href="r-for-statistical-inference.html#cb677-3" aria-hidden="true" tabindex="-1"></a>}</span></code></pre></div>
<p>Note that in the above function, we passed both parameters as a single argument. We need to do it this way to be able to use <code>optim()</code>.</p>
<div class="sourceCode" id="cb678"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb678-1"><a href="r-for-statistical-inference.html#cb678-1" aria-hidden="true" tabindex="-1"></a>mle_norm <span class="ot">&lt;-</span> <span class="fu">optim</span>(</span>
<span id="cb678-2"><a href="r-for-statistical-inference.html#cb678-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">par =</span> <span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">1.5</span>), <span class="co"># Initial values for the parameters to be optimized over</span></span>
<span id="cb678-3"><a href="r-for-statistical-inference.html#cb678-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">fn =</span> nloglik_norm,</span>
<span id="cb678-4"><a href="r-for-statistical-inference.html#cb678-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_norm</span>
<span id="cb678-5"><a href="r-for-statistical-inference.html#cb678-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb678-6"><a href="r-for-statistical-inference.html#cb678-6" aria-hidden="true" tabindex="-1"></a>mle_norm<span class="sc">$</span>par <span class="co"># MLE - note that it is close to the original parameter</span></span></code></pre></div>
<pre><code>## [1] 0.9779522 2.0690633</code></pre>
<div class="sourceCode" id="cb680"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb680-1"><a href="r-for-statistical-inference.html#cb680-1" aria-hidden="true" tabindex="-1"></a>mle_norm<span class="sc">$</span>value <span class="co"># Negative loglikelihood</span></span></code></pre></div>
<pre><code>## [1] 2145.906</code></pre>
<p>Again, we can verify our results using that for the normal distribution, the MLEs of <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are explicit and given by
<span class="math display">\[
\hat{\mu} = \bar{x}_n \,, \quad \hat{\sigma} = \left( n^{-1} \sum_{i = 1}^n(x_i - \bar{x}_n)^2 \right)^{1/2} \,.
\]</span>
Thus, for our simulated sample, we obtain</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="r-for-statistical-inference.html#cb682-1" aria-hidden="true" tabindex="-1"></a>mu_hat <span class="ot">&lt;-</span> <span class="fu">mean</span>(x_norm)</span>
<span id="cb682-2"><a href="r-for-statistical-inference.html#cb682-2" aria-hidden="true" tabindex="-1"></a>sigma_hat <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="fu">sum</span>((x_norm <span class="sc">-</span> <span class="fu">mean</span>(x_norm))<span class="sc">^</span><span class="dv">2</span>) <span class="sc">/</span> <span class="fu">length</span>(x_norm))</span>
<span id="cb682-3"><a href="r-for-statistical-inference.html#cb682-3" aria-hidden="true" tabindex="-1"></a>mu_hat</span></code></pre></div>
<pre><code>## [1] 0.9767037</code></pre>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="r-for-statistical-inference.html#cb684-1" aria-hidden="true" tabindex="-1"></a>sigma_hat</span></code></pre></div>
<pre><code>## [1] 2.068797</code></pre>
<p>Note that our results using <code>optim()</code> are very close to the ones obtained via the closed-form formulas.</p>
</div>
<div id="properties-of-the-mle" class="section level4 unnumbered hasAnchor">
<h4>Properties of the MLE<a href="r-for-statistical-inference.html#properties-of-the-mle" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>We now review some properties of maximum likelihood estimators. For illustration purposes, we state the results when the parameter space is a subset of <span class="math inline">\(\mathbb{R}\)</span>. However, the results can be extended to higher dimensions.</p>
<div id="consistency" class="section level5 unnumbered hasAnchor">
<h5>Consistency<a href="r-for-statistical-inference.html#consistency" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div class="theorem">
<p><span id="thm:unlabeled-div-30" class="theorem"><strong>Theorem 2.3  </strong></span>Let <span class="math inline">\(X_1,X_2,\dots\)</span> be a sequence of i.i.d. random variables with common density function <span class="math inline">\(f(\cdot;\theta)\)</span>. Then, under mild conditions, for any <span class="math inline">\(\epsilon &gt;0\)</span>
<span class="math display">\[
\underset{n\rightarrow \infty}{\lim}\mathbb{P}(|\hat{\theta}_n-\theta|\geq \epsilon)=0 \,,
\]</span>
where <span class="math inline">\(\hat{\theta}_n\)</span> is the maximum likelihood estimator of <span class="math inline">\(\theta\)</span> based on a sample of size <span class="math inline">\(n\)</span>.
In other words, as the sample size <span class="math inline">\(n\)</span> increases, the probability that the MLE <span class="math inline">\(\hat{\theta}_n\)</span> is different from the true parameter <span class="math inline">\(\theta\)</span> converges to zero.</p>
</div>
<p>Let us now illustrate this result with a simulation.</p>
<div class="sourceCode" id="cb686"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb686-1"><a href="r-for-statistical-inference.html#cb686-1" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb686-2"><a href="r-for-statistical-inference.html#cb686-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb686-3"><a href="r-for-statistical-inference.html#cb686-3" aria-hidden="true" tabindex="-1"></a>x_10 <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">10</span>, <span class="at">rate =</span> lambda)</span>
<span id="cb686-4"><a href="r-for-statistical-inference.html#cb686-4" aria-hidden="true" tabindex="-1"></a>x_100 <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">100</span>, <span class="at">rate =</span> lambda)</span>
<span id="cb686-5"><a href="r-for-statistical-inference.html#cb686-5" aria-hidden="true" tabindex="-1"></a>x_1000 <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">1000</span>, <span class="at">rate =</span> lambda)</span>
<span id="cb686-6"><a href="r-for-statistical-inference.html#cb686-6" aria-hidden="true" tabindex="-1"></a>mle_exp_10 <span class="ot">&lt;-</span> <span class="fu">suppressWarnings</span>(<span class="fu">optim</span>(<span class="at">par =</span> <span class="dv">1</span>, <span class="at">fn =</span> nloglik_exp, <span class="at">x =</span> x_10)<span class="sc">$</span>par)</span>
<span id="cb686-7"><a href="r-for-statistical-inference.html#cb686-7" aria-hidden="true" tabindex="-1"></a>mle_exp_100 <span class="ot">&lt;-</span> <span class="fu">suppressWarnings</span>(<span class="fu">optim</span>(<span class="at">par =</span> <span class="dv">1</span>, <span class="at">fn =</span> nloglik_exp, <span class="at">x =</span> x_100)<span class="sc">$</span>par)</span>
<span id="cb686-8"><a href="r-for-statistical-inference.html#cb686-8" aria-hidden="true" tabindex="-1"></a>mle_exp_1000 <span class="ot">&lt;-</span> <span class="fu">suppressWarnings</span>(<span class="fu">optim</span>(<span class="at">par =</span> <span class="dv">1</span>, <span class="at">fn =</span> nloglik_exp, <span class="at">x =</span> x_1000)<span class="sc">$</span>par)</span>
<span id="cb686-9"><a href="r-for-statistical-inference.html#cb686-9" aria-hidden="true" tabindex="-1"></a>mle_exp_10</span></code></pre></div>
<pre><code>## [1] 1.780078</code></pre>
<div class="sourceCode" id="cb688"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb688-1"><a href="r-for-statistical-inference.html#cb688-1" aria-hidden="true" tabindex="-1"></a>mle_exp_100</span></code></pre></div>
<pre><code>## [1] 1.419922</code></pre>
<div class="sourceCode" id="cb690"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb690-1"><a href="r-for-statistical-inference.html#cb690-1" aria-hidden="true" tabindex="-1"></a>mle_exp_1000</span></code></pre></div>
<pre><code>## [1] 1.480859</code></pre>
<p>We can see that as the sample size increases, the MLE gets closer to the true parameter.</p>
</div>
<div id="efficiency" class="section level5 unnumbered hasAnchor">
<h5>Efficiency<a href="r-for-statistical-inference.html#efficiency" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<div class="theorem">
<p><span id="thm:effmle" class="theorem"><strong>Theorem 2.4  </strong></span>Let <span class="math inline">\(X_1,X_2,\ldots\)</span> be a sequence of i.i.d. random variables with common density function <span class="math inline">\(f(\cdot;\theta)\)</span>. Now, let <span class="math inline">\(\hat{\theta}_n\)</span> be the maximum likelihood estimator of <span class="math inline">\(\theta\)</span> based on a sample of size <span class="math inline">\(n\)</span>. Then, under mild conditions, for <span class="math inline">\(n\)</span> sufficiently large,</p>
<p><span class="math display" id="eq:anmle">\[\begin{equation}
\sqrt{n}(\hat{\theta}_n - \theta)\simeq N(0,(\mathcal{I}(\theta))^{-1})\,,
  \tag{2.1}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\mathcal{I}(\theta)\)</span> is the Fisher information
<span class="math display">\[
\mathcal{I}(\theta) = \mathbb{E}_\theta\left[ -\frac{d^2}{d\theta^2} \log(f(X;\theta)) \right] \,.
\]</span></p>
</div>
<p>We now give an equivalent representation for <a href="r-for-statistical-inference.html#eq:anmle">(2.1)</a>. First, we define the information of the sample <span class="math inline">\(\mathcal{I}_n(\theta)\)</span> as
<span class="math display">\[
\mathcal{I}_n(\theta) = n\mathcal{I}(\theta) =  \mathbb{E}_\theta\left[ -\frac{d^2}{d\theta^2} \log(L(\theta;\mathbf{X})) \right] \,.
\]</span>
Next, we define the <em>standard error</em> <span class="math inline">\(se\)</span> as
<span class="math display">\[
se = \sqrt{1 / \mathcal{I}_n(\theta)}
\]</span>
Then, <a href="r-for-statistical-inference.html#eq:anmle">(2.1)</a> can be rewritten as</p>
<p><span class="math display" id="eq:anmle2">\[\begin{equation}
\frac{(\hat{\theta}_n - \theta)}{se}\simeq N(0,1)\,.
  \tag{2.2}
\end{equation}\]</span></p>
<p>In practice, <span class="math inline">\(\mathcal{I}_n(\theta)\)</span> can be approximated by the observed information <span class="math inline">\(\hat{\mathcal{I}}_n(\hat{\theta}_n)\)</span> given by</p>
<p><span class="math display">\[
\hat{\mathcal{I}}_n(\hat{\theta}_n) =  -\frac{d^2}{d\theta^2} \log(L(\theta;\mathbf{x}))\mid_{\theta = \hat{\theta}_n}  \,.
\]</span>
Consequently, the standard error can be approximated as <span class="math inline">\(\hat{se} = \sqrt{1 / \mathcal{I}_n(\hat{\theta}_n)}\)</span>.</p>
<p>In R, we can compute <span class="math inline">\(\hat{\mathcal{I}}_n(\hat{\theta}_n)\)</span> by using the argument <code>hessian</code> in <code>optim()</code>. For example,</p>
<div class="sourceCode" id="cb692"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb692-1"><a href="r-for-statistical-inference.html#cb692-1" aria-hidden="true" tabindex="-1"></a>mle_exp <span class="ot">&lt;-</span> <span class="fu">optim</span>(</span>
<span id="cb692-2"><a href="r-for-statistical-inference.html#cb692-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">par =</span> <span class="dv">1</span>, <span class="co"># Initial value for the parameter to be optimized over</span></span>
<span id="cb692-3"><a href="r-for-statistical-inference.html#cb692-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">fn =</span> nloglik_exp, <span class="co"># Function to be minimized</span></span>
<span id="cb692-4"><a href="r-for-statistical-inference.html#cb692-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">hessian =</span> <span class="cn">TRUE</span>, <span class="co"># Computes the Hessian</span></span>
<span id="cb692-5"><a href="r-for-statistical-inference.html#cb692-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">x =</span> x_exp <span class="co"># Further parameters</span></span>
<span id="cb692-6"><a href="r-for-statistical-inference.html#cb692-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## Warning in optim(par = 1, fn = nloglik_exp, hessian = TRUE, x = x_exp): one-dimensional optimization by Nelder-Mead is unreliable:
## use &quot;Brent&quot; or optimize() directly</code></pre>
<div class="sourceCode" id="cb694"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb694-1"><a href="r-for-statistical-inference.html#cb694-1" aria-hidden="true" tabindex="-1"></a>obs_inf_exp <span class="ot">&lt;-</span> mle_exp<span class="sc">$</span>hessian</span>
<span id="cb694-2"><a href="r-for-statistical-inference.html#cb694-2" aria-hidden="true" tabindex="-1"></a>obs_inf_exp</span></code></pre></div>
<pre><code>##          [,1]
## [1,] 472.8183</code></pre>
<p>Then, we can approximate the standard error as well.</p>
<div class="sourceCode" id="cb696"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb696-1"><a href="r-for-statistical-inference.html#cb696-1" aria-hidden="true" tabindex="-1"></a>se_exp <span class="ot">&lt;-</span> <span class="fu">sqrt</span>(<span class="dv">1</span> <span class="sc">/</span> obs_inf_exp)</span>
<span id="cb696-2"><a href="r-for-statistical-inference.html#cb696-2" aria-hidden="true" tabindex="-1"></a>se_exp</span></code></pre></div>
<pre><code>##            [,1]
## [1,] 0.04598888</code></pre>
<p>Now, we can use the asymptotic normality of the MLE to compute confidence intervals. More specifically, an <span class="math inline">\((1 -\alpha)\)</span> confidence interval for <span class="math inline">\(\theta\)</span> is given by
<span class="math display">\[
\hat{\theta}_n \pm q_{(1 -\alpha/2)}\, \hat{se} \,,
\]</span></p>
<p>where <span class="math inline">\(q_{(1 -\alpha/2)}\)</span> is the <span class="math inline">\((1 -\alpha/2)\)</span>-quantile of the standard normal distribution.</p>
</div>
<div id="further-properties-of-the-mle" class="section level5 unnumbered hasAnchor">
<h5>Further properties of the MLE<a href="r-for-statistical-inference.html#further-properties-of-the-mle" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The following theorem provides further properties of the MLE</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-31" class="theorem"><strong>Theorem 2.5  </strong></span><span class="math inline">\(\,\)</span></p>
<ol style="list-style-type: lower-alpha">
<li>Let <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> be the MLE of <span class="math inline">\(\boldsymbol{\theta}\)</span>. Then, given a function <span class="math inline">\(g : \mathbb{R}^d \to \mathbb{R}\)</span>, the MLE of <span class="math inline">\(g(\boldsymbol{\theta})\)</span> is <span class="math inline">\(g(\hat{\boldsymbol{\theta}})\)</span>. This is called the invariance property of the MLE.</li>
<li>If <span class="math inline">\(\mathbf{Y} = \mathbf{h} (\mathbf{X})\)</span>, where <span class="math inline">\(\mathbf{h}\)</span> is invertible in the domain of <span class="math inline">\(\mathbf{X}\)</span>, then the MLE based on <span class="math inline">\(\mathbf{Y}\)</span> is the same as the MLE based on <span class="math inline">\(\mathbf{X}\)</span>.</li>
</ol>
</div>
</div>
</div>
<div id="r-packages-for-mle" class="section level4 unnumbered hasAnchor">
<h4>R packages for MLE<a href="r-for-statistical-inference.html#r-packages-for-mle" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There are several R packages that include functions to perform maximum likelihood estimation. For instance, <code>EstimationTools</code>, <code>fitdistrplus</code>, and <code>MASS</code>, among others. Here, we illustrate the use of the <code>fitdistrplus</code> package.</p>
<div class="sourceCode" id="cb698"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb698-1"><a href="r-for-statistical-inference.html#cb698-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(fitdistrplus)</span></code></pre></div>
<pre><code>## Loading required package: MASS</code></pre>
<pre><code>## Loading required package: survival</code></pre>
<p>The <code>fitdistrplus</code> package comes with the <code>fitdist()</code> function to perform MLE (and other estimation methods). The distribution is specified with the argument <code>distr</code>, but the density (<code>d</code>) and distribution (<code>p</code>) functions must be available for the given distribution (see help for details <code>?fitdist</code>). Note that the argument <code>start</code> can be omitted for some distributions (the list can be found in the help); otherwise, it has to be specified. Let us give a couple of examples.</p>
<p>First, the MLE for our exponentially distributed sample:</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="r-for-statistical-inference.html#cb701-1" aria-hidden="true" tabindex="-1"></a>fit_exp <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(x_exp, <span class="at">distr =</span> <span class="st">&quot;exp&quot;</span>)</span>
<span id="cb701-2"><a href="r-for-statistical-inference.html#cb701-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_exp)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; exp &#39; by maximum likelihood 
## Parameters : 
##      estimate Std. Error
## rate 1.454471  0.0459944
## Loglikelihood:  -625.3576   AIC:  1252.715   BIC:  1257.623</code></pre>
<p>Secondly, the MLE for our normally distributed sample:</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb703-1"><a href="r-for-statistical-inference.html#cb703-1" aria-hidden="true" tabindex="-1"></a>fit_norm <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(x_norm, <span class="at">distr =</span> <span class="st">&quot;norm&quot;</span>)</span>
<span id="cb703-2"><a href="r-for-statistical-inference.html#cb703-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_norm)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; norm &#39; by maximum likelihood 
## Parameters : 
##       estimate Std. Error
## mean 0.9767037 0.06542109
## sd   2.0687965 0.04625965
## Loglikelihood:  -2145.906   AIC:  4295.811   BIC:  4305.627 
## Correlation matrix:
##      mean sd
## mean    1  0
## sd      0  1</code></pre>
<p>Note that we obtain (approximately) the same values as our implementations above.</p>
<div class="remark">
<p><span id="unlabeled-div-32" class="remark"><em>Remark</em>. </span>Another useful implementation in <code>fitdistrplus</code> is that it can generate plots to evaluate the quality of the fit by simply using the <code>plot()</code> function. For example,</p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb705-1"><a href="r-for-statistical-inference.html#cb705-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(fit_exp)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-286-1.png" width="672" /></p>
</div>
<p>Finally, we provide an example with a user-defined distribution, namely, the Gumbel distribution with location parameter <span class="math inline">\(\mu \in \mathbb{R}\)</span> and scale parameter <span class="math inline">\(\beta &gt; 0\)</span>. Recall that the density and distribution functions of this model are given by
<span class="math display">\[
f(x) = \exp\left(-\exp\left(-\frac{(x - \mu)}{\beta}\right)\right)\exp\left(-\frac{(x - \mu)}{\beta}\right) \frac{1}{\beta} \,, \quad x\in\mathbb{R} \,,
\]</span>
<span class="math display">\[
F(x) = \exp\left(-\exp\left(-\frac{(x - \mu)}{\beta}\right)\right)\,, \quad x\in\mathbb{R} \,.
\]</span>
An implementation of these functions is the following:</p>
<div class="sourceCode" id="cb706"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb706-1"><a href="r-for-statistical-inference.html#cb706-1" aria-hidden="true" tabindex="-1"></a>dgumbel <span class="ot">&lt;-</span> <span class="cf">function</span>(x, mu, beta) {</span>
<span id="cb706-2"><a href="r-for-statistical-inference.html#cb706-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>((mu <span class="sc">-</span> x) <span class="sc">/</span> beta) <span class="sc">*</span> <span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>((mu <span class="sc">-</span> x) <span class="sc">/</span> beta)) <span class="sc">/</span> beta</span>
<span id="cb706-3"><a href="r-for-statistical-inference.html#cb706-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb706-4"><a href="r-for-statistical-inference.html#cb706-4" aria-hidden="true" tabindex="-1"></a><span class="fu">dgumbel</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.1839397</code></pre>
<div class="sourceCode" id="cb708"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb708-1"><a href="r-for-statistical-inference.html#cb708-1" aria-hidden="true" tabindex="-1"></a>pgumbel <span class="ot">&lt;-</span> <span class="cf">function</span>(q, mu, beta) {</span>
<span id="cb708-2"><a href="r-for-statistical-inference.html#cb708-2" aria-hidden="true" tabindex="-1"></a>  <span class="fu">exp</span>(<span class="sc">-</span><span class="fu">exp</span>((mu <span class="sc">-</span> q) <span class="sc">/</span> beta))</span>
<span id="cb708-3"><a href="r-for-statistical-inference.html#cb708-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb708-4"><a href="r-for-statistical-inference.html#cb708-4" aria-hidden="true" tabindex="-1"></a><span class="fu">pgumbel</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">2</span>)</span></code></pre></div>
<pre><code>## [1] 0.3678794</code></pre>
<p>With these implementations at hand, we can now call <code>fitdist()</code> to perform MLE. For example, we consider the <code>groundbeef</code> data set in the <code>fitdistrplus</code> package:</p>
<div class="sourceCode" id="cb710"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb710-1"><a href="r-for-statistical-inference.html#cb710-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(groundbeef)</span></code></pre></div>
<p>Then, we fit a Gumbel distribution to the serving sizes:</p>
<div class="sourceCode" id="cb711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb711-1"><a href="r-for-statistical-inference.html#cb711-1" aria-hidden="true" tabindex="-1"></a>fit_gum <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(groundbeef<span class="sc">$</span>serving,</span>
<span id="cb711-2"><a href="r-for-statistical-inference.html#cb711-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">distr =</span> <span class="st">&quot;gumbel&quot;</span>,</span>
<span id="cb711-3"><a href="r-for-statistical-inference.html#cb711-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">start =</span> <span class="fu">list</span>(<span class="at">mu =</span> <span class="dv">1</span>, <span class="at">beta =</span> <span class="dv">2</span>)</span>
<span id="cb711-4"><a href="r-for-statistical-inference.html#cb711-4" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb711-5"><a href="r-for-statistical-inference.html#cb711-5" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_gum)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; gumbel &#39; by maximum likelihood 
## Parameters : 
##      estimate Std. Error
## mu   56.97836   1.924291
## beta 29.08311   1.431894
## Loglikelihood:  -1255.717   AIC:  2515.435   BIC:  2522.509 
## Correlation matrix:
##             mu      beta
## mu   1.0000000 0.3180636
## beta 0.3180636 1.0000000</code></pre>
</div>
</div>
<div id="adequacy-of-the-fit" class="section level3 hasAnchor" number="2.3.2">
<h3><span class="header-section-number">2.3.2</span> Adequacy of the fit<a href="r-for-statistical-inference.html#adequacy-of-the-fit" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now focus on assessing the adequacy of a fit either via graphical methods or numerical methods. To illustrate the methods, we consider the Danish fire insurance data set (<code>danishuni</code>) available in <code>fitdistrplus</code>. More specifically, we will consider the losses above 1 million danish kroner and subtract 1 million to all data points to bring the data to the origin, that is,</p>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="r-for-statistical-inference.html#cb713-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(danishuni)</span>
<span id="cb713-2"><a href="r-for-statistical-inference.html#cb713-2" aria-hidden="true" tabindex="-1"></a>danish_loss <span class="ot">&lt;-</span> danishuni<span class="sc">$</span>Loss[danishuni<span class="sc">$</span>Loss <span class="sc">&gt;</span> <span class="dv">1</span>] <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb713-3"><a href="r-for-statistical-inference.html#cb713-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(danish_loss)</span></code></pre></div>
<pre><code>##      Min.   1st Qu.    Median      Mean   3rd Qu.      Max. 
##   0.00289   0.33092   0.78178   2.39726   1.97253 262.25037</code></pre>
<p>We will consider the following potential models for the transformed data:</p>
<ol style="list-style-type: lower-alpha">
<li>Gamma - <code>gamma</code></li>
<li>Pareto - <code>pareto</code> (available in the <code>actuar</code> R package)</li>
<li>Burr - <code>burr</code> (available in the <code>actuar</code> R package)</li>
<li>Mixture of Gamma and Pareto - To be implemented</li>
</ol>
<p>The idea is to select the model that “best” describes the data from the above list.</p>
<p>First, we need to load the <code>actuar</code> package to get access to the implementations of the Pareto and Burr distributions.</p>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb715-1"><a href="r-for-statistical-inference.html#cb715-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(actuar)</span></code></pre></div>
<pre><code>## 
## Attaching package: &#39;actuar&#39;</code></pre>
<pre><code>## The following objects are masked from &#39;package:stats&#39;:
## 
##     sd, var</code></pre>
<pre><code>## The following object is masked from &#39;package:grDevices&#39;:
## 
##     cm</code></pre>
<p>We can now perform MLE for the Gamma, Pareto and Burr distributions</p>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="r-for-statistical-inference.html#cb719-1" aria-hidden="true" tabindex="-1"></a>fit_gamma <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(danish_loss,</span>
<span id="cb719-2"><a href="r-for-statistical-inference.html#cb719-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">distr =</span> <span class="st">&quot;gamma&quot;</span></span>
<span id="cb719-3"><a href="r-for-statistical-inference.html#cb719-3" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb719-4"><a href="r-for-statistical-inference.html#cb719-4" aria-hidden="true" tabindex="-1"></a>fit_burr <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(danish_loss,</span>
<span id="cb719-5"><a href="r-for-statistical-inference.html#cb719-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">distr =</span> <span class="st">&quot;burr&quot;</span>,</span>
<span id="cb719-6"><a href="r-for-statistical-inference.html#cb719-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">start =</span> <span class="fu">list</span>(<span class="at">shape1 =</span> <span class="dv">1</span>, <span class="at">shape2 =</span> <span class="dv">1</span>, <span class="at">scale =</span> <span class="dv">1</span>)</span>
<span id="cb719-7"><a href="r-for-statistical-inference.html#cb719-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb719-8"><a href="r-for-statistical-inference.html#cb719-8" aria-hidden="true" tabindex="-1"></a>fit_pareto <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(danish_loss,</span>
<span id="cb719-9"><a href="r-for-statistical-inference.html#cb719-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">distr =</span> <span class="st">&quot;pareto&quot;</span>,</span>
<span id="cb719-10"><a href="r-for-statistical-inference.html#cb719-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">start =</span> <span class="fu">list</span>(<span class="at">shape =</span> <span class="dv">1</span>, <span class="at">scale =</span> <span class="dv">1</span>)</span>
<span id="cb719-11"><a href="r-for-statistical-inference.html#cb719-11" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>To perform MLE of the mixture of Gamma and Pareto, we need to program its density and distribution functions. This is easily done using the corresponding functions for the <code>gamma</code> and <code>pareto</code> distributions:</p>
<div class="sourceCode" id="cb720"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb720-1"><a href="r-for-statistical-inference.html#cb720-1" aria-hidden="true" tabindex="-1"></a>dmgp <span class="ot">&lt;-</span> <span class="cf">function</span>(x, shapeg, rateg, shapep, scalep, prob) {</span>
<span id="cb720-2"><a href="r-for-statistical-inference.html#cb720-2" aria-hidden="true" tabindex="-1"></a>  prob <span class="sc">*</span> <span class="fu">dgamma</span>(x, shapeg, rateg) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> prob) <span class="sc">*</span> <span class="fu">dpareto</span>(x, shapep, scalep)</span>
<span id="cb720-3"><a href="r-for-statistical-inference.html#cb720-3" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb720-4"><a href="r-for-statistical-inference.html#cb720-4" aria-hidden="true" tabindex="-1"></a>pmgp <span class="ot">&lt;-</span> <span class="cf">function</span>(q, shapeg, rateg, shapep, scalep, prob) {</span>
<span id="cb720-5"><a href="r-for-statistical-inference.html#cb720-5" aria-hidden="true" tabindex="-1"></a>  prob <span class="sc">*</span> <span class="fu">pgamma</span>(q, shapeg, rateg) <span class="sc">+</span> (<span class="dv">1</span> <span class="sc">-</span> prob) <span class="sc">*</span> <span class="fu">ppareto</span>(q, shapep, scalep)</span>
<span id="cb720-6"><a href="r-for-statistical-inference.html#cb720-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb720-7"><a href="r-for-statistical-inference.html#cb720-7" aria-hidden="true" tabindex="-1"></a><span class="fu">dmgp</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.3089397</code></pre>
<div class="sourceCode" id="cb722"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb722-1"><a href="r-for-statistical-inference.html#cb722-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pmgp</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.5660603</code></pre>
<p>We can now find the MLE for the above model:</p>
<div class="sourceCode" id="cb724"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb724-1"><a href="r-for-statistical-inference.html#cb724-1" aria-hidden="true" tabindex="-1"></a>fit_mgp <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(danish_loss,</span>
<span id="cb724-2"><a href="r-for-statistical-inference.html#cb724-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">distr =</span> <span class="st">&quot;mgp&quot;</span>,</span>
<span id="cb724-3"><a href="r-for-statistical-inference.html#cb724-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">start =</span> <span class="fu">list</span>(<span class="at">shapeg =</span> <span class="dv">1</span>, <span class="at">rateg =</span> <span class="dv">1</span>, <span class="at">shapep =</span> <span class="dv">1</span>, <span class="at">scalep =</span> <span class="dv">1</span>, <span class="at">prob =</span> <span class="fl">0.5</span>),</span>
<span id="cb724-4"><a href="r-for-statistical-inference.html#cb724-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">lower =</span> <span class="dv">0</span> <span class="co"># Avoid negative values</span></span>
<span id="cb724-5"><a href="r-for-statistical-inference.html#cb724-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<div class="remark">
<p><span id="unlabeled-div-33" class="remark"><em>Remark</em>. </span>Although numerical maximization of mixture models can be done directly, aka by “brute force,” there are more efficient ways to perform MLE of these models. For example, by using the expectation-maximization (EM) algorithm.</p>
</div>
<p>Now, let us look at the results of our fits:</p>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="r-for-statistical-inference.html#cb725-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_gamma)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; gamma &#39; by maximum likelihood 
## Parameters : 
##        estimate  Std. Error
## shape 0.5506529 0.013970187
## rate  0.2296712 0.008853186
## Loglikelihood:  -3712.443   AIC:  7428.887   BIC:  7440.239 
## Correlation matrix:
##           shape      rate
## shape 1.0000000 0.6581388
## rate  0.6581388 1.0000000</code></pre>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="r-for-statistical-inference.html#cb727-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_pareto)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; pareto &#39; by maximum likelihood 
## Parameters : 
##       estimate Std. Error
## shape 1.654915  0.0906339
## scale 1.566186  0.1265238
## Loglikelihood:  -3339.701   AIC:  6683.403   BIC:  6694.755 
## Correlation matrix:
##           shape     scale
## shape 1.0000000 0.9194348
## scale 0.9194348 1.0000000</code></pre>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="r-for-statistical-inference.html#cb729-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_burr)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; burr &#39; by maximum likelihood 
## Parameters : 
##        estimate Std. Error
## shape1 1.232000 0.10508632
## shape2 1.134183 0.03620174
## scale  1.029599 0.11953332
## Loglikelihood:  -3331.881   AIC:  6669.761   BIC:  6686.789 
## Correlation matrix:
##            shape1     shape2      scale
## shape1  1.0000000 -0.8285421  0.9641895
## shape2 -0.8285421  1.0000000 -0.8099389
## scale   0.9641895 -0.8099389  1.0000000</code></pre>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="r-for-statistical-inference.html#cb731-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_mgp)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; mgp &#39; by maximum likelihood 
## Parameters : 
##          estimate Std. Error
## shapeg 5.58594329         NA
## rateg  8.40560052         NA
## shapep 1.54732512         NA
## scalep 1.50836064         NA
## prob   0.09576093         NA
## Loglikelihood:  -3327.25   AIC:  6664.501   BIC:  6692.881 
## Correlation matrix:
## [1] NA</code></pre>
<p>The first number we can look at to select a model is the likelihood. Remember that we aim to maximize the likelihood; hence we would prefer a model with the highest likelihood possible. In our case, the mixture model has the highest likelihood. However, we also need to take into account the complexity of a model. Let us explain the last point in detail: In general, statistical models with more parameters allow for more flexibility, and thus, we can expect improvements in the fits as the number of parameters increases. However, having too many parameters can result in a fit that only describes the data at hand and fails to fit additional data or predict future observations. This is known as overfitting. On the other hand, underfitting occurs when a model cannot adequately capture the underlying structure of the data. Information criteria, such as the Akaike information criterion (AIC) and the Bayesian information criterion (BIC), deal with the problem of overfitting by introducing a penalty term for the number of parameters in the model. More specifically, if we let <span class="math inline">\(\hat {L}\)</span> be the maximum value of the likelihood function, <span class="math inline">\(d\)</span> the number of parameters in our model, and <span class="math inline">\(n\)</span> the sample size, the AIC and BIC are computed as</p>
<p><span class="math display">\[ \mathrm {AIC} \,=\,2d-2\ln({\hat {L}})\]</span>
<span class="math display">\[ \mathrm {BIC} \,=\,d\log(n)-2\ln({\hat {L}})\]</span>
Given a set of candidate models for our data, the preferred model would be the one with the minimum AIC (or BIC) value. In our current example, these numbers indicate that the mixture model is still preferred.</p>
<p>We can also use visual tools to assess the quality of the fit. Let us start by plotting the histogram of the data</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="r-for-statistical-inference.html#cb733-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(danish_loss, <span class="at">freq =</span> F, <span class="at">breaks =</span> <span class="dv">30</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-297-1.png" width="672" /></p>
<p>Given that our data has losses that are quite large, in this case, it is more convenient to plot the logarithm of the data</p>
<div class="sourceCode" id="cb734"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb734-1"><a href="r-for-statistical-inference.html#cb734-1" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">log</span>(danish_loss), <span class="at">freq =</span> F, <span class="at">breaks =</span> <span class="dv">30</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-298-1.png" width="672" /></p>
<p>We now compare the histogram with the fitted distributions. Note, however, that we need to adapt our density functions accordingly to compare with the logarithm of the data by using the change of variable theorem.</p>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="r-for-statistical-inference.html#cb735-1" aria-hidden="true" tabindex="-1"></a>sq <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="sc">-</span><span class="dv">7</span>, <span class="dv">7</span>, <span class="at">by =</span> <span class="fl">0.01</span>)</span>
<span id="cb735-2"><a href="r-for-statistical-inference.html#cb735-2" aria-hidden="true" tabindex="-1"></a><span class="fu">hist</span>(<span class="fu">log</span>(danish_loss), <span class="at">freq =</span> F, <span class="at">breaks =</span> <span class="dv">30</span>)</span>
<span id="cb735-3"><a href="r-for-statistical-inference.html#cb735-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq,</span>
<span id="cb735-4"><a href="r-for-statistical-inference.html#cb735-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dgamma</span>(<span class="fu">exp</span>(sq), fit_gamma<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_gamma<span class="sc">$</span>estimate[<span class="dv">2</span>]) <span class="sc">*</span> <span class="fu">exp</span>(sq),</span>
<span id="cb735-5"><a href="r-for-statistical-inference.html#cb735-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;red&quot;</span></span>
<span id="cb735-6"><a href="r-for-statistical-inference.html#cb735-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb735-7"><a href="r-for-statistical-inference.html#cb735-7" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq,</span>
<span id="cb735-8"><a href="r-for-statistical-inference.html#cb735-8" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dpareto</span>(<span class="fu">exp</span>(sq), fit_pareto<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_pareto<span class="sc">$</span>estimate[<span class="dv">2</span>]) <span class="sc">*</span> <span class="fu">exp</span>(sq),</span>
<span id="cb735-9"><a href="r-for-statistical-inference.html#cb735-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;blue&quot;</span></span>
<span id="cb735-10"><a href="r-for-statistical-inference.html#cb735-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb735-11"><a href="r-for-statistical-inference.html#cb735-11" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(sq,</span>
<span id="cb735-12"><a href="r-for-statistical-inference.html#cb735-12" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dburr</span>(<span class="fu">exp</span>(sq), fit_burr<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_burr<span class="sc">$</span>estimate[<span class="dv">2</span>]) <span class="sc">*</span> <span class="fu">exp</span>(sq),</span>
<span id="cb735-13"><a href="r-for-statistical-inference.html#cb735-13" aria-hidden="true" tabindex="-1"></a>  <span class="at">col =</span> <span class="st">&quot;green&quot;</span></span>
<span id="cb735-14"><a href="r-for-statistical-inference.html#cb735-14" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb735-15"><a href="r-for-statistical-inference.html#cb735-15" aria-hidden="true" tabindex="-1"></a><span class="fu">lines</span>(</span>
<span id="cb735-16"><a href="r-for-statistical-inference.html#cb735-16" aria-hidden="true" tabindex="-1"></a>  sq,</span>
<span id="cb735-17"><a href="r-for-statistical-inference.html#cb735-17" aria-hidden="true" tabindex="-1"></a>  <span class="fu">dmgp</span>(<span class="fu">exp</span>(sq), fit_mgp<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">2</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">3</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">4</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">5</span>]) <span class="sc">*</span> <span class="fu">exp</span>(sq)</span>
<span id="cb735-18"><a href="r-for-statistical-inference.html#cb735-18" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-299-1.png" width="672" /></p>
<p>We observe that the density mixture distribution is closer to the histogram. Finally, we can also create QQ-plots to evaluate the fit. Notice that to create the QQ-plot of the mixture distribution, we need to implement a function to compute its quantiles. An implementation is the following:</p>
<div class="sourceCode" id="cb736"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb736-1"><a href="r-for-statistical-inference.html#cb736-1" aria-hidden="true" tabindex="-1"></a>qmgp <span class="ot">&lt;-</span> <span class="cf">function</span>(p, shapeg, rateg, shapep, scalep, prob) {</span>
<span id="cb736-2"><a href="r-for-statistical-inference.html#cb736-2" aria-hidden="true" tabindex="-1"></a>  L2 <span class="ot">&lt;-</span> <span class="cf">function</span>(q, p) {</span>
<span id="cb736-3"><a href="r-for-statistical-inference.html#cb736-3" aria-hidden="true" tabindex="-1"></a>    (p <span class="sc">-</span> <span class="fu">pmgp</span>(q, shapeg, rateg, shapep, scalep, prob))<span class="sc">^</span><span class="dv">2</span></span>
<span id="cb736-4"><a href="r-for-statistical-inference.html#cb736-4" aria-hidden="true" tabindex="-1"></a>  }</span>
<span id="cb736-5"><a href="r-for-statistical-inference.html#cb736-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">sapply</span>(p, <span class="cf">function</span>(p) <span class="fu">optimize</span>(L2, <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">10</span><span class="sc">^</span><span class="dv">3</span>), <span class="at">p =</span> p)<span class="sc">$</span>minimum)</span>
<span id="cb736-6"><a href="r-for-statistical-inference.html#cb736-6" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb736-7"><a href="r-for-statistical-inference.html#cb736-7" aria-hidden="true" tabindex="-1"></a><span class="fu">qmgp</span>(<span class="fl">0.5</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.5</span>)</span></code></pre></div>
<pre><code>## [1] 0.8064592</code></pre>
<p>We can now create the corresponding QQ-plots:</p>
<div class="sourceCode" id="cb738"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb738-1"><a href="r-for-statistical-inference.html#cb738-1" aria-hidden="true" tabindex="-1"></a>p <span class="ot">&lt;-</span> <span class="fu">seq</span>(<span class="fl">0.001</span>, <span class="fl">0.999</span>, <span class="at">by =</span> <span class="fl">0.001</span>)</span>
<span id="cb738-2"><a href="r-for-statistical-inference.html#cb738-2" aria-hidden="true" tabindex="-1"></a>danish_quant <span class="ot">&lt;-</span> <span class="fu">quantile</span>(danish_loss, p)</span>
<span id="cb738-3"><a href="r-for-statistical-inference.html#cb738-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb738-4"><a href="r-for-statistical-inference.html#cb738-4" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">2</span>))</span>
<span id="cb738-5"><a href="r-for-statistical-inference.html#cb738-5" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">qgamma</span>(p, fit_gamma<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_gamma<span class="sc">$</span>estimate[<span class="dv">2</span>]),</span>
<span id="cb738-6"><a href="r-for-statistical-inference.html#cb738-6" aria-hidden="true" tabindex="-1"></a>  danish_quant,</span>
<span id="cb738-7"><a href="r-for-statistical-inference.html#cb738-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;QQ plot - Gamma&quot;</span>,</span>
<span id="cb738-8"><a href="r-for-statistical-inference.html#cb738-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Quantiles fitted Gamma&quot;</span>,</span>
<span id="cb738-9"><a href="r-for-statistical-inference.html#cb738-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Empirical quantiles&quot;</span></span>
<span id="cb738-10"><a href="r-for-statistical-inference.html#cb738-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb738-11"><a href="r-for-statistical-inference.html#cb738-11" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb738-12"><a href="r-for-statistical-inference.html#cb738-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb738-13"><a href="r-for-statistical-inference.html#cb738-13" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">qpareto</span>(p, fit_pareto<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_pareto<span class="sc">$</span>estimate[<span class="dv">2</span>]),</span>
<span id="cb738-14"><a href="r-for-statistical-inference.html#cb738-14" aria-hidden="true" tabindex="-1"></a>  danish_quant,</span>
<span id="cb738-15"><a href="r-for-statistical-inference.html#cb738-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;QQ plot - Pareto&quot;</span>,</span>
<span id="cb738-16"><a href="r-for-statistical-inference.html#cb738-16" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Quantiles fitted Pareto&quot;</span>,</span>
<span id="cb738-17"><a href="r-for-statistical-inference.html#cb738-17" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Empirical quantiles&quot;</span></span>
<span id="cb738-18"><a href="r-for-statistical-inference.html#cb738-18" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb738-19"><a href="r-for-statistical-inference.html#cb738-19" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb738-20"><a href="r-for-statistical-inference.html#cb738-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb738-21"><a href="r-for-statistical-inference.html#cb738-21" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">qburr</span>(p, fit_burr<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_burr<span class="sc">$</span>estimate[<span class="dv">2</span>]),</span>
<span id="cb738-22"><a href="r-for-statistical-inference.html#cb738-22" aria-hidden="true" tabindex="-1"></a>  danish_quant,</span>
<span id="cb738-23"><a href="r-for-statistical-inference.html#cb738-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;QQ plot - Burr&quot;</span>,</span>
<span id="cb738-24"><a href="r-for-statistical-inference.html#cb738-24" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Quantiles fitted Burr&quot;</span>,</span>
<span id="cb738-25"><a href="r-for-statistical-inference.html#cb738-25" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Empirical quantiles&quot;</span></span>
<span id="cb738-26"><a href="r-for-statistical-inference.html#cb738-26" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb738-27"><a href="r-for-statistical-inference.html#cb738-27" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span>
<span id="cb738-28"><a href="r-for-statistical-inference.html#cb738-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb738-29"><a href="r-for-statistical-inference.html#cb738-29" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(<span class="fu">qmgp</span>(p, fit_mgp<span class="sc">$</span>estimate[<span class="dv">1</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">2</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">3</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">4</span>], fit_mgp<span class="sc">$</span>estimate[<span class="dv">5</span>]),</span>
<span id="cb738-30"><a href="r-for-statistical-inference.html#cb738-30" aria-hidden="true" tabindex="-1"></a>  danish_quant,</span>
<span id="cb738-31"><a href="r-for-statistical-inference.html#cb738-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;QQ plot - Gamma-Pareto mixture&quot;</span>,</span>
<span id="cb738-32"><a href="r-for-statistical-inference.html#cb738-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;Quantiles fitted Gamma-Pareto mixture&quot;</span>,</span>
<span id="cb738-33"><a href="r-for-statistical-inference.html#cb738-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;Empirical quantiles&quot;</span></span>
<span id="cb738-34"><a href="r-for-statistical-inference.html#cb738-34" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb738-35"><a href="r-for-statistical-inference.html#cb738-35" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="dv">0</span>, <span class="dv">1</span>, <span class="at">col =</span> <span class="st">&quot;blue&quot;</span>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-301-1.png" width="672" /></p>
<p>One of the difficulties of this data set is the large values, which make it challenging to find a model that adequately models the body and tail simultaneously. However, the problem can be split. On the one hand, one can find a model for the body of the distribution and, on the other, a model for the tail of the distribution by, for example, using Extreme value theory statistics. In fact, this data set has been analyzed extensively using Extreme Value Theory techniques.</p>
</div>
<div id="other-estimation-methods" class="section level3 hasAnchor" number="2.3.3">
<h3><span class="header-section-number">2.3.3</span> Other estimation methods<a href="r-for-statistical-inference.html#other-estimation-methods" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Although MLE is the most commonly used estimation method, we now review some alternatives, namely the methods of moments, quantile-matching, and maximum goodness-of-fit. Note that all of these methods are available in the <code>fitdistrplus</code> R package.</p>
<div id="method-of-moments" class="section level5 unnumbered hasAnchor">
<h5>Method of moments<a href="r-for-statistical-inference.html#method-of-moments" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Let <span class="math inline">\(X_1, \dots, X_n\)</span> be i.i.d. random variables with common distribution function <span class="math inline">\(F(\cdot; \boldsymbol{\theta})\)</span>, where <span class="math inline">\(\boldsymbol{\theta} = (\theta_1,\dots,\theta_d) \in \boldsymbol{\Theta} \subset \mathbb{R}^d\)</span>. Assuming that the moments up to order <span class="math inline">\(d\)</span> of <span class="math inline">\(X \sim F(\cdot; \boldsymbol{\theta})\)</span> exist, we set
<span class="math display">\[
\mu_k(\boldsymbol{\theta}) = \mathbb{E}\left[ X^k\right] = \mu_k \,, \quad k = 1,\dots, d\,.
\]</span>
In particular, this means that given <span class="math inline">\(\mu_1, \dots, \mu_d\)</span> we have <span class="math inline">\(d\)</span> nonlinear equations with <span class="math inline">\(d\)</span> unknown <span class="math inline">\(\theta\)</span>’s. Therefore, we can find <span class="math inline">\(\boldsymbol{\theta}\)</span> from the raw moments of <span class="math inline">\(X\)</span>, assuming that a unique solution exists, which is often the case. In practice, we can use the empirical raw moments <span class="math inline">\(\hat{\mu}_k\)</span> given by
<span class="math display">\[
\hat{\mu}_k = \frac{1}{n} \sum_{i = 1}^n x_i^k\,, \quad k = 1,\dots, d\,.
\]</span>
Then, the moment matching estimator <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> of <span class="math inline">\(\boldsymbol{\theta}\)</span> is the solution to
<span class="math display">\[
\mu_k({\boldsymbol{\theta}}) =  \hat{\mu_k} \,, \quad k = 1,\dots, d\,.
\]</span>
Sometimes it is more convenient to base the estimation on central moments. Let
<span class="math display">\[
m_1(\boldsymbol{\theta}) = \mathbb{E}\left[ X\right] \quad \mbox{and} \quad m_k(\boldsymbol{\theta}) = \mathbb{E}\left[ (X - \mathbb{E}\left[ X\right])^k\right] \,,k = 2,\dots, d \,,
\]</span>
and
<span class="math display">\[
\hat{m}_1 = \bar{x}_n \quad \mbox{and} \quad \hat{m}_k =  \frac{1}{n} \sum_{i = 1}^n (x_i - \bar{x}_n )^k\,, \quad k = 2,\dots, d\,.
\]</span>
Then, we can solve for <span class="math inline">\(\boldsymbol{\theta}\)</span> in
<span class="math display">\[
m_k({\boldsymbol{\theta}}) =  \hat{m_k} \,, \quad k = 1,\dots, d\,,
\]</span>
to find the moment matching estimator <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span>.</p>
<p>In general, there are no closed-form formulas for the moment-matching estimators, and numerical methods must be employed. In R, we can use, for example, the <code>fitdist()</code> function in the <code>fitdistrplus</code> R package to perform moment-matching estimation by simply adjusting the argument <code>method</code>. For example, for our exponential distributed sample</p>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="r-for-statistical-inference.html#cb739-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb739-2"><a href="r-for-statistical-inference.html#cb739-2" aria-hidden="true" tabindex="-1"></a>lambda <span class="ot">&lt;-</span> <span class="fl">1.5</span></span>
<span id="cb739-3"><a href="r-for-statistical-inference.html#cb739-3" aria-hidden="true" tabindex="-1"></a>x_exp <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">1000</span>, lambda)</span></code></pre></div>
<p>we compute the moment matching estimator as follows:</p>
<div class="sourceCode" id="cb740"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb740-1"><a href="r-for-statistical-inference.html#cb740-1" aria-hidden="true" tabindex="-1"></a>fit_exp_mme <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(x_exp, <span class="at">distr =</span> <span class="st">&quot;exp&quot;</span>, <span class="at">method =</span> <span class="st">&quot;mme&quot;</span>)</span>
<span id="cb740-2"><a href="r-for-statistical-inference.html#cb740-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_exp_mme)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; exp &#39; by matching moments 
## Parameters : 
##      estimate
## rate 1.454471
## Loglikelihood:  -625.3576   AIC:  1252.715   BIC:  1257.623</code></pre>
<div class="remark">
<p><span id="unlabeled-div-34" class="remark"><em>Remark</em>. </span>You may have noticed that the maximum likelihood and the moment-matching estimators coincide for our exponentially distributed sample. This is a particular property of the exponential distribution. However, in general, this is not the case for other distributions.</p>
</div>
</div>
<div id="quantile-matching" class="section level5 unnumbered hasAnchor">
<h5>Quantile-matching<a href="r-for-statistical-inference.html#quantile-matching" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>Quantile-matching estimation follows a similar idea to the moment-matching estimation. The main difference is that we now match the empirical quantiles of the given sample and the theoretical quantiles of the parametric distribution to be fitted. More specifically, we have the following equations</p>
<p><span class="math display">\[
F^{\leftarrow}(p_k;\boldsymbol{\theta}) = Q_{n, p_k}\,, \quad k = 1, \dots, d \,,
\]</span>
where <span class="math inline">\(Q_{n, p_k}\)</span> are the empirical quantiles of the data for specified probabilities <span class="math inline">\(p_k \in [0,1]\)</span>, <span class="math inline">\(k = 1,\dots,d\)</span>. The solution <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> for the above equations is the quantile-matching estimator and is (typically) computed using numerical optimization. Note that the probabilities <span class="math inline">\(p_k \in [0,1]\)</span>, <span class="math inline">\(k = 1,\dots,d\)</span> must be pre-selected and, thus, the resulting estimator would depend on this selection. We can use the <code>fitdist()</code> function in R to perform this estimation method. We simply change the input of the argument <code>method</code> to “qme”. Note that in this case, we need to specify the probabilities via the argument <code>probs</code>. Let us give a specific example</p>
<div class="sourceCode" id="cb742"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb742-1"><a href="r-for-statistical-inference.html#cb742-1" aria-hidden="true" tabindex="-1"></a>fit_exp_qme <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(x_exp, <span class="at">distr =</span> <span class="st">&quot;exp&quot;</span>, <span class="at">method =</span> <span class="st">&quot;qme&quot;</span>, <span class="at">probs =</span> <span class="fl">0.5</span>)</span>
<span id="cb742-2"><a href="r-for-statistical-inference.html#cb742-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_exp_qme)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; exp &#39; by matching quantiles 
## Parameters : 
##      estimate
## rate 1.415335
## Loglikelihood:  -625.7263   AIC:  1253.453   BIC:  1258.36</code></pre>
</div>
<div id="maximum-goodness-of-fit" class="section level5 unnumbered hasAnchor">
<h5>Maximum Goodness-of-fit<a href="r-for-statistical-inference.html#maximum-goodness-of-fit" class="anchor-section" aria-label="Anchor link to header"></a></h5>
<p>The last method that we present here is the Goodness-of-fit estimation method, also known as minimum distance estimation. The idea of this method is to find a parameter <span class="math inline">\(\boldsymbol{\theta}\)</span> that minimizes the “distance” between the empirical distribution function <span class="math inline">\(F_{n}(x) = n^{-1}\sum_{i = 1}^n \mathbf{1}(x_i \leq x)\)</span> and the parametric distribution <span class="math inline">\(F(x; \boldsymbol{\theta})\)</span>. The distance can be measure, for example, using the Cramer–von Mises distance defined as
<span class="math display">\[
D(\boldsymbol{\theta}) = \int_{-\infty}^{\infty} (F_{n}(x) - F(x; \boldsymbol{\theta}))^2 dx \,,
\]</span>
which in practice can be estimated as</p>
<p><span class="math display">\[
\hat{D}(\boldsymbol{\theta}) = \frac{1}{12 n} + \sum_{i = 1}^{n} \left(F(x; \boldsymbol{\theta}) - \frac{2i - 1}{2n} \right)^2 dx \,.
\]</span>
Thus, maximum goodness-of-fit estimation translates to finding <span class="math inline">\(\boldsymbol{\theta}\)</span> that minimizes <span class="math inline">\(\hat{D}(\boldsymbol{\theta})\)</span>. In R, we can access this method by changing the argument <code>method</code> to “mge” in the <code>fitdist()</code> function. Let us finish this section by trying this method in our exponential sample</p>
<div class="sourceCode" id="cb744"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb744-1"><a href="r-for-statistical-inference.html#cb744-1" aria-hidden="true" tabindex="-1"></a>fit_exp_mge <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(x_exp, <span class="at">distr =</span> <span class="st">&quot;exp&quot;</span>, <span class="at">method =</span> <span class="st">&quot;mge&quot;</span>)</span></code></pre></div>
<pre><code>## Warning in fitdist(x_exp, distr = &quot;exp&quot;, method = &quot;mge&quot;): maximum GOF
## estimation has a default &#39;gof&#39; argument set to &#39;CvM&#39;</code></pre>
<div class="sourceCode" id="cb746"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb746-1"><a href="r-for-statistical-inference.html#cb746-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(fit_exp_mge)</span></code></pre></div>
<pre><code>## Fitting of the distribution &#39; exp &#39; by maximum goodness-of-fit 
## Parameters : 
##      estimate
## rate  1.41384
## Loglikelihood:  -625.7552   AIC:  1253.51   BIC:  1258.418</code></pre>
<p>Note that the Cramer-von Mises distance is the default option, but it can be changed to other distances (see help for details).</p>
</div>
</div>
</div>
<div id="multivariate-distributions" class="section level2 hasAnchor" number="2.4">
<h2><span class="header-section-number">2.4</span> Multivariate distributions<a href="r-for-statistical-inference.html#multivariate-distributions" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>In this section, we review some parametric models for random vectors. First, we review one of the most well know multivariate models, namely the multivariate normal distribution, and then we present a more general multivariate modeling approach using copulas.</p>
<div id="multivariate-normal-distribution" class="section level3 hasAnchor" number="2.4.1">
<h3><span class="header-section-number">2.4.1</span> Multivariate normal distribution<a href="r-for-statistical-inference.html#multivariate-normal-distribution" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Recall that a <span class="math inline">\(p\)</span>-dimensional random vector <span class="math inline">\(\mathbf{X} = (X_1,\dots, X_p)\)</span> is said to be multivariate normal distributed with mean vector <span class="math inline">\(\boldsymbol{\mu}\)</span> and covariance matrix <span class="math inline">\(\boldsymbol{\Sigma}\)</span> if its joint density function <span class="math inline">\(f_{\mathbf{X}}\)</span> is given by</p>
<p><span class="math display">\[
f_{\mathbf{X}}(x_1,\dots, x_p) = \frac{1}{\sqrt{(2\pi)^p |\boldsymbol{\Sigma}|}} \exp\left( -\frac{1}{2}(\mathbf{x} - \boldsymbol{\mu})\boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})^{\top} \right) \,,
\]</span>
where <span class="math inline">\(|\boldsymbol{\Sigma}|\)</span> denotes the determinant of <span class="math inline">\(\boldsymbol{\Sigma}\)</span>. We write <span class="math inline">\(\mathbf{X}\sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span>.</p>
<p>There are several implementations of the multivariate normal distribution in R. However, we will employ the one available in the <code>mvtnorm</code> package.</p>
<div class="sourceCode" id="cb748"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb748-1"><a href="r-for-statistical-inference.html#cb748-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(mvtnorm)</span></code></pre></div>
<p>We start by exemplifying how to compute the joint density function via the <code>dmvnorm()</code> function:</p>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="r-for-statistical-inference.html#cb749-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dmvnorm</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>))</span></code></pre></div>
<pre><code>## [1] 0.1591549</code></pre>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="r-for-statistical-inference.html#cb751-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dmvnorm</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>, <span class="dv">1</span>))</span></code></pre></div>
<pre><code>## [1] 0.03851084</code></pre>
<p>We can also compute density evaluations for several data points by giving them in a matrix form. For instance,</p>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="r-for-statistical-inference.html#cb753-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)), <span class="dv">2</span>, <span class="dv">2</span>, <span class="at">byrow =</span> T)</span>
<span id="cb753-2"><a href="r-for-statistical-inference.html#cb753-2" aria-hidden="true" tabindex="-1"></a>x</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    0    0
## [2,]    1    1</code></pre>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb755-1"><a href="r-for-statistical-inference.html#cb755-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dmvnorm</span>(x)</span></code></pre></div>
<pre><code>## [1] 0.15915494 0.05854983</code></pre>
<p>Note that the default value for the mean vector is the vector of 0’s, and for the covariance matrix, the identity matrix. We can change these default values by providing the desired information in the respective arguments. For example,</p>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="r-for-statistical-inference.html#cb757-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb757-2"><a href="r-for-statistical-inference.html#cb757-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="at">ncol =</span> <span class="dv">2</span>)</span>
<span id="cb757-3"><a href="r-for-statistical-inference.html#cb757-3" aria-hidden="true" tabindex="-1"></a>sigma</span></code></pre></div>
<pre><code>##      [,1] [,2]
## [1,]    4    2
## [2,]    2    3</code></pre>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="r-for-statistical-inference.html#cb759-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dmvnorm</span>(<span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="at">mean =</span> mu, <span class="at">sigma =</span> sigma)</span></code></pre></div>
<pre><code>## [1] 0.04664928</code></pre>
<p>Recall that for a random <span class="math inline">\(\mathbf{X}\)</span>, its joint distribution function <span class="math inline">\(F_{\mathbf{X}}\)</span> is given by
<span class="math display">\[
F_{\mathbf{X}}(x_1, \dots, x_p) = \mathbb{P}( X_1 \leq x_1,\dots,  X_p \leq x_p) \,.
\]</span>
The joint distribution function of <span class="math inline">\(\mathbf{X}\sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span> can be evaluated in R using the <code>pmvnorm()</code> function. For instance, we can compute</p>
<p><span class="math display">\[
\mathbb{P}( X_1 \leq 1, X_2 \leq 4) \,,
\]</span>
for <span class="math inline">\(\mathbf{X}\sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span> with <span class="math inline">\(\boldsymbol{\mu}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span> given by</p>
<div class="sourceCode" id="cb761"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb761-1"><a href="r-for-statistical-inference.html#cb761-1" aria-hidden="true" tabindex="-1"></a>mu <span class="ot">&lt;-</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>)</span>
<span id="cb761-2"><a href="r-for-statistical-inference.html#cb761-2" aria-hidden="true" tabindex="-1"></a>sigma <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="dv">4</span>, <span class="dv">2</span>, <span class="dv">2</span>, <span class="dv">3</span>), <span class="at">ncol =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>as follows</p>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="r-for-statistical-inference.html#cb762-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pmvnorm</span>(<span class="at">mean =</span> mu, <span class="at">sigma =</span> sigma, <span class="at">upper =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<pre><code>## [1] 0.4970487
## attr(,&quot;error&quot;)
## [1] 1e-15
## attr(,&quot;msg&quot;)
## [1] &quot;Normal Completion&quot;</code></pre>
<p>Moreover, <code>pmvnorm()</code> allow us to compute more complicated probabilities. For example, to compute
<span class="math display">\[
\mathbb{P}( X_1 \leq 1, -1 &lt; X_2 \leq 4) \,,
\]</span>
we simply specify values in the <code>lower</code> argument of <code>pmvnorm()</code> as follows</p>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="r-for-statistical-inference.html#cb764-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pmvnorm</span>(<span class="at">mean =</span> mu, <span class="at">sigma =</span> sigma, <span class="at">lower =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="cn">Inf</span>, <span class="sc">-</span><span class="dv">1</span>), <span class="at">upper =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">4</span>))</span></code></pre></div>
<pre><code>## [1] 0.3892527
## attr(,&quot;error&quot;)
## [1] 1e-15
## attr(,&quot;msg&quot;)
## [1] &quot;Normal Completion&quot;</code></pre>
<p>Simulation of multivariate normal models can be performed using the <code>rmvnorm()</code> function. For example,</p>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="r-for-statistical-inference.html#cb766-1" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rmvnorm</span>(<span class="at">n =</span> <span class="dv">500</span>, <span class="at">mean =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>), <span class="at">sigma =</span> sigma)</span>
<span id="cb766-2"><a href="r-for-statistical-inference.html#cb766-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(x)</span></code></pre></div>
<pre><code>##            [,1]     [,2]
## [1,]  0.4651394 2.677685
## [2,]  1.2112011 1.154777
## [3,]  0.7727047 1.649591
## [4,]  4.2882523 3.114262
## [5,]  0.4101875 3.575816
## [6,] -1.1396597 2.166214</code></pre>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="r-for-statistical-inference.html#cb768-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(x,</span>
<span id="cb768-2"><a href="r-for-statistical-inference.html#cb768-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Simulated sample from multivariate normal&quot;</span>,</span>
<span id="cb768-3"><a href="r-for-statistical-inference.html#cb768-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;X1&quot;</span>, <span class="at">ylab =</span> <span class="st">&quot;X2&quot;</span></span>
<span id="cb768-4"><a href="r-for-statistical-inference.html#cb768-4" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-313-1.png" width="672" /></p>
<div class="remark">
<p><span id="unlabeled-div-35" class="remark"><em>Remark</em>. </span>The MLEs for <span class="math inline">\(\boldsymbol{\mu}\)</span> and <span class="math inline">\(\boldsymbol{\Sigma}\)</span> are explicit and given by the vector of sample means and the sample covariance matrix, which can be computed easily as</p>
<div class="sourceCode" id="cb769"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb769-1"><a href="r-for-statistical-inference.html#cb769-1" aria-hidden="true" tabindex="-1"></a><span class="fu">colMeans</span>(x)</span></code></pre></div>
<pre><code>## [1] 0.9603442 1.9359186</code></pre>
<div class="sourceCode" id="cb771"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb771-1"><a href="r-for-statistical-inference.html#cb771-1" aria-hidden="true" tabindex="-1"></a><span class="fu">var</span>(x) <span class="sc">*</span> (<span class="dv">1</span> <span class="sc">-</span> <span class="dv">1</span> <span class="sc">/</span> <span class="fu">nrow</span>(x))</span></code></pre></div>
<pre><code>##          [,1]     [,2]
## [1,] 4.366248 1.903049
## [2,] 1.903049 2.905198</code></pre>
<p>In the next section, we will cover the estimation of more complex models.</p>
</div>
<p>Let us conclude the present section by recalling the close-form expression for the joint characteristic function of <span class="math inline">\(\mathbf{X}\sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span></p>
<p><span class="math display">\[
\varphi_{\mathbf{X}} (\mathbf{t}) = \exp\left( i\mathbf{t}\boldsymbol{\mu}^{\top} - \frac{1}{2} \mathbf{t} \boldsymbol{\Sigma}\mathbf{t}^{\top}  \right) \,.
\]</span></p>
</div>
<div id="copulas" class="section level3 hasAnchor" number="2.4.2">
<h3><span class="header-section-number">2.4.2</span> Copulas<a href="r-for-statistical-inference.html#copulas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>A <span class="math inline">\(p\)</span>-dimensional copula is a distribution function on <span class="math inline">\([0,1]^p\)</span> with uniform marginals over <span class="math inline">\([0,1]\)</span>. In other words, for a <span class="math inline">\(p\)</span>-dimensional random vector <span class="math inline">\(\mathbf{U} = (U_1, \dots, U_p)\)</span> on the unit cube, a copula <span class="math inline">\(C\)</span> is</p>
<p><span class="math display">\[
C(u_1, \dots, u_p) = \mathbb{P}(U_1 \leq u_1, \dots, U_p \leq u_p) \,.
\]</span></p>
<p>The importance of studying copulas for multivariate modeling is summarized by the following theorem, known as Sklar’s Theorem.</p>
<div class="theorem">
<p><span id="thm:unlabeled-div-36" class="theorem"><strong>Theorem 2.6  </strong></span>Let <span class="math inline">\(F\)</span> be a joint distribution function with marginals <span class="math inline">\(F_1,\dots,F_p\)</span>. Then there exists a copula <span class="math inline">\(C : [0,1]^p \to [0,1]\)</span> such that, for all <span class="math inline">\(x_1,\dots,x_p\)</span> in <span class="math inline">\(\bar{\mathbb{R}} = [-\infty,\infty]\)</span>,
<span class="math display" id="eq:sklar">\[\begin{equation}
F(x_1,\dots,x_p) = C(F_1(x_1),\dots,F_p(x_p))\,.
\tag{2.3}
\end{equation}\]</span>
Moreover, if the marginals are continuous, then <span class="math inline">\(C\)</span> is unique. Conversely, if <span class="math inline">\(C\)</span> is a copula and <span class="math inline">\(F_1,\dots,F_p\)</span> are univariate distribution functions, then the function <span class="math inline">\(F\)</span> defined in <a href="r-for-statistical-inference.html#eq:sklar">(2.3)</a> is a joint distribution function with margins <span class="math inline">\(F_1,\dots,F_p\)</span> .</p>
</div>
<p>We now recall a fundamental proposition in probability theory. In particular, i) is key for performing stochastic simulation.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-37" class="proposition"><strong>Proposition 2.1  </strong></span>Let <span class="math inline">\(F\)</span> be a distribution function and <span class="math inline">\(F^{\leftarrow}\)</span> its generalized inverse. Then</p>
<ol style="list-style-type: lower-roman">
<li><p>If <span class="math inline">\(U\)</span> is a standard uniform distributed random variable, that is, <span class="math inline">\(U \sim U(0,1)\)</span>, then <span class="math inline">\(\mathbb{P} (F^{\leftarrow}(U) \leq x) = F(x)\)</span>.</p></li>
<li><p>If <span class="math inline">\(Y \sim F\)</span>, with <span class="math inline">\(F\)</span> a continuous distribution function, then <span class="math inline">\(F(Y) \sim U(0,1)\)</span>.</p></li>
</ol>
</div>
<p>Thus, in the case of continuous marginals, Sklar’s Theorem also suggests that we can find the copula of a given joint distribution. More specifically, if a random vector <span class="math inline">\(\mathbf{X}\)</span> has joint distribution function <span class="math inline">\(F\)</span> with continuous marginal distributions <span class="math inline">\(F_1, \dots, F_p\)</span>, then the copula of <span class="math inline">\(F\)</span> (or <span class="math inline">\(\mathbf{X}\)</span>) is the joint distribution function <span class="math inline">\(C\)</span> of the random vector <span class="math inline">\((F_1(X_1),\dots,F_d(X_p))\)</span>.</p>
<p>Copulas allow for modeling very different types of dependence structures. For instance, the independence case is retrieved by the <em>independence copula</em> given by
<span class="math display">\[
C_{ind}(u_1, \dots, u_p) = \prod_{i = 1}^p u_i \,.
\]</span>
Indeed, Sklar’s Theorem implies that r.v.’s (with continuous distributions) are independent if and only if their copula is the independence copula.</p>
<p>Another important property of copulas is their invariance under strictly increasing transformations of the marginals, as stated in the following proposition.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-38" class="proposition"><strong>Proposition 2.2  </strong></span>Let <span class="math inline">\((X_1,\dots, X_p )\)</span> be a random vector with continuous marginals and copula <span class="math inline">\(C\)</span>. Let <span class="math inline">\(T_1,\dots, T_p\)</span> be strictly increasing functions. Then <span class="math inline">\((T_1(X_1),\dots, T_p(X_p))\)</span> also has copula <span class="math inline">\(C\)</span>.</p>
</div>
<p>As previously mentioned, copulas can be obtained from given distribution functions. In particular, we can derive copulas from several well-known multivariate distributions. These are commonly known as <em>implicit</em> copulas. For example, consider <span class="math inline">\(\mathbf{X}\sim N(\boldsymbol{0}, \boldsymbol{P})\)</span>, where <span class="math inline">\(\boldsymbol{0}\)</span> is the <span class="math inline">\(p\)</span>-dimensional vector of zeroes, and <span class="math inline">\(\boldsymbol{P}\)</span> is a <span class="math inline">\(p \times p\)</span> correlation matrix. Then, we define the <em>Gaussian</em> copula as the copula of <span class="math inline">\(\mathbf{X}\)</span>. More specifically, the Gaussian copula is given by</p>
<p><span class="math display">\[
C_{\boldsymbol{P}}^{Ga}(\mathbf{u}) = \mathbb{P}(\Phi(X_1) \leq u_1, \dots, \Phi(X_p) \leq u_p) = \boldsymbol{\Phi}_{\boldsymbol{P}} (\Phi^{-1}(u_1), \dots, \Phi^{-1}(u_p)) \,,
\]</span>
where <span class="math inline">\(\Phi\)</span> denotes the distribution function of a (univariate) standard normal and <span class="math inline">\(\boldsymbol{\Phi}_{\boldsymbol{P}}\)</span> is the joint distribution function of <span class="math inline">\(\mathbf{X}\)</span>.
Note that considering more general <span class="math inline">\(\mathbf{X}\sim N(\boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span>, leads to the same family of Gaussian copulas due to the property of invariance under increasing transformations.</p>
<p>It turns out that the Gaussian copula falls into the more general family of <em>elliptical copulas</em>, which we review next.</p>
<div id="elliptical-copulas" class="section level4 unnumbered hasAnchor">
<h4>Elliptical copulas<a href="r-for-statistical-inference.html#elliptical-copulas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Before introducing elliptic copulas, we define elliptical distributions. We say that a random vector <span class="math inline">\(\mathbf{X}\)</span> follows an elliptical distribution if its characteristic function <span class="math inline">\(\varphi_{\mathbf{X}}\)</span> is of the form</p>
<p><span class="math display">\[
\varphi_{\mathbf{X}} (\mathbf{t}) = \exp( i\mathbf{t}\boldsymbol{\mu}^{\top}) \psi\left(\mathbf{t} \boldsymbol{\Sigma}\mathbf{t}^{\top}  \right) \,,
\]</span>
for some vector <span class="math inline">\(\boldsymbol{\mu}\)</span> known as the location vector, some positive definite matrix <span class="math inline">\(\boldsymbol{\Sigma}\)</span> known as the dispersion matrix, and some function <span class="math inline">\(\psi\)</span>.
Note, for instance, that the multivariate normal distribution is a particular case with <span class="math inline">\(\psi(t) = \exp(-\frac{1}{2}t)\)</span>. Another important example of elliptical distributions is the multivariate <span class="math inline">\(t\)</span> distribution. Recall that <span class="math inline">\(\mathbf{X}\)</span> is said to be multivariate <span class="math inline">\(t\)</span>-distributed with <span class="math inline">\(\nu\)</span> degrees of freedom if its joint density function is given by
<span class="math display">\[
f(\mathbf{x}) = \frac{\Gamma(\frac{1}{2}(v+ p))}{\Gamma(\frac{1}{2}v)\sqrt{(2\pi)^p |\boldsymbol{\Sigma}|}} \left( 1 + \frac{1}{v}(\mathbf{x} - \boldsymbol{\mu})\boldsymbol{\Sigma}^{-1} (\mathbf{x} - \boldsymbol{\mu})^{\top} \right)^{-(v + p) /2} \,.
\]</span>
We write <span class="math inline">\(\mathbf{X} \sim t(\nu, \boldsymbol{\mu}, \boldsymbol{\Sigma})\)</span>. In this case, <span class="math inline">\(\psi(t) = \hat{H}(-\frac{1}{2}t)\)</span>, where <span class="math inline">\(\hat{H}\)</span> is the Laplace transform of an (appropriate) Inverse Gamma distribution.</p>
<div class="definition">
<p><span id="def:unlabeled-div-39" class="definition"><strong>Definition 2.1  </strong></span>An <em>elliptical copula</em> is the implicit copula of an elliptical distribution.</p>
</div>
<div class="remark">
<p><span id="unlabeled-div-40" class="remark"><em>Remark</em>. </span>Since copulas are invariant to increasing transformations of the marginals, elliptical copulas are typically defined in terms of the standardized dispersion matrix, or correlation matrix.</p>
</div>
<p>Now, let us review how to work with elliptical copulas in R. There are several packages to do so, for example, <code>copula</code> and <code>fCopulae</code>. However, we will use <code>copula</code> here.</p>
<div class="sourceCode" id="cb773"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb773-1"><a href="r-for-statistical-inference.html#cb773-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(copula)</span></code></pre></div>
<p>Elliptical copulas can be defined in R by using the <code>ellipCopula()</code> function, which creates objects of type <code>copula</code>. Next, we present an example of how to define a Gaussian copula of dimension <span class="math inline">\(2\)</span> with a correlation of <span class="math inline">\(0.4\)</span>:</p>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="r-for-statistical-inference.html#cb774-1" aria-hidden="true" tabindex="-1"></a>gaussian_cop <span class="ot">&lt;-</span> <span class="fu">ellipCopula</span>(</span>
<span id="cb774-2"><a href="r-for-statistical-inference.html#cb774-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;normal&quot;</span>, <span class="co"># Gaussian copula</span></span>
<span id="cb774-3"><a href="r-for-statistical-inference.html#cb774-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">dim =</span> <span class="dv">2</span>, <span class="co"># Dimension of the copula</span></span>
<span id="cb774-4"><a href="r-for-statistical-inference.html#cb774-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">dispstr =</span> <span class="st">&quot;ex&quot;</span>, <span class="co"># Structure of the correlation matrix</span></span>
<span id="cb774-5"><a href="r-for-statistical-inference.html#cb774-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span> <span class="fl">0.4</span> <span class="co"># Correlation</span></span>
<span id="cb774-6"><a href="r-for-statistical-inference.html#cb774-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb774-7"><a href="r-for-statistical-inference.html#cb774-7" aria-hidden="true" tabindex="-1"></a>gaussian_cop</span></code></pre></div>
<pre><code>## Normal copula, dim. d = 2 
## Dimension:  2 
## Parameters:
##   rho.1   = 0.4</code></pre>
<p>The argument <code>dispstr</code> characterizes the structure of the correlation matrix. The available structures are “ex” for exchangeable, “ar1” for AR(1), “toep” for Toeplitz, and “un” for unstructured. For example, for dimension 3, the corresponding matrices are:</p>
<p><span class="math display">\[
\left( \begin{array}{ccc}
        1 &amp;  \rho_1 &amp; \rho_1\\
        \rho_1 &amp;  1 &amp; \rho_1  \\
        \rho_1 &amp;  \rho_1 &amp; 1  \\
    \end{array} \right) \,, \quad \left( \begin{array}{ccc}
        1 &amp;  \rho_1 &amp; \rho_1^2\\
        \rho_1 &amp;  1 &amp; \rho_1  \\
        \rho_1^2 &amp;  \rho_1 &amp; 1  \\
    \end{array} \right) \,, \quad \left( \begin{array}{ccc}
        1 &amp;  \rho_1 &amp; \rho_2\\
        \rho_1 &amp;  1 &amp; \rho_1  \\
        \rho_2 &amp;  \rho_1 &amp; 1  \\
    \end{array} \right) \,, \quad \mbox{and} \quad  \left( \begin{array}{ccc}
        1 &amp;  \rho_1 &amp; \rho_2\\
        \rho_1 &amp;  1 &amp; \rho_3  \\
        \rho_2 &amp;  \rho_3 &amp; 1  \\
    \end{array} \right) \,.
\]</span></p>
<p>To exemplify these constructions, next, we make use of the <code>getSigma()</code> function to recover the correlation matrices of Gaussian copulas defined using the different values of <code>dispstr</code>:</p>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb776-1"><a href="r-for-statistical-inference.html#cb776-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getSigma</span>(<span class="fu">ellipCopula</span>(</span>
<span id="cb776-2"><a href="r-for-statistical-inference.html#cb776-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;normal&quot;</span>,</span>
<span id="cb776-3"><a href="r-for-statistical-inference.html#cb776-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">dim =</span> <span class="dv">3</span>, <span class="at">dispstr =</span> <span class="st">&quot;ex&quot;</span>, </span>
<span id="cb776-4"><a href="r-for-statistical-inference.html#cb776-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span> <span class="fl">0.4</span></span>
<span id="cb776-5"><a href="r-for-statistical-inference.html#cb776-5" aria-hidden="true" tabindex="-1"></a>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]  1.0  0.4  0.4
## [2,]  0.4  1.0  0.4
## [3,]  0.4  0.4  1.0</code></pre>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb778-1"><a href="r-for-statistical-inference.html#cb778-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getSigma</span>(<span class="fu">ellipCopula</span>(</span>
<span id="cb778-2"><a href="r-for-statistical-inference.html#cb778-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;normal&quot;</span>,</span>
<span id="cb778-3"><a href="r-for-statistical-inference.html#cb778-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">dim =</span> <span class="dv">3</span>, <span class="at">dispstr =</span> <span class="st">&quot;ar1&quot;</span>, </span>
<span id="cb778-4"><a href="r-for-statistical-inference.html#cb778-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span> <span class="fl">0.4</span></span>
<span id="cb778-5"><a href="r-for-statistical-inference.html#cb778-5" aria-hidden="true" tabindex="-1"></a>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,] 1.00  0.4 0.16
## [2,] 0.40  1.0 0.40
## [3,] 0.16  0.4 1.00</code></pre>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="r-for-statistical-inference.html#cb780-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getSigma</span>(<span class="fu">ellipCopula</span>(</span>
<span id="cb780-2"><a href="r-for-statistical-inference.html#cb780-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;normal&quot;</span>,</span>
<span id="cb780-3"><a href="r-for-statistical-inference.html#cb780-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">dim =</span> <span class="dv">3</span>, <span class="at">dispstr =</span> <span class="st">&quot;toep&quot;</span>, </span>
<span id="cb780-4"><a href="r-for-statistical-inference.html#cb780-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span> <span class="fu">c</span>(<span class="fl">0.4</span>, <span class="fl">0.5</span>)</span>
<span id="cb780-5"><a href="r-for-statistical-inference.html#cb780-5" aria-hidden="true" tabindex="-1"></a>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]  1.0  0.4  0.5
## [2,]  0.4  1.0  0.4
## [3,]  0.5  0.4  1.0</code></pre>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="r-for-statistical-inference.html#cb782-1" aria-hidden="true" tabindex="-1"></a><span class="fu">getSigma</span>(<span class="fu">ellipCopula</span>(</span>
<span id="cb782-2"><a href="r-for-statistical-inference.html#cb782-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;normal&quot;</span>,</span>
<span id="cb782-3"><a href="r-for-statistical-inference.html#cb782-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">dim =</span> <span class="dv">3</span>, <span class="at">dispstr =</span> <span class="st">&quot;un&quot;</span>, </span>
<span id="cb782-4"><a href="r-for-statistical-inference.html#cb782-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span> <span class="fu">c</span>(<span class="fl">0.4</span>, <span class="fl">0.5</span>, <span class="fl">0.2</span>)</span>
<span id="cb782-5"><a href="r-for-statistical-inference.html#cb782-5" aria-hidden="true" tabindex="-1"></a>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3]
## [1,]  1.0  0.4  0.5
## [2,]  0.4  1.0  0.2
## [3,]  0.5  0.2  1.0</code></pre>
<p>We can evaluate the density and distribution functions of a <code>copula</code> object via the <code>dCopula()</code> and <code>pCopula()</code> functions, respectively. For example,</p>
<div class="sourceCode" id="cb784"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb784-1"><a href="r-for-statistical-inference.html#cb784-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dCopula</span>(<span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.2</span>), gaussian_cop)</span></code></pre></div>
<pre><code>## [1] 1.019913</code></pre>
<div class="sourceCode" id="cb786"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb786-1"><a href="r-for-statistical-inference.html#cb786-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pCopula</span>(<span class="fu">c</span>(<span class="fl">0.5</span>, <span class="fl">0.2</span>), gaussian_cop)</span></code></pre></div>
<pre><code>## [1] 0.1449953</code></pre>
<p>Moreover, for 2-dimensional copulas, we can visualize the joint density function by using the <code>contour()</code> and <code>persp()</code> functions:</p>
<div class="sourceCode" id="cb788"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb788-1"><a href="r-for-statistical-inference.html#cb788-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb788-2"><a href="r-for-statistical-inference.html#cb788-2" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(gaussian_cop, dCopula)</span>
<span id="cb788-3"><a href="r-for-statistical-inference.html#cb788-3" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(gaussian_cop, dCopula)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-319-1.png" width="672" /></p>
<p>Finally, to generate random values from our copula object, we use <code>rCopula()</code>.</p>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb789-1"><a href="r-for-statistical-inference.html#cb789-1" aria-hidden="true" tabindex="-1"></a>gauc_samp <span class="ot">&lt;-</span> <span class="fu">rCopula</span>(<span class="dv">5000</span>, gaussian_cop)</span>
<span id="cb789-2"><a href="r-for-statistical-inference.html#cb789-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(gauc_samp)</span></code></pre></div>
<pre><code>##            [,1]       [,2]
## [1,] 0.54092961 0.32358013
## [2,] 0.89182178 0.95080018
## [3,] 0.21661897 0.09522707
## [4,] 0.05448803 0.59939116
## [5,] 0.41222385 0.74123338
## [6,] 0.98678731 0.94826755</code></pre>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb791-1"><a href="r-for-statistical-inference.html#cb791-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(gauc_samp,</span>
<span id="cb791-2"><a href="r-for-statistical-inference.html#cb791-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Simulation of Gaussian copula&quot;</span>,</span>
<span id="cb791-3"><a href="r-for-statistical-inference.html#cb791-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;U1&quot;</span>,</span>
<span id="cb791-4"><a href="r-for-statistical-inference.html#cb791-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;U2&quot;</span></span>
<span id="cb791-5"><a href="r-for-statistical-inference.html#cb791-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-320-1.png" width="672" /></p>
<p>Now, let us exemplify how to define a t-copula:</p>
<div class="sourceCode" id="cb792"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb792-1"><a href="r-for-statistical-inference.html#cb792-1" aria-hidden="true" tabindex="-1"></a>t_cop <span class="ot">&lt;-</span> <span class="fu">ellipCopula</span>(</span>
<span id="cb792-2"><a href="r-for-statistical-inference.html#cb792-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">family =</span> <span class="st">&quot;t&quot;</span>, </span>
<span id="cb792-3"><a href="r-for-statistical-inference.html#cb792-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">dim =</span> <span class="dv">2</span>,</span>
<span id="cb792-4"><a href="r-for-statistical-inference.html#cb792-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">dispstr =</span> <span class="st">&quot;ex&quot;</span>, </span>
<span id="cb792-5"><a href="r-for-statistical-inference.html#cb792-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span> <span class="sc">-</span><span class="fl">0.4</span>,</span>
<span id="cb792-6"><a href="r-for-statistical-inference.html#cb792-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">df =</span> <span class="dv">2</span></span>
<span id="cb792-7"><a href="r-for-statistical-inference.html#cb792-7" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb792-8"><a href="r-for-statistical-inference.html#cb792-8" aria-hidden="true" tabindex="-1"></a>t_cop</span></code></pre></div>
<pre><code>## t-copula, dim. d = 2 
## Dimension:  2 
## Parameters:
##   rho.1   = -0.4
##   df      =  2.0</code></pre>
<p>We can now use the methods <code>dCopula()</code>, <code>pCopula()</code>, and <code>rCopula()</code> to compute the density and distribution functions and generate random values for this new object, respectively. For example,</p>
<div class="sourceCode" id="cb794"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb794-1"><a href="r-for-statistical-inference.html#cb794-1" aria-hidden="true" tabindex="-1"></a>tc_samp <span class="ot">&lt;-</span> <span class="fu">rCopula</span>(<span class="dv">5000</span>, t_cop)</span>
<span id="cb794-2"><a href="r-for-statistical-inference.html#cb794-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(tc_samp,</span>
<span id="cb794-3"><a href="r-for-statistical-inference.html#cb794-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Simulation of t copula&quot;</span>,</span>
<span id="cb794-4"><a href="r-for-statistical-inference.html#cb794-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;U1&quot;</span>,</span>
<span id="cb794-5"><a href="r-for-statistical-inference.html#cb794-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;U2&quot;</span></span>
<span id="cb794-6"><a href="r-for-statistical-inference.html#cb794-6" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-322-1.png" width="672" /></p>
<p>While elliptical copulas are implied by the well-known multivariate distribution functions of elliptical distributed random vectors, the copulas themselves do not have simple closed-form expressions. However, there are families of copulas that have simple closed-form formulas. These are often referred to as <em>explicit</em> copulas. Next, we review one of the most famous families of explicit copulas: the <em>Archemidiean</em> copulas.</p>
</div>
<div id="archimedean-copulas" class="section level4 unnumbered hasAnchor">
<h4>Archimedean copulas<a href="r-for-statistical-inference.html#archimedean-copulas" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>An Archimedean copula is characterized by a generator function <span class="math inline">\(\phi : [0,1] \to [0,\infty]\)</span> as</p>
<p><span class="math display" id="eq:arcop">\[\begin{equation}
C(\mathbf{u}) = \phi^{-1}\left( \phi(u_1) + \cdots + \phi(u_p) \right) \,,
\tag{2.4}
\end{equation}\]</span>
where <span class="math inline">\(\phi^{-1}\)</span> is the inverse of the generator <span class="math inline">\(\phi\)</span>. In order for <a href="r-for-statistical-inference.html#eq:arcop">(2.4)</a> to be a copula, a sufficient condition for the generator <span class="math inline">\(\phi\)</span> is that its inverse <span class="math inline">\(\phi^{-1} :[0, \infty] \to [0,1]\)</span> needs to be <em>completely monotonic</em>. In this family, the three most classical copulas are the Gumbel copula, the Frank copula, and the Clayton copula. These copulas are constructed as follows:</p>
<p><strong>Gumbel copula.</strong> The generator of this copula is <span class="math inline">\(\phi(t) = (-\log(t))^{\alpha}\)</span>, <span class="math inline">\(\alpha &gt; 1\)</span>. Then</p>
<p><span class="math display">\[
C_{Gu}(\mathbf{u}) = \exp\left( - \left((-\log(u_1))^{\alpha} + \cdots + (-\log(u_p))^{\alpha} \right)^{1/\alpha} \right) \,.
\]</span></p>
<p><strong>Frank copula.</strong> In this case, the generator is <span class="math inline">\(\phi(t) = -\log((\exp(-\alpha t) - 1) / (\exp(-\alpha ) - 1) )\)</span>, <span class="math inline">\(\alpha \in \mathbb{R}\)</span>. Then</p>
<p><span class="math display">\[
C_{F}(\mathbf{u}) = -\frac{1}{\alpha}\log\left( 1 + \frac{(\exp(-\alpha u_1) - 1)  \cdots  (\exp(-\alpha u_p) - 1)}{\exp(-\alpha) - 1} \right) \,.
\]</span></p>
<p><strong>Clayton copula</strong> The generator of this copula is given by <span class="math inline">\(\phi(t) =\alpha^{-1} (t ^{-\alpha} - 1)\)</span>, <span class="math inline">\(\alpha &gt; 0\)</span> (or <span class="math inline">\(\alpha &gt; -1\)</span> for dimension 2). Then</p>
<p><span class="math display">\[
C_{C}(\mathbf{u}) =  \left(u_1^{-\alpha} + \cdots + u_p^{-\alpha} - p + 1 \right)^{-1/\alpha}  \,.
\]</span></p>
<div class="remark">
<p><span id="unlabeled-div-41" class="remark"><em>Remark</em>. </span>Note that the three copulas above are uniparametric.</p>
</div>
<p>In R, we can use the <code>archmCopula()</code> function to construct Archimedean copulas. For example, a 2-dimensional Gumbel copula of parameter <span class="math inline">\(\alpha = 2.5\)</span> is created as follows</p>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb795-1"><a href="r-for-statistical-inference.html#cb795-1" aria-hidden="true" tabindex="-1"></a>gum_cop <span class="ot">&lt;-</span> <span class="fu">archmCopula</span>(<span class="at">family =</span> <span class="st">&quot;gumbel&quot;</span>, <span class="at">dim =</span> <span class="dv">2</span>, <span class="at">param =</span> <span class="fl">2.5</span>)</span>
<span id="cb795-2"><a href="r-for-statistical-inference.html#cb795-2" aria-hidden="true" tabindex="-1"></a>gum_cop</span></code></pre></div>
<pre><code>## Gumbel copula, dim. d = 2 
## Dimension:  2 
## Parameters:
##   alpha   = 2.5</code></pre>
<p>Again, <code>dCopula()</code>, <code>pCopula()</code>, and <code>rCopula()</code> give access to the density and distribution functions and the random values generator, respectively.</p>
<p>For example,</p>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb797-1"><a href="r-for-statistical-inference.html#cb797-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">3</span>))</span>
<span id="cb797-2"><a href="r-for-statistical-inference.html#cb797-2" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(<span class="fu">archmCopula</span>(<span class="at">family =</span> <span class="st">&quot;gumbel&quot;</span>, <span class="at">dim =</span> <span class="dv">2</span>, <span class="at">param =</span> <span class="dv">2</span>),</span>
<span id="cb797-3"><a href="r-for-statistical-inference.html#cb797-3" aria-hidden="true" tabindex="-1"></a>  dCopula,</span>
<span id="cb797-4"><a href="r-for-statistical-inference.html#cb797-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Gumbel copula&quot;</span>,</span>
<span id="cb797-5"><a href="r-for-statistical-inference.html#cb797-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">nlevels =</span> <span class="dv">20</span></span>
<span id="cb797-6"><a href="r-for-statistical-inference.html#cb797-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb797-7"><a href="r-for-statistical-inference.html#cb797-7" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(<span class="fu">archmCopula</span>(<span class="at">family =</span> <span class="st">&quot;frank&quot;</span>, <span class="at">dim =</span> <span class="dv">2</span>, <span class="at">param =</span> <span class="fl">5.5</span>),</span>
<span id="cb797-8"><a href="r-for-statistical-inference.html#cb797-8" aria-hidden="true" tabindex="-1"></a>  dCopula,</span>
<span id="cb797-9"><a href="r-for-statistical-inference.html#cb797-9" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Frank copula&quot;</span>,</span>
<span id="cb797-10"><a href="r-for-statistical-inference.html#cb797-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">nlevels =</span> <span class="dv">20</span></span>
<span id="cb797-11"><a href="r-for-statistical-inference.html#cb797-11" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb797-12"><a href="r-for-statistical-inference.html#cb797-12" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(<span class="fu">archmCopula</span>(<span class="at">family =</span> <span class="st">&quot;clayton&quot;</span>, <span class="at">dim =</span> <span class="dv">2</span>, <span class="at">param =</span> <span class="dv">2</span>),</span>
<span id="cb797-13"><a href="r-for-statistical-inference.html#cb797-13" aria-hidden="true" tabindex="-1"></a>  dCopula,</span>
<span id="cb797-14"><a href="r-for-statistical-inference.html#cb797-14" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Clayton copula&quot;</span>,</span>
<span id="cb797-15"><a href="r-for-statistical-inference.html#cb797-15" aria-hidden="true" tabindex="-1"></a>  <span class="at">nlevels =</span> <span class="dv">20</span></span>
<span id="cb797-16"><a href="r-for-statistical-inference.html#cb797-16" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-324-1.png" width="672" /></p>
<p>We will study some properties of these Archimedean copulas when we cover dependence measures.</p>
</div>
</div>
<div id="constructing-multivariate-distributions-from-copulas" class="section level3 hasAnchor" number="2.4.3">
<h3><span class="header-section-number">2.4.3</span> Constructing multivariate distributions from copulas<a href="r-for-statistical-inference.html#constructing-multivariate-distributions-from-copulas" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Given a copula <span class="math inline">\(C\)</span> and marginals <span class="math inline">\(F_1, \dots, F_p\)</span>, we now want to construct a multivariate distribution from these components. The <code>copula</code> package allows us to do this via the <code>mvdc()</code> function, which creates objects of the type <code>mvdc</code>. There are three main arguments for this function: <code>copula</code>, which is a copula object, <code>margins</code> a character vector with the names of the marginals, and <code>paramMargins</code>, which is a list with the parameters of the marginals. The use of this function is better illustrated with an example. Let us imagine that we want to create a bivariate distribution with normally distributed marginals <span class="math inline">\(X_1 \sim N(1, 4)\)</span> and <span class="math inline">\(X_2\sim N(2, 2)\)</span> and copula the Clayton copula with parameter <span class="math inline">\(\alpha = 2\)</span>. First, we need the copula object:</p>
<div class="sourceCode" id="cb798"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb798-1"><a href="r-for-statistical-inference.html#cb798-1" aria-hidden="true" tabindex="-1"></a>clay_cop <span class="ot">&lt;-</span> <span class="fu">archmCopula</span>(<span class="at">family =</span> <span class="st">&quot;clayton&quot;</span>, <span class="at">dim =</span> <span class="dv">2</span>, <span class="at">param =</span> <span class="dv">2</span>)</span></code></pre></div>
<p>We can now define our <code>mvdc</code> object:</p>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb799-1"><a href="r-for-statistical-inference.html#cb799-1" aria-hidden="true" tabindex="-1"></a>my_mvd <span class="ot">&lt;-</span> <span class="fu">mvdc</span>(</span>
<span id="cb799-2"><a href="r-for-statistical-inference.html#cb799-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">copula =</span> clay_cop,</span>
<span id="cb799-3"><a href="r-for-statistical-inference.html#cb799-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">margins =</span> <span class="fu">c</span>(<span class="st">&quot;norm&quot;</span>, <span class="st">&quot;norm&quot;</span>),</span>
<span id="cb799-4"><a href="r-for-statistical-inference.html#cb799-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">paramMargins =</span> <span class="fu">list</span>(<span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">1</span>, <span class="at">sd =</span> <span class="dv">2</span>), <span class="fu">list</span>(<span class="at">mean =</span> <span class="dv">2</span>, <span class="at">sd =</span> <span class="fu">sqrt</span>(<span class="dv">2</span>)))</span>
<span id="cb799-5"><a href="r-for-statistical-inference.html#cb799-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb799-6"><a href="r-for-statistical-inference.html#cb799-6" aria-hidden="true" tabindex="-1"></a>my_mvd</span></code></pre></div>
<pre><code>## Multivariate Distribution Copula based (&quot;mvdc&quot;)
##  @ copula:
## Clayton copula, dim. d = 2 
## Dimension:  2 
## Parameters:
##   alpha   = 2
##  @ margins:
## [1] &quot;norm&quot; &quot;norm&quot;
##    with 2 (not identical)  margins; with parameters (@ paramMargins) 
## List of 2
##  $ :List of 2
##   ..$ mean: num 1
##   ..$ sd  : num 2
##  $ :List of 2
##   ..$ mean: num 2
##   ..$ sd  : num 1.414214</code></pre>
<p>We can now use <code>dMvdc()</code> to access the joint density of our multivariate model:</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="r-for-statistical-inference.html#cb801-1" aria-hidden="true" tabindex="-1"></a><span class="fu">dMvdc</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), my_mvd)</span></code></pre></div>
<pre><code>## [1] 0.08333573</code></pre>
<p>The joint distribution function can be evaluated using <code>pMvdc()</code>:</p>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="r-for-statistical-inference.html#cb803-1" aria-hidden="true" tabindex="-1"></a><span class="fu">pMvdc</span>(<span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">2</span>), my_mvd)</span></code></pre></div>
<pre><code>## [1] 0.3779645</code></pre>
<p>Again, we can use <code>contour()</code> and <code>persp()</code> to visualize our distribution:</p>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb805-1"><a href="r-for-statistical-inference.html#cb805-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">2</span>))</span>
<span id="cb805-2"><a href="r-for-statistical-inference.html#cb805-2" aria-hidden="true" tabindex="-1"></a><span class="fu">contour</span>(my_mvd, dMvdc, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">5</span>)) <span class="co"># xlim and ylim must be given</span></span>
<span id="cb805-3"><a href="r-for-statistical-inference.html#cb805-3" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(my_mvd, dMvdc, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">4</span>, <span class="dv">5</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="sc">-</span><span class="dv">2</span>, <span class="dv">5</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-329-1.png" width="672" /></p>
<p>Finally, random values from our multivariate model can be generated using <code>rMvdc()</code>:</p>
<div class="sourceCode" id="cb806"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb806-1"><a href="r-for-statistical-inference.html#cb806-1" aria-hidden="true" tabindex="-1"></a>my_mvdc_sample <span class="ot">&lt;-</span> <span class="fu">rMvdc</span>(<span class="dv">5000</span>, my_mvd)</span>
<span id="cb806-2"><a href="r-for-statistical-inference.html#cb806-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(my_mvdc_sample)</span></code></pre></div>
<pre><code>##            [,1]      [,2]
## [1,]  0.1009846 0.7844453
## [2,] -1.3441178 0.6030844
## [3,]  2.5885680 2.5168967
## [4,]  1.8196410 3.0904643
## [5,]  3.0041156 2.0874910
## [6,] -1.4500833 0.8198126</code></pre>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="r-for-statistical-inference.html#cb808-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(my_mvdc_sample,</span>
<span id="cb808-2"><a href="r-for-statistical-inference.html#cb808-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">main =</span> <span class="st">&quot;Simulation of multivariate distribution&quot;</span>,</span>
<span id="cb808-3"><a href="r-for-statistical-inference.html#cb808-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">xlab =</span> <span class="st">&quot;X1&quot;</span>,</span>
<span id="cb808-4"><a href="r-for-statistical-inference.html#cb808-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">ylab =</span> <span class="st">&quot;X2&quot;</span></span>
<span id="cb808-5"><a href="r-for-statistical-inference.html#cb808-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-330-1.png" width="672" /></p>
<div class="remark">
<p><span id="unlabeled-div-42" class="remark"><em>Remark</em>. </span>We can pass user-defined distributions for the marginals as long as the density (<code>d</code>), distribution (<code>p</code>), and quantile (<code>q</code>) functions are available. For example, if we name our distribution <code>foo</code>, then we need the <code>dfoo()</code>, <code>pfoo()</code>, and <code>qfoo()</code> functions.</p>
</div>
</div>
<div id="dependence-measures" class="section level3 hasAnchor" number="2.4.4">
<h3><span class="header-section-number">2.4.4</span> Dependence measures<a href="r-for-statistical-inference.html#dependence-measures" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>We now present some measures that assess the strength of dependence between random variables in different ways. We will limit ourselves to bivariate random vectors <span class="math inline">\((X_1,X_2)\)</span> for presentation purposes.</p>
<p>We first recall one of the most popular dependence measures: Pearson correlation. The correlation between <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, denoted by <span class="math inline">\(\rho(X_1,X_2)\)</span>, is given by</p>
<p><span class="math display">\[
\rho(X_1,X_2) = \frac{\mathbb{E}(X_1 X_2) - \mathbb{E}(X_1) \mathbb{E}(X_2) }{\sqrt{\mbox{Var}(X_1)\mbox{Var}(X_2)}} \,.
\]</span>
We know that if <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are independent, then <span class="math inline">\(\rho(X_1,X_2) =0\)</span>, but the converse is false.
If <span class="math inline">\(|\rho(X_1,X_2)| = 1\)</span> is equivalent to saying that <span class="math inline">\(X_2 = a + b X_1\)</span> for some <span class="math inline">\(a \in \mathbb{R}\)</span> and <span class="math inline">\(b \neq0\)</span>.</p>
<p>There are several pitfalls of using the correlation. For instance, we can have perfectly dependent random variables that exhibit relatively low correlation:</p>
<div class="sourceCode" id="cb809"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb809-1"><a href="r-for-statistical-inference.html#cb809-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb809-2"><a href="r-for-statistical-inference.html#cb809-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">100</span>)</span>
<span id="cb809-3"><a href="r-for-statistical-inference.html#cb809-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">exp</span>(x <span class="sc">*</span> <span class="dv">10</span>)</span>
<span id="cb809-4"><a href="r-for-statistical-inference.html#cb809-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(x, y)</span></code></pre></div>
<pre><code>## [1] 0.4163004</code></pre>
<p>Moreover, the correlation depends on the marginal distributions and may not even exist in some cases (we require finite second moments).</p>
<p>Hence, we now introduce other measures of dependence that depend only on the underlying copula of our multivariate model.</p>
<div id="rank-correlation" class="section level4 unnumbered hasAnchor">
<h4>Rank correlation<a href="r-for-statistical-inference.html#rank-correlation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>There are two crucial rank correlation measures: Kendall’s tau and Spearman’s rho. The empirical estimators of rank correlations can be calculated by looking at the ranks of the data (i.e., the positions of the data), hence the name.
We begin by defining Kendall’s tau, which can be understood as a measure of concordance for a bivariate random vector. Recall that two point in <span class="math inline">\(\mathbb{R}^2\)</span>, lets say <span class="math inline">\((x_1,x_2)\)</span> and <span class="math inline">\((\tilde{x_1},\tilde{x}_2)\)</span>, are said to be <em>concordant</em> if <span class="math inline">\((x_1 - \tilde{x}_1)(x_2 - \tilde{x}_2)&gt;0\)</span> and <em>discordant</em> if <span class="math inline">\((x_1 - \tilde{x}_1)(x_2 - \tilde{x}_2)&lt;0\)</span>. This motivates the following definition for random vectors <span class="math inline">\((X_1, X_2)\)</span></p>
<div class="definition">
<p><span id="def:unlabeled-div-43" class="definition"><strong>Definition 2.2  </strong></span>For two random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span>, Kendall’s tau is given by
<span class="math display">\[
\rho_\tau (X_1, X_2) = \mathbb{P}((X_1 - \tilde{X}_1)(X_2 - \tilde{X}_2)&gt;0) - \mathbb{P}((X_1 - \tilde{X}_1)(X_2 - \tilde{X}_2)&lt;0) \,,
\]</span>
where <span class="math inline">\((\tilde{X}_1, \tilde{X}_2)\)</span> is an independent copy of <span class="math inline">\((X_1, X_2)\)</span></p>
</div>
<p>In R, we can compute the empirical Kedall’s tau by using <code>method = "kendall"</code> in <code>cor()</code>:</p>
<div class="sourceCode" id="cb811"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb811-1"><a href="r-for-statistical-inference.html#cb811-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb811-2"><a href="r-for-statistical-inference.html#cb811-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">100</span>)</span>
<span id="cb811-3"><a href="r-for-statistical-inference.html#cb811-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">exp</span>(x <span class="sc">*</span> <span class="dv">10</span>)</span>
<span id="cb811-4"><a href="r-for-statistical-inference.html#cb811-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(x, y, <span class="at">method =</span> <span class="st">&quot;kendall&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>The second way to measure rank correlation is with Spearma’s rho. Although this measure can also be defined in terms of concordance and discordance for random pairs, we adopt the following definition:</p>
<div class="definition">
<p><span id="def:unlabeled-div-44" class="definition"><strong>Definition 2.3  </strong></span>For two random variables <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> with distribution functions <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span>, respectively, Spearma’s rho is given by
<span class="math display">\[
\rho_S (X_1, X_2) = \rho(F_1(X_1), F_2(X_2))\,,
\]</span>
where <span class="math inline">\(\rho\)</span> denotes the Pearson correlation.</p>
</div>
<p>In R, the empirical Spearman’s rho can be computed by changing <code>method = "spearman"</code> in <code>cor()</code>:</p>
<div class="sourceCode" id="cb813"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb813-1"><a href="r-for-statistical-inference.html#cb813-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb813-2"><a href="r-for-statistical-inference.html#cb813-2" aria-hidden="true" tabindex="-1"></a>x <span class="ot">&lt;-</span> <span class="fu">rexp</span>(<span class="dv">100</span>)</span>
<span id="cb813-3"><a href="r-for-statistical-inference.html#cb813-3" aria-hidden="true" tabindex="-1"></a>y <span class="ot">&lt;-</span> <span class="fu">exp</span>(x <span class="sc">*</span> <span class="dv">10</span>)</span>
<span id="cb813-4"><a href="r-for-statistical-inference.html#cb813-4" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(x, y, <span class="at">method =</span> <span class="st">&quot;spearman&quot;</span>)</span></code></pre></div>
<pre><code>## [1] 1</code></pre>
<p>As previously mentioned, an important feature of rank correlations is that they depend only on the (unique) copula of <span class="math inline">\((X_1, X_2)\)</span>.</p>
<div class="proposition">
<p><span id="prp:unlabeled-div-45" class="proposition"><strong>Proposition 2.3  </strong></span>Let <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> random variables with continuous marginal distribution functions and unique copula <span class="math inline">\(C\)</span>. The rank correlations are given by
<span class="math display">\[
\rho_\tau (X_1, X_2) = 4\int_{0}^1\int_{0}^1C(u_1,u_2)dC(u_1,u_2) - 1
\]</span>
<span class="math display">\[
\rho_S (X_1, X_2) = 12\int_{0}^1\int_{0}^1(C(u_1,u_2) - u_1u_2)du_1du_2
\]</span></p>
</div>
<p>The <code>copula</code> package comes with the functions <code>tau()</code> and <code>rho()</code> to compute the rank correlations for a copula object. Let us give an example:</p>
<div class="sourceCode" id="cb815"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb815-1"><a href="r-for-statistical-inference.html#cb815-1" aria-hidden="true" tabindex="-1"></a>clay_cop <span class="ot">&lt;-</span> <span class="fu">archmCopula</span>(<span class="at">family =</span> <span class="st">&quot;clayton&quot;</span>, <span class="at">dim =</span> <span class="dv">2</span>, <span class="at">param =</span> <span class="dv">2</span>)</span>
<span id="cb815-2"><a href="r-for-statistical-inference.html#cb815-2" aria-hidden="true" tabindex="-1"></a><span class="fu">tau</span>(clay_cop)</span></code></pre></div>
<pre><code>## [1] 0.5</code></pre>
<div class="sourceCode" id="cb817"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb817-1"><a href="r-for-statistical-inference.html#cb817-1" aria-hidden="true" tabindex="-1"></a><span class="fu">rho</span>(clay_cop)</span></code></pre></div>
<pre><code>## [1] 0.6828928</code></pre>
</div>
<div id="coefficients-of-tail-dependence" class="section level4 unnumbered hasAnchor">
<h4>Coefficients of tail dependence<a href="r-for-statistical-inference.html#coefficients-of-tail-dependence" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>The coefficients of tail dependence measure the strength of dependence in the tails of a bivariate distribution. These are defined as follows:</p>
<div class="definition">
<p><span id="def:unlabeled-div-46" class="definition"><strong>Definition 2.4  </strong></span>Let <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> be random variables with distribution functions <span class="math inline">\(F_1\)</span> and <span class="math inline">\(F_2\)</span>, respectively. The <em>coefficient of upper tail dependence</em> <span class="math inline">\(\lambda_u\)</span> of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> is
<span class="math display">\[
\lambda_u:= \lambda_u(X_1, X_2) = \lim_{q \to 1^{-}} \mathbb{P}(X_2&gt;F_2^{\leftarrow}(q) \mid X_1&gt;F_1^{\leftarrow}(q)) \,,
\]</span>
provided a limit <span class="math inline">\(\lambda_u \in [0,1]\)</span> exists. If <span class="math inline">\(\lambda_u \in (0,1]\)</span>, then we say that <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> show upper tail dependence. Alternatively, if <span class="math inline">\(\lambda_u = 0\)</span>, then they are said to be asymptotically independent in the upper tail. Similarly, we define the <em>coefficient of lower tail dependence</em> <span class="math inline">\(\lambda_l\)</span> as
<span class="math display">\[
\lambda_l:= \lambda_u(X_1, X_2) = \lim_{q \to 0^{+}} \mathbb{P}(X_2\leq F_2^{\leftarrow}(q) \mid X_1\leq F_1^{\leftarrow}(q)) \,,
\]</span>
provided a limit <span class="math inline">\(\lambda_l \in [0,1]\)</span> exists.</p>
</div>
<p>When the distribution functions of <span class="math inline">\(X_1\)</span> and <span class="math inline">\(X_2\)</span> are continuous, the upper and lower tail dependence coefficients can be written (solely) in terms of the copula of the bivariate distribution. More specifically, we have that
<span class="math display">\[
\lambda_u =\lim_{q \to 1^{-}} \frac{1 - 2q + C(q, q)}{1 - q} \quad \mbox{and} \quad \lambda_l =\lim_{q \to 0^{+}} \frac{C(q, q)}{q} \,.
\]</span></p>
<p>In R, we can compute these coefficients for a copula object using <code>lambda()</code>. For example,</p>
<div class="sourceCode" id="cb819"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb819-1"><a href="r-for-statistical-inference.html#cb819-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lambda</span>(clay_cop)</span></code></pre></div>
<pre><code>##     lower     upper 
## 0.7071068 0.0000000</code></pre>
<p>We conclude this section by providing Table <a href="r-for-statistical-inference.html#tab:depcop">2.3</a>, which contains the closed-form formulas of some dependence measures for the copula models introduced so far.</p>
<table>
<caption><span id="tab:depcop">Table 2.3: </span>Kendall’s tau and coefficients of tail dependence for some copulas. <span class="math inline">\(D_1\)</span> is the Debye function <span class="math inline">\(D_1(\theta) =\theta^{-1}\int_{0}^{\theta}t / (\exp(t) - 1)dt\)</span> and <span class="math inline">\(t_{\nu +1}\)</span> is the cdf of a univariate <span class="math inline">\(t\)</span> distribution with <span class="math inline">\(\nu +1\)</span> degrees of freedom.</caption>
<colgroup>
<col width="14%" />
<col width="24%" />
<col width="46%" />
<col width="13%" />
</colgroup>
<thead>
<tr class="header">
<th align="left">Copula</th>
<th align="left"><span class="math inline">\(\rho_{\tau}\)</span></th>
<th align="left"><span class="math inline">\(\lambda_{u}\)</span></th>
<th align="left"><span class="math inline">\(\lambda_{l}\)</span></th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">Gaussian</td>
<td align="left"><span class="math inline">\((2/ \pi) \arcsin (\rho)\)</span></td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">t</td>
<td align="left"><span class="math inline">\((2/ \pi) \arcsin (\rho)\)</span></td>
<td align="left"><span class="math inline">\(2t_{\nu+1}\left( - \sqrt{(\nu + 1)(1 - \rho) / (1 + \rho)}\right)\)</span></td>
<td align="left">Same as <span class="math inline">\(\lambda_u\)</span></td>
</tr>
<tr class="odd">
<td align="left">Gumbel</td>
<td align="left"><span class="math inline">\(1 - 1/\alpha\)</span></td>
<td align="left"><span class="math inline">\(2 - 2^{1/\alpha}\)</span></td>
<td align="left">0</td>
</tr>
<tr class="even">
<td align="left">Frank</td>
<td align="left"><span class="math inline">\(1 - 4\alpha^{-1}(1 - D_1(\alpha))\)</span></td>
<td align="left">0</td>
<td align="left">0</td>
</tr>
<tr class="odd">
<td align="left">Clayton <span class="math inline">\((\alpha&gt;0)\)</span></td>
<td align="left"><span class="math inline">\(\alpha / (\alpha + 2)\)</span></td>
<td align="left">0</td>
<td align="left"><span class="math inline">\(2^{-1/\alpha}\)</span></td>
</tr>
</tbody>
</table>
</div>
</div>
<div id="fitting" class="section level3 hasAnchor" number="2.4.5">
<h3><span class="header-section-number">2.4.5</span> Fitting<a href="r-for-statistical-inference.html#fitting" class="anchor-section" aria-label="Anchor link to header"></a></h3>
<p>Next, we will review two estimation methods for multivariate models based on copulas.</p>
<div id="full-maximum-likelihood-estimation" class="section level4 unnumbered hasAnchor">
<h4>Full maximum likelihood estimation<a href="r-for-statistical-inference.html#full-maximum-likelihood-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>Consider <span class="math inline">\(\mathbf{X} = (X_1, \dots, X_p)\)</span> a random vector with joint distribution function <span class="math inline">\(F\)</span> which is specified by marginals with distribution functions <span class="math inline">\(F_1 \dots, F_p\)</span> and densities <span class="math inline">\(f_1 \dots, f_p\)</span>, and a copula <span class="math inline">\(C\)</span> with density <span class="math inline">\(c\)</span>. Furthermore, let <span class="math inline">\(\boldsymbol{\beta}_j\)</span> be the parameters of the <span class="math inline">\(j\)</span>th marginal, that is, <span class="math inline">\(f_j(\cdot, \boldsymbol{\beta}_j)\)</span>, <span class="math inline">\(j =1, \dots, p\)</span>, <span class="math inline">\(\boldsymbol{\alpha}\)</span> be the parameters of the copula <span class="math inline">\(C\)</span>, i.e., <span class="math inline">\(C(\cdot, \boldsymbol{\alpha})\)</span>, and <span class="math inline">\(\boldsymbol{\theta} = (\boldsymbol{\beta}_1, \dots,\boldsymbol{\beta}_p, \boldsymbol{\alpha})\)</span>. Next,
suppose that we have <span class="math inline">\(n\)</span> independent realizations <span class="math inline">\(\tilde{\mathbf{x}} = \{ \mathbf{x}_i = (x_{i1}, \dots, x_{ip}) : i = 1, \dots, n \}\)</span> from <span class="math inline">\(\mathbf{X}\)</span>. Then, the loglikelihood function is given by</p>
<p><span class="math display">\[
l(\boldsymbol{\theta}; \tilde{\mathbf{x}}) = \sum_{i = 1}^n \log(c(F_{1}(x_{i1}; \boldsymbol{\beta}_1), \dots, F_{p}(x_{ip}; \boldsymbol{\beta}_p); \boldsymbol{\alpha})) + \sum_{i = 1}^n \sum_{j= 1}^p \log(f_{j}(x_{ij}; \boldsymbol{\beta}_j)) \,.
\]</span>
Thus, the maximum likelihood estimator <span class="math inline">\(\hat{\boldsymbol{\theta}}\)</span> of <span class="math inline">\(\boldsymbol{\theta}\)</span> is given by
<span class="math display">\[
\hat{\boldsymbol{\theta}} = {\arg\max}_{\boldsymbol{\theta} \in \boldsymbol{\Theta}} l(\boldsymbol{\theta}; \tilde{\mathbf{x}})\,.
\]</span>
Let us now illustrate how to implement this procedure in R. Consider the following multivariate model:</p>
<div class="sourceCode" id="cb821"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb821-1"><a href="r-for-statistical-inference.html#cb821-1" aria-hidden="true" tabindex="-1"></a>my_mvd <span class="ot">&lt;-</span> <span class="fu">mvdc</span>(</span>
<span id="cb821-2"><a href="r-for-statistical-inference.html#cb821-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">copula =</span> <span class="fu">ellipCopula</span>(<span class="at">family =</span> <span class="st">&quot;normal&quot;</span>, <span class="at">param =</span> <span class="fl">0.5</span>),</span>
<span id="cb821-3"><a href="r-for-statistical-inference.html#cb821-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">margins =</span> <span class="fu">c</span>(<span class="st">&quot;gamma&quot;</span>, <span class="st">&quot;gamma&quot;</span>), </span>
<span id="cb821-4"><a href="r-for-statistical-inference.html#cb821-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">paramMargins =</span> <span class="fu">list</span>(<span class="fu">list</span>(<span class="at">shape =</span> <span class="dv">2</span>,<span class="at">scale =</span> <span class="dv">1</span>), <span class="fu">list</span>(<span class="at">shape =</span> <span class="dv">3</span>, <span class="at">scale =</span> <span class="dv">2</span>))</span>
<span id="cb821-5"><a href="r-for-statistical-inference.html#cb821-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<p>Then, we simulate a sample from the model above</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb822-1"><a href="r-for-statistical-inference.html#cb822-1" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="dv">200</span></span>
<span id="cb822-2"><a href="r-for-statistical-inference.html#cb822-2" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">1</span>)</span>
<span id="cb822-3"><a href="r-for-statistical-inference.html#cb822-3" aria-hidden="true" tabindex="-1"></a>sim_dat <span class="ot">&lt;-</span> <span class="fu">rMvdc</span>(n, my_mvd)</span></code></pre></div>
<p>Firstly, we can make loglikelihood evaluations for a certain set of parameters using the <code>loglikMvdc()</code> function. For example, using the original parameters of our model, we obtain:</p>
<div class="sourceCode" id="cb823"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb823-1"><a href="r-for-statistical-inference.html#cb823-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglikMvdc</span>(<span class="at">param =</span> <span class="fu">c</span>(<span class="dv">2</span>, <span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">2</span>, <span class="fl">0.5</span>), sim_dat, my_mvd)</span></code></pre></div>
<pre><code>## [1] -793.0129</code></pre>
<p>Note that the parameters must be passed in vector form and ordered: first, the parameters of the marginals and last, the copula parameters. Now, to perform MLE, we can use the <code>fitMvd()</code> function. In this case, we need to pass the data, an mvdc object with the structure that we want to fit, and the starting values for the optimization. For example,</p>
<div class="sourceCode" id="cb825"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb825-1"><a href="r-for-statistical-inference.html#cb825-1" aria-hidden="true" tabindex="-1"></a>mut_fit <span class="ot">&lt;-</span> <span class="fu">fitMvdc</span>(sim_dat, my_mvd, <span class="at">start =</span> <span class="fu">c</span>(<span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>))</span>
<span id="cb825-2"><a href="r-for-statistical-inference.html#cb825-2" aria-hidden="true" tabindex="-1"></a>mut_fit</span></code></pre></div>
<pre><code>## Call: fitMvdc(data = sim_dat, mvdc = my_mvd, start = c(1, 1, 1, 1, 
##     0.1))
## Maximum Likelihood estimation based on 200 2-dimensional observations.
## Copula:  normalCopula 
## Margin 1 :
## m1.shape m1.scale 
##   2.1431   0.9435 
## Margin 2 :
## m2.shape m2.scale 
##    3.308    1.859 
## Copula: 
##  rho.1 
## 0.4879 
## The maximized loglikelihood is -792.2 
## Optimization converged</code></pre>
<p>A useful characteristic of the implementation above is that we get an mvdc object with the estimated parameters as part of the output, which can be accessed using the <code>@</code> operator. Then, we can use all the methods for mvdc objects with our fitted multivariate model. For instance,</p>
<div class="sourceCode" id="cb827"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb827-1"><a href="r-for-statistical-inference.html#cb827-1" aria-hidden="true" tabindex="-1"></a><span class="fu">persp</span>(mut_fit<span class="sc">@</span>mvdc, dMvdc, <span class="at">xlim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">4</span>), <span class="at">ylim =</span> <span class="fu">c</span>(<span class="dv">0</span>, <span class="dv">6</span>))</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-340-1.png" width="672" style="display: block; margin: auto;" /></p>
</div>
<div id="two-step-estimation" class="section level4 unnumbered hasAnchor">
<h4>Two-step estimation<a href="r-for-statistical-inference.html#two-step-estimation" class="anchor-section" aria-label="Anchor link to header"></a></h4>
<p>When the dimension <span class="math inline">\(p\)</span> increases, the number of parameters to be estimated increases as well, making the optimization problem harder. In such a case, separating the estimation problem into fitting the marginals and the copula separately can significantly reduce the computational burden. This approach is often referred to as a two-stage parametric maximum likelihood method. More specifically, the method consists of estimating first the parameters of the marginals, that is, we first compute
<span class="math display">\[
\hat{\boldsymbol{\beta}}_j = {\arg\max}_{\boldsymbol{\beta}}  \sum_{i = 1}^n \log(f_{j}(x_{ij}; \boldsymbol{\beta})) \,, \quad \, j = 1,\dots, p \,.
\]</span>
Next, we estimate the parameter <span class="math inline">\(\boldsymbol{\alpha}\)</span> of <span class="math inline">\(C\)</span>, given the parameters of the marginals <span class="math inline">\(\hat{\boldsymbol{\beta}}_j\)</span>, <span class="math inline">\(j = 1,\dots, p\)</span>, by finding</p>
<p><span class="math display">\[
\hat{\boldsymbol{\alpha}} = {\arg\max}_{\boldsymbol{\alpha}} \sum_{i = 1}^n \log(c(F_{1}(x_{i1}; \hat{\boldsymbol{\beta}}_1), \dots, F_{p}(x_{ip}; \hat{\boldsymbol{\beta}}_p); \boldsymbol{\alpha})) \,.
\]</span>
In R, we can use the machinery introduced in Section <a href="r-for-statistical-inference.html#parinf">2.3</a> to fit the marginal distributions, and with those estimators at hand, then we can use the <code>fitCopula()</code> to find the MLE of the copula parameters. Let us now look at a specific example. First, we estimate the parameters of the marginals</p>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="r-for-statistical-inference.html#cb828-1" aria-hidden="true" tabindex="-1"></a>par1 <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(sim_dat[, <span class="dv">1</span>], <span class="at">distr =</span> <span class="st">&quot;gamma&quot;</span>)<span class="sc">$</span>estimate</span>
<span id="cb828-2"><a href="r-for-statistical-inference.html#cb828-2" aria-hidden="true" tabindex="-1"></a>par1</span></code></pre></div>
<pre><code>##    shape     rate 
## 2.142617 1.058976</code></pre>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb830-1"><a href="r-for-statistical-inference.html#cb830-1" aria-hidden="true" tabindex="-1"></a>par2 <span class="ot">&lt;-</span> <span class="fu">fitdist</span>(sim_dat[, <span class="dv">2</span>], <span class="at">distr =</span> <span class="st">&quot;gamma&quot;</span>)<span class="sc">$</span>estimate</span>
<span id="cb830-2"><a href="r-for-statistical-inference.html#cb830-2" aria-hidden="true" tabindex="-1"></a>par2</span></code></pre></div>
<pre><code>##     shape      rate 
## 3.3085663 0.5378679</code></pre>
<p>Next, using the estimators above, we find the evaluation points <span class="math inline">\((F_{1}(x_{i1}; \hat{\boldsymbol{\beta}}_1), F_{2}(x_{ip}; \hat{\boldsymbol{\beta}}_2))\)</span> that will be used to estimate the copula parameters.</p>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb832-1"><a href="r-for-statistical-inference.html#cb832-1" aria-hidden="true" tabindex="-1"></a>u_dat <span class="ot">&lt;-</span> <span class="fu">cbind</span>(<span class="fu">pgamma</span>(sim_dat[, <span class="dv">1</span>], par1[<span class="dv">1</span>], par1[<span class="dv">2</span>]),</span>
<span id="cb832-2"><a href="r-for-statistical-inference.html#cb832-2" aria-hidden="true" tabindex="-1"></a>    <span class="fu">pgamma</span>(sim_dat[, <span class="dv">2</span>], par2[<span class="dv">1</span>], par2[<span class="dv">2</span>]))</span></code></pre></div>
<p>Finally, we estimate the copula parameters using <code>fitCopula()</code></p>
<div class="sourceCode" id="cb833"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb833-1"><a href="r-for-statistical-inference.html#cb833-1" aria-hidden="true" tabindex="-1"></a>cop_fit <span class="ot">&lt;-</span> <span class="fu">fitCopula</span>(my_mvd<span class="sc">@</span>copula, u_dat, <span class="at">start =</span> <span class="fl">0.1</span>)</span>
<span id="cb833-2"><a href="r-for-statistical-inference.html#cb833-2" aria-hidden="true" tabindex="-1"></a>cop_fit</span></code></pre></div>
<pre><code>## Call: fitCopula(my_mvd@copula, data = u_dat, ... = pairlist(start = 0.1))
## Fit based on &quot;maximum pseudo-likelihood&quot; and 200 2-dimensional observations.
## Copula: normalCopula 
##  rho.1 
## 0.4879 
## The maximized loglikelihood is 27.2 
## Optimization converged</code></pre>
<p>Thus, the estimated multivariate model would be the following:</p>
<div class="sourceCode" id="cb835"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb835-1"><a href="r-for-statistical-inference.html#cb835-1" aria-hidden="true" tabindex="-1"></a>mut_fit_2stage <span class="ot">&lt;-</span> <span class="fu">mvdc</span>(</span>
<span id="cb835-2"><a href="r-for-statistical-inference.html#cb835-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">copula =</span> cop_fit<span class="sc">@</span>copula,</span>
<span id="cb835-3"><a href="r-for-statistical-inference.html#cb835-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">margins =</span> <span class="fu">c</span>(<span class="st">&quot;gamma&quot;</span>, <span class="st">&quot;gamma&quot;</span>),</span>
<span id="cb835-4"><a href="r-for-statistical-inference.html#cb835-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">paramMargins =</span> <span class="fu">list</span>(</span>
<span id="cb835-5"><a href="r-for-statistical-inference.html#cb835-5" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">shape =</span> <span class="fu">unname</span>(par1[<span class="dv">1</span>]), <span class="at">rate =</span> <span class="fu">unname</span>(par1[<span class="dv">2</span>])),</span>
<span id="cb835-6"><a href="r-for-statistical-inference.html#cb835-6" aria-hidden="true" tabindex="-1"></a>    <span class="fu">list</span>(<span class="at">shape =</span> <span class="fu">unname</span>(par2[<span class="dv">1</span>]), <span class="at">rate =</span> <span class="fu">unname</span>(par2[<span class="dv">2</span>]))</span>
<span id="cb835-7"><a href="r-for-statistical-inference.html#cb835-7" aria-hidden="true" tabindex="-1"></a>  )</span>
<span id="cb835-8"><a href="r-for-statistical-inference.html#cb835-8" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb835-9"><a href="r-for-statistical-inference.html#cb835-9" aria-hidden="true" tabindex="-1"></a>mut_fit_2stage</span></code></pre></div>
<pre><code>## Multivariate Distribution Copula based (&quot;mvdc&quot;)
##  @ copula:
## Normal copula, dim. d = 2 
## Dimension:  2 
## Parameters:
##   rho.1   = 0.4879325
##  @ margins:
## [1] &quot;gamma&quot; &quot;gamma&quot;
##    with 2 (not identical)  margins; with parameters (@ paramMargins) 
## List of 2
##  $ :List of 2
##   ..$ shape: num 2.142617
##   ..$ rate : num 1.058976
##  $ :List of 2
##   ..$ shape: num 3.308566
##   ..$ rate : num 0.5378679</code></pre>
<p>with corresponding loglikelihood</p>
<div class="sourceCode" id="cb837"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb837-1"><a href="r-for-statistical-inference.html#cb837-1" aria-hidden="true" tabindex="-1"></a><span class="fu">loglikMvdc</span>(</span>
<span id="cb837-2"><a href="r-for-statistical-inference.html#cb837-2" aria-hidden="true" tabindex="-1"></a>  <span class="at">param =</span> <span class="fu">c</span>(par1, par2, cop_fit<span class="sc">@</span>copula<span class="sc">@</span>parameters),</span>
<span id="cb837-3"><a href="r-for-statistical-inference.html#cb837-3" aria-hidden="true" tabindex="-1"></a>  sim_dat,</span>
<span id="cb837-4"><a href="r-for-statistical-inference.html#cb837-4" aria-hidden="true" tabindex="-1"></a>  mut_fit_2stage</span>
<span id="cb837-5"><a href="r-for-statistical-inference.html#cb837-5" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
<pre><code>## [1] -792.1991</code></pre>
</div>
</div>
</div>
<div id="linear-regression" class="section level2 hasAnchor" number="2.5">
<h2><span class="header-section-number">2.5</span> Linear regression<a href="r-for-statistical-inference.html#linear-regression" class="anchor-section" aria-label="Anchor link to header"></a></h2>
<p>Linear regression is one of the most commonly used statistical methods in practice. The main idea is to use explanatory variables (or covariates) to explain (and predict) a random variable of interest. More specifically, a linear regression model relates a response variable <span class="math inline">\(Y\)</span> to a <span class="math inline">\(p\)</span>-dimensional vector <span class="math inline">\(X = (X_1, \dots, X_p)\)</span> of covariates via the identity</p>
<p><span class="math display">\[
\mathbb{E}\left[ Y \mid {X}\right] = \sum_{j = 1}^p X_j \beta_j =  X \boldsymbol{\beta}  \,,
\]</span>
where <span class="math inline">\(\boldsymbol{\beta} = (\beta_1, \dots, \beta_p)^{\top}\)</span>. It is common practice to add an <em>intercept</em> parameter <span class="math inline">\(\beta_0\)</span>, so that the linear model becomes</p>
<p><span class="math display">\[
\mathbb{E}\left[ Y \mid {X}\right] = \beta_0 + X \boldsymbol{\beta}  \,.
\]</span>
For notation convenience, the intercept is included among the other parameters, that is, <span class="math inline">\(\boldsymbol{\beta} = (\beta_0, \beta_1, \dots, \beta_p)^{\top}\)</span>. Note that <span class="math inline">\(\boldsymbol{\beta}\)</span> is now a <span class="math inline">\((p +1)\)</span> dimensional vector. We now want to express our regression model in terms of matrix products. To that end, we need to make an extra adjustment consisting of adding the covariate <span class="math inline">\(X_0 = 1\)</span> to <span class="math inline">\(X\)</span>. Thus, the regression model can be written as</p>
<p><span class="math display">\[
\mathbb{E}\left[ Y \mid {X}\right] = X \boldsymbol{\beta} = \beta_0 + \sum_{j = 1}^p X_j \beta_j  \,.
\]</span>
Now assume that we have a set of observations <span class="math inline">\((y_1, x_1), \dots, (y_n, x_n)\)</span>, where <span class="math inline">\(x_i = (x_{i1}, \dots,x_{ip})\)</span> are vectors of covariates, <span class="math inline">\(i = 1,\dots, n\)</span>, and that we want to estimate <span class="math inline">\(\boldsymbol{\beta}\)</span> from this data. The most common method to do so is the method of <em>least squares</em>, which consists of finding the coefficients <span class="math inline">\(\boldsymbol{\beta} = (\beta_1, \dots, \beta_p)\)</span> that minimize the residual sum of squares</p>
<p><span class="math display">\[
RSS(\boldsymbol{\beta}) = \sum_{i = 1}^n (y_i - \beta_0 - \sum_{j = 1}^n x_{ij} \beta_j)^2 \,.
\]</span>
Before showing how to minimize the above expression, we introduce further notation. Let <span class="math inline">\(\mathbf{X}\)</span> be the <span class="math inline">\(n \times (p + 1)\)</span> matrix with <span class="math inline">\(i\)</span>-th row the vector <span class="math inline">\(x_i\)</span> (with <span class="math inline">\(1\)</span> in the first position) and let <span class="math inline">\(\mathbf{y} = (y_1, \dots, y_n)^{\top}\)</span>. Then we can write the residual sum of squares as
<span class="math display">\[
RSS(\boldsymbol{\beta}) = (\mathbf{y} - \mathbf{X} \boldsymbol{\beta})^{\top}(\mathbf{y} - \mathbf{X} \boldsymbol{\beta}) \,.
\]</span>
It is easy to see that the value of <span class="math inline">\(\boldsymbol{\beta}\)</span> that minimizes the expression above is given by
<span class="math display">\[
\hat{\boldsymbol{\beta}} = (\mathbf{X}^{\top}\mathbf{X})^{-1} \mathbf{X}^{\top} \mathbf{y} \,.
\]</span>
With the estimated parameters <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> at hand, we can now compute the predicted values <span class="math inline">\(\hat{\mathbf{y}}\)</span> for the input data as</p>
<p><span class="math display">\[
\hat{\mathbf{y}} = \mathbf{X} \hat{\boldsymbol{\beta}}  \,.
\]</span>
Moreover, we could use the above expression to predict values for new covariate information.</p>
<p>In R, linear regression can be performed using the <code>lm()</code> function. Let us now look at a specific example, dealing with the <em>Prostate Cancer</em> data set available in the <code>genridge</code> R package. First, we need to load the data set into our working space:</p>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb839-1"><a href="r-for-statistical-inference.html#cb839-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(genridge)</span></code></pre></div>
<pre><code>## Loading required package: car</code></pre>
<pre><code>## Loading required package: carData</code></pre>
<pre><code>## 
## Attaching package: &#39;genridge&#39;</code></pre>
<pre><code>## The following object is masked from &#39;package:survival&#39;:
## 
##     ridge</code></pre>
<div class="sourceCode" id="cb844"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb844-1"><a href="r-for-statistical-inference.html#cb844-1" aria-hidden="true" tabindex="-1"></a><span class="fu">data</span>(prostate)</span>
<span id="cb844-2"><a href="r-for-statistical-inference.html#cb844-2" aria-hidden="true" tabindex="-1"></a>prostate <span class="ot">&lt;-</span> prostate[, <span class="sc">-</span><span class="dv">10</span>] <span class="co"># No relevant for the present analysis</span></span>
<span id="cb844-3"><a href="r-for-statistical-inference.html#cb844-3" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(prostate)</span></code></pre></div>
<pre><code>##       lcavol  lweight age      lbph svi       lcp gleason pgg45       lpsa
## 1 -0.5798185 2.769459  50 -1.386294   0 -1.386294       6     0 -0.4307829
## 2 -0.9942523 3.319626  58 -1.386294   0 -1.386294       6     0 -0.1625189
## 3 -0.5108256 2.691243  74 -1.386294   0 -1.386294       7    20 -0.1625189
## 4 -1.2039728 3.282789  58 -1.386294   0 -1.386294       6     0 -0.1625189
## 5  0.7514161 3.432373  62 -1.386294   0 -1.386294       6     0  0.3715636
## 6 -1.0498221 3.228826  50 -1.386294   0 -1.386294       6     0  0.7654678</code></pre>
<p>We aim to explain the variable <code>lpsa</code> (level of prostate-specific antigen) in terms of the other variables. The following is a scatter plot matrix showing every pairwise plot between the variables:</p>
<div class="sourceCode" id="cb846"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb846-1"><a href="r-for-statistical-inference.html#cb846-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prostate)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-347-1.png" width="672" /></p>
<p>One can observe, for example, that <code>lcavol</code> and <code>lpc</code> are positively correlated with <code>lpsa</code>. Moreover, note that <code>svi</code> is a binary variable, and <code>gleason</code> is a categorical variable.</p>
<p>We now fit a linear regression model using all our covariates:</p>
<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb847-1"><a href="r-for-statistical-inference.html#cb847-1" aria-hidden="true" tabindex="-1"></a>prost_lm <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> lpsa <span class="sc">~</span> lcavol <span class="sc">+</span> lweight <span class="sc">+</span> age <span class="sc">+</span> lbph</span>
<span id="cb847-2"><a href="r-for-statistical-inference.html#cb847-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> svi <span class="sc">+</span> lcp <span class="sc">+</span> gleason <span class="sc">+</span> pgg45, <span class="at">data =</span> prostate)</span>
<span id="cb847-3"><a href="r-for-statistical-inference.html#cb847-3" aria-hidden="true" tabindex="-1"></a>prost_lm</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + age + lbph + svi + lcp + 
##     gleason + pgg45, data = prostate)
## 
## Coefficients:
## (Intercept)       lcavol      lweight          age         lbph          svi  
##    0.181561     0.564341     0.622020    -0.021248     0.096713     0.761673  
##         lcp      gleason        pgg45  
##   -0.106051     0.049228     0.004458</code></pre>
<p>Using our linear model above, we can now compute the predicted values for the input data with the function <code>predic()</code>:</p>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb849-1"><a href="r-for-statistical-inference.html#cb849-1" aria-hidden="true" tabindex="-1"></a>pros_pred <span class="ot">&lt;-</span> <span class="fu">predict</span>(prost_lm) </span>
<span id="cb849-2"><a href="r-for-statistical-inference.html#cb849-2" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(pros_pred)</span></code></pre></div>
<pre><code>##         1         2         3         4         5         6 
## 0.8229078 0.7612550 0.4416131 0.6199877 1.7315458 0.8434007</code></pre>
<p>If we want to predict values of a new set of covariate values, these have to be passed into the <code>predict()</code> function in the form of a data frame with column names equal to those of the data frame used to create the linear mode. For example,</p>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb851-1"><a href="r-for-statistical-inference.html#cb851-1" aria-hidden="true" tabindex="-1"></a>xn <span class="ot">&lt;-</span> <span class="fu">matrix</span>(<span class="fu">c</span>(<span class="fl">1.35</span>, <span class="fl">3.6</span>, <span class="dv">64</span>, <span class="fl">0.1</span>, <span class="dv">0</span>, <span class="sc">-</span><span class="fl">0.18</span>, <span class="dv">6</span>, <span class="fl">2.5</span>), <span class="dv">1</span>)</span>
<span id="cb851-2"><a href="r-for-statistical-inference.html#cb851-2" aria-hidden="true" tabindex="-1"></a><span class="fu">colnames</span>(xn) <span class="ot">&lt;-</span>  <span class="fu">names</span>(prostate[, <span class="sc">-</span><span class="dv">9</span>])</span>
<span id="cb851-3"><a href="r-for-statistical-inference.html#cb851-3" aria-hidden="true" tabindex="-1"></a>xn <span class="ot">&lt;-</span> <span class="fu">as.data.frame</span>(xn) <span class="co"># Covariates have to be in the form of a data.frame</span></span>
<span id="cb851-4"><a href="r-for-statistical-inference.html#cb851-4" aria-hidden="true" tabindex="-1"></a>xn</span></code></pre></div>
<pre><code>##   lcavol lweight age lbph svi   lcp gleason pgg45
## 1   1.35     3.6  64  0.1   0 -0.18       6   2.5</code></pre>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="r-for-statistical-inference.html#cb853-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict</span>(prost_lm, xn) </span></code></pre></div>
<pre><code>##        1 
## 2.158081</code></pre>
<p>So far, we have made minimal assumptions regarding the linear model. However, we need further assumptions to draw inference about the parameters and the model. More specifically, we assume that our model is of the form</p>
<p><span class="math display">\[
Y_i  =  X_i \boldsymbol{\beta} + e_i   \,, \quad i = 1,\dots, n \,,
\]</span></p>
<p>where the <span class="math inline">\(e_i\)</span>, called error terms or <em>residuals</em>, are uncorrelated with <span class="math inline">\(\mathbb{E}[e_i] = 0\)</span> and <span class="math inline">\(Var(e_i) = \sigma^2\)</span>. Moreover, note that by using the vector notation <span class="math inline">\(\mathbf{e} =(e_1, \dots, e_n)^{\top}\)</span>, we can rewrite the model as
<span class="math display">\[
\mathbf{Y}  =  \mathbf{X} \boldsymbol{\beta}+ \mathbf{e}\,.
\]</span>
Under these assumptions, it is easy to see that the covariance matrix of the least squared estimator <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> is given by</p>
<p><span class="math display">\[
Var(\hat{\boldsymbol{\beta}}) = \sigma^2 (\mathbf{X}^{\top}\mathbf{X})^{-1} \,.
\]</span>
Note also that we can estimate the residuals as
<span class="math display">\[
\hat{\mathbf{e}} = \mathbf{y} - \hat{\mathbf{y}} \,.
\]</span>
In R, one can compute the residuals of a linear model using the <code>residuals()</code> function. For instance,</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="r-for-statistical-inference.html#cb855-1" aria-hidden="true" tabindex="-1"></a>res_pros <span class="ot">&lt;-</span> <span class="fu">residuals</span>(prost_lm)</span>
<span id="cb855-2"><a href="r-for-statistical-inference.html#cb855-2" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(res_pros)</span></code></pre></div>
<pre><code>##     Min.  1st Qu.   Median     Mean  3rd Qu.     Max. 
## -1.76644 -0.35510 -0.00328  0.00000  0.38087  1.55770</code></pre>
<p>It turns out that properties of the estimate residuals <span class="math inline">\(\hat{\mathbf{e}}\)</span>, lead to the following unbiased estimator of the variance <span class="math inline">\(\sigma^2\)</span>
<span class="math display">\[
\hat{\sigma}^2 = \frac{1}{n - p - 1} ({\mathbf{y}}  - \hat{\mathbf{y}} )^{\top} ({\mathbf{y}}  - \hat{\mathbf{y}} ) = \frac{1}{n - p - 1} \sum_{i = 1}^n(y_i - \hat{y}_i)^2  \,.
\]</span>
If we further assume that the residuals are normally distributed with mean <span class="math inline">\(0\)</span> and variance <span class="math inline">\(\sigma^2\)</span>, that is, <span class="math inline">\(e_i \sim N(0, \sigma^2)\)</span>, <span class="math inline">\(i =1 \dots, n\)</span>, then it is easy to show that
<span class="math display">\[
\hat{\boldsymbol{\beta}} \sim N({\boldsymbol{\beta}}, \sigma^2 (\mathbf{X}^{\top}\mathbf{X})^{-1} ) \,,
\]</span>
and</p>
<p><span class="math display">\[
(n - p - 1) \hat{\sigma}^2 \sim \sigma^2 \chi^{2}_{n - p - 1} \,,
\]</span>
where <span class="math inline">\(\chi^{2}_{n - p - 1}\)</span> denotes a chi-squared distribution with <span class="math inline">\(n - p -1\)</span> degrees of freedom. Moreover, <span class="math inline">\(\hat{\boldsymbol{\beta}}\)</span> and <span class="math inline">\(\hat{\sigma}^2\)</span> are independent. These properties are particularly useful for performing hypothesis testing and creating confidence intervals for the parameters <span class="math inline">\(\beta_j\)</span>.</p>
<p>To test the hypothesis that a coefficient of the linear model <span class="math inline">\(\beta_j\)</span> is equal to zero, i.e., <span class="math inline">\(\beta_j = 0\)</span>, we consider the standardized coefficient or Z-score
<span class="math display">\[
z_j = \frac{\hat{\beta_j}}{\hat{\sigma} \sqrt{v_j}} \,,
\]</span>
where <span class="math inline">\(v_j\)</span> is the <span class="math inline">\(j\)</span>-th diagonal element of <span class="math inline">\((\mathbf{X}^{\top}\mathbf{X})^{-1}\)</span>. Under the null hypothesis that <span class="math inline">\(\beta_j = 0\)</span>, <span class="math inline">\(z_j\)</span> is <span class="math inline">\(t_{n - p -1}\)</span> distributed, and hence large (absolute) values of <span class="math inline">\(z_j\)</span> will lead to the rejection of this null hypothesis. In R, we can use <code>summary()</code> to access the values of these statistics (<em>t-statistic</em> column):</p>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb857-1"><a href="r-for-statistical-inference.html#cb857-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(prost_lm)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + age + lbph + svi + lcp + 
##     gleason + pgg45, data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.76644 -0.35510 -0.00328  0.38087  1.55770 
## 
## Coefficients:
##              Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  0.181561   1.320568   0.137  0.89096    
## lcavol       0.564341   0.087833   6.425 6.55e-09 ***
## lweight      0.622020   0.200897   3.096  0.00263 ** 
## age         -0.021248   0.011084  -1.917  0.05848 .  
## lbph         0.096713   0.057913   1.670  0.09848 .  
## svi          0.761673   0.241176   3.158  0.00218 ** 
## lcp         -0.106051   0.089868  -1.180  0.24115    
## gleason      0.049228   0.155341   0.317  0.75207    
## pgg45        0.004458   0.004365   1.021  0.31000    
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.6995 on 88 degrees of freedom
## Multiple R-squared:  0.6634, Adjusted R-squared:  0.6328 
## F-statistic: 21.68 on 8 and 88 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>R also provides the <em>p-value</em>s associated with these tests (column <em>Pr(&gt;|t|)</em>). Recall that a p-value is the probability of obtaining test results at least as “extreme” as the results observed, assuming that the null hypothesis is correct. In other words, the smaller the p-value, the stronger the evidence that you should reject the null hypothesis. A nice feature of R is that marks with <code>*</code> and <code>.</code> the parameters with p-values lower than commonly used significance levels.</p>
<p>It is often the case that we need to test for the significance of groups of coefficients simultaneously. For that purpose, we can use the F statistics, defined as
<span class="math display">\[
F = \frac{(RSS_0 - RSS_1) / ( p_1 - p_0)}{RSS_1 / (n - p_1 - 1)} \,,
\]</span>
where <span class="math inline">\(RSS_1\)</span> is the residual sum of squares for the fit of the bigger model with <span class="math inline">\(p_1 + 1\)</span> parameters, and <span class="math inline">\(RSS_0\)</span> is the corresponding value for the (nested) smaller model with <span class="math inline">\(p_0 + 1\)</span> parameters. Under Gaussian assumption on the residuals, and that the smaller model is correct, the F statistics is <span class="math inline">\(F_{p_1 - p_0, n - p_1 - 1}\)</span> distributed. In the output of the <code>summary()</code> function above, we have an F statistics (and corresponding p-value) that compares with a model with all coefficients equal to zero (i.e., test the null hypothesis: “All coefficients are zero”).</p>
<p>Finally, note that <code>summary()</code> displays additional information, such as the <em>Multiple R-squared</em>. This measures the proportion of the variance in the response variable that the model can explain, and it varies from 0 to 1. Thus, we should aim for a model with multiple R-squared as close to 1 as possible. The last piece of information is the <em>Adjusted R-squared</em>, which is simply an adjustment to the multiple R-squared that considers the data size and the number of covariates. Hence, the adjusted R-squared is recommended to be used over the (conventional) multiple R-squared.</p>
<p>Considering all the information described above, let us now consider a smaller model that consists only of the covariates <code>lcavol</code>, <code>lweight</code>, <code>lbph</code>, <code>svi</code>, and without an intercept.</p>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb859-1"><a href="r-for-statistical-inference.html#cb859-1" aria-hidden="true" tabindex="-1"></a>prost_lm2 <span class="ot">&lt;-</span> <span class="fu">lm</span>(<span class="at">formula =</span> lpsa <span class="sc">~</span> lcavol <span class="sc">+</span> lweight</span>
<span id="cb859-2"><a href="r-for-statistical-inference.html#cb859-2" aria-hidden="true" tabindex="-1"></a>  <span class="sc">+</span> lbph <span class="sc">+</span> svi <span class="sc">-</span> <span class="dv">1</span>, <span class="at">data =</span> prostate)</span>
<span id="cb859-3"><a href="r-for-statistical-inference.html#cb859-3" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(prost_lm2)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = lpsa ~ lcavol + lweight + lbph + svi - 1, data = prostate)
## 
## Residuals:
##      Min       1Q   Median       3Q      Max 
## -1.84248 -0.39868  0.01499  0.44124  1.51028 
## 
## Coefficients:
##         Estimate Std. Error t value Pr(&gt;|t|)    
## lcavol   0.53274    0.07370   7.229 1.34e-10 ***
## lweight  0.44069    0.03083  14.293  &lt; 2e-16 ***
## lbph     0.09098    0.04992   1.822 0.071619 .  
## svi      0.71339    0.20651   3.455 0.000832 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 0.7011 on 93 degrees of freedom
## Multiple R-squared:  0.9368, Adjusted R-squared:  0.9341 
## F-statistic: 344.8 on 4 and 93 DF,  p-value: &lt; 2.2e-16</code></pre>
<p>We can see that for the covariates selected, we can reject the null hypothesis <span class="math inline">\(\beta_j = 0\)</span>, and we obtain a larger adjusted R-squared. All good indicators that our model is better.</p>
<p>Furthermore, we can test if “the smaller model is correct” using the F statistics, which can be accessed in R via the <code>anova()</code> function:</p>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb861-1"><a href="r-for-statistical-inference.html#cb861-1" aria-hidden="true" tabindex="-1"></a><span class="fu">anova</span>(prost_lm, prost_lm2)</span></code></pre></div>
<pre><code>## Analysis of Variance Table
## 
## Model 1: lpsa ~ lcavol + lweight + age + lbph + svi + lcp + gleason + 
##     pgg45
## Model 2: lpsa ~ lcavol + lweight + lbph + svi - 1
##   Res.Df    RSS Df Sum of Sq     F Pr(&gt;F)
## 1     88 43.058                          
## 2     93 45.715 -5   -2.6568 1.086 0.3738</code></pre>
<p>Hence, we cannot reject the null hypothesis that “the smaller model is correct”. We can also use information criteria to assess the quality of a model. For instance, we can compute the AIC for our two models using the <code>AIC()</code> function:</p>
<div class="sourceCode" id="cb863"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb863-1"><a href="r-for-statistical-inference.html#cb863-1" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(prost_lm)</span></code></pre></div>
<pre><code>## [1] 216.4952</code></pre>
<div class="sourceCode" id="cb865"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb865-1"><a href="r-for-statistical-inference.html#cb865-1" aria-hidden="true" tabindex="-1"></a><span class="fu">AIC</span>(prost_lm2)</span></code></pre></div>
<pre><code>## [1] 212.303</code></pre>
<p>Confirming our previous selection.</p>
<p>We are often also interested in constructing confidence intervals for the coefficients <span class="math inline">\(\beta_j\)</span>. Fortunately, it is easy to see that under the Gaussian assumption on the residuals, a <span class="math inline">\((1 - \alpha)\)</span> confidence interval for <span class="math inline">\(\beta_j\)</span> is given by
<span class="math display">\[
\hat{\beta}_j \pm z_{1 - \alpha /2} v_j^{1/2} \hat{\sigma} \,,
\]</span>
where <span class="math inline">\(z_{1 - \alpha /2}\)</span> is the <span class="math inline">\((1 - \alpha /2)\)</span> quantile of a standard normal distribution. We can compute confidence intervals in R via the <code>confint()</code> function. For instance, for our last model, we have</p>
<div class="sourceCode" id="cb867"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb867-1"><a href="r-for-statistical-inference.html#cb867-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(prost_lm2)</span></code></pre></div>
<pre><code>##                2.5 %    97.5 %
## lcavol   0.386398071 0.6790891
## lweight  0.379458771 0.5019129
## lbph    -0.008161222 0.1901136
## svi      0.303311220 1.1234695</code></pre>
<p>Corresponding to 95% confidence intervals for the parameters <span class="math inline">\(\beta_j\)</span>.</p>
<p>Finally, note that all the above discussion regarding the inference of a linear model is based on the assumption that the residuals are normally distributed with mean <span class="math inline">\(0\)</span> and constant variance <span class="math inline">\(\sigma^2\)</span>. Hence it is important to check whether this assumption is satisfied or not. One way to do this is by using visual tools, which are readily available using the <code>plot()</code> function. For instance,</p>
<div class="sourceCode" id="cb869"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb869-1"><a href="r-for-statistical-inference.html#cb869-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(prost_lm2)</span></code></pre></div>
<p><img src="_main_files/figure-html/unnamed-chunk-357-1.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-357-2.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-357-3.png" width="672" /><img src="_main_files/figure-html/unnamed-chunk-357-4.png" width="672" /></p>
<p>The first plot (<em>Residuals vs Fitted</em>) helps us to assess the condition of mean zero of the residuals. Ideally, we should observe approximately a straight line around 0 (as above). The second plot (<em>Normal Q-Q</em>) deals with the normality of the residuals, and we should preferably observe points close to the identity line. The third plot (<em>Scale-Location</em>) assists us in identifying if the assumption of constant variance holds. We look for a red line close to a horizontal line (no matter the location). Finally, the fourth plot (<em>Residuals vs Leverage</em>) helps us to identify data points that are “extreme” and affect considerable the regression model. This is the case (not observed in the example above) when having points outside the dotted red lines. An in-depth analysis of those points should take place in such a situation.</p>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="introduction-to-r.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="r-for-finance.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": ["_main.pdf"],
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.9/latest.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
